Backbone(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): ModuleList(
        (0): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
            (4): ReLU()
            (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Sequential(
            (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
            (1): ReLU()
            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
            (4): ReLU()
            (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sequential(
            (0): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
            (1): ReLU()
            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
            (4): ReLU()
            (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (1): ModuleList(
        (0-2): 3 x ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (4): ReLU()
            (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Sequential(
            (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
            (1): ReLU()
            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (4): ReLU()
            (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sequential(
            (0): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
            (1): ReLU()
            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
            (4): ReLU()
            (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (2): ModuleList(
        (0-8): 9 x ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (4): ReLU()
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): Sequential(
            (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
            (1): ReLU()
            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (4): ReLU()
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (2): Sequential(
            (0): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
            (1): ReLU()
            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
            (4): ReLU()
            (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (encoder_0): Sequential(
      (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
      (4): ReLU()
      (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): ModuleList(
        (0-8): 9 x Sequential(
          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (4): ReLU()
          (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): ModuleList(
        (0-8): 9 x Sequential(
          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
          (1): ReLU()
          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
          (4): ReLU()
          (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): ModuleList(
        (0-8): 9 x Sequential(
          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))
          (1): ReLU()
          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
          (4): ReLU()
          (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): ModuleList(
        (0-8): 9 x Sequential(
          (0): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))
          (1): ReLU()
          (2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1))
          (4): ReLU()
          (5): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (softmax): Softmax(dim=1)
  )
)
  0%|          | 0/301 [00:00<?, ?it/s]step 11/275, epoch 1/301 --> loss:0.3899084091186523
step 21/275, epoch 1/301 --> loss:0.3150217115879059
step 31/275, epoch 1/301 --> loss:0.26642662286758423
step 41/275, epoch 1/301 --> loss:0.27687371969223024
step 51/275, epoch 1/301 --> loss:0.23188324570655822
step 61/275, epoch 1/301 --> loss:0.23256879448890685
step 71/275, epoch 1/301 --> loss:0.23976899385452272
step 81/275, epoch 1/301 --> loss:0.22800541520118714
step 91/275, epoch 1/301 --> loss:0.21265409588813783
step 101/275, epoch 1/301 --> loss:0.20346156358718873
step 111/275, epoch 1/301 --> loss:0.21783180832862853
step 121/275, epoch 1/301 --> loss:0.1781040370464325
step 131/275, epoch 1/301 --> loss:0.21457720994949342
step 141/275, epoch 1/301 --> loss:0.20115160346031188
step 151/275, epoch 1/301 --> loss:0.2099607467651367
step 161/275, epoch 1/301 --> loss:0.17397043704986573
step 171/275, epoch 1/301 --> loss:0.17824520468711852
step 181/275, epoch 1/301 --> loss:0.1964289665222168
step 191/275, epoch 1/301 --> loss:0.19405050873756408
step 201/275, epoch 1/301 --> loss:0.2102975845336914
step 211/275, epoch 1/301 --> loss:0.18671310544013978
step 221/275, epoch 1/301 --> loss:0.20401418805122376
step 231/275, epoch 1/301 --> loss:0.15121133327484132
step 241/275, epoch 1/301 --> loss:0.18776658177375793
step 251/275, epoch 1/301 --> loss:0.19276145100593567
step 261/275, epoch 1/301 --> loss:0.15664726495742798
step 271/275, epoch 1/301 --> loss:0.1965415060520172
########## train dataset ##########
PLout index:  2
acc -->  [83.9512308918666]
F1 -->  {'F1': [0.7839614308815888], 'precision': [0.8837518696669407], 'recall': [0.7044284866534438]}
########## eval dataset ##########
  0%|          | 1/301 [09:14<46:10:20, 554.07s/it]PLout index:  2
acc -->  [83.58289714055825]
F1 -->  {'F1': [0.7829629161421451], 'precision': [0.8864812012925212], 'recall': [0.7011011072260597]}
save model!
  1%|          | 2/301 [14:33<34:33:28, 416.08s/it]step 11/275, epoch 2/301 --> loss:0.17450681328773499
step 21/275, epoch 2/301 --> loss:0.1738347291946411
step 31/275, epoch 2/301 --> loss:0.20013163685798646
step 41/275, epoch 2/301 --> loss:0.18025383353233337
step 51/275, epoch 2/301 --> loss:0.1745292901992798
step 61/275, epoch 2/301 --> loss:0.1816813826560974
step 71/275, epoch 2/301 --> loss:0.1456052243709564
step 81/275, epoch 2/301 --> loss:0.2021073579788208
step 91/275, epoch 2/301 --> loss:0.16440643668174743
step 101/275, epoch 2/301 --> loss:0.16385115385055543
step 111/275, epoch 2/301 --> loss:0.17469800710678102
step 121/275, epoch 2/301 --> loss:0.17070037722587586
step 131/275, epoch 2/301 --> loss:0.17664554119110107
step 141/275, epoch 2/301 --> loss:0.16341790556907654
step 151/275, epoch 2/301 --> loss:0.17267897129058837
step 161/275, epoch 2/301 --> loss:0.16016685366630554
step 171/275, epoch 2/301 --> loss:0.17165457010269164
step 181/275, epoch 2/301 --> loss:0.16320232748985292
step 191/275, epoch 2/301 --> loss:0.1747291386127472
step 201/275, epoch 2/301 --> loss:0.18383100628852844
step 211/275, epoch 2/301 --> loss:0.18158167600631714
step 221/275, epoch 2/301 --> loss:0.20047816634178162
step 231/275, epoch 2/301 --> loss:0.1816750466823578
step 241/275, epoch 2/301 --> loss:0.18741300702095032
step 251/275, epoch 2/301 --> loss:0.18414461016654968
step 261/275, epoch 2/301 --> loss:0.16796330213546753
step 271/275, epoch 2/301 --> loss:0.17124101519584656
  1%|          | 3/301 [19:53<30:47:38, 372.01s/it]step 11/275, epoch 3/301 --> loss:0.17957083582878114
step 21/275, epoch 3/301 --> loss:0.17296297550201417
step 31/275, epoch 3/301 --> loss:0.16011608839035035
step 41/275, epoch 3/301 --> loss:0.16380011439323425
step 51/275, epoch 3/301 --> loss:0.15224899649620055
step 61/275, epoch 3/301 --> loss:0.14716600775718688
step 71/275, epoch 3/301 --> loss:0.16147368550300598
step 81/275, epoch 3/301 --> loss:0.19763241410255433
step 91/275, epoch 3/301 --> loss:0.1717437505722046
step 101/275, epoch 3/301 --> loss:0.175620174407959
step 111/275, epoch 3/301 --> loss:0.18413103222846985
step 121/275, epoch 3/301 --> loss:0.16671782732009888
step 131/275, epoch 3/301 --> loss:0.19156636595726012
step 141/275, epoch 3/301 --> loss:0.16807340383529662
step 151/275, epoch 3/301 --> loss:0.16224101781845093
step 161/275, epoch 3/301 --> loss:0.15453475713729858
step 171/275, epoch 3/301 --> loss:0.18284162878990173
step 181/275, epoch 3/301 --> loss:0.1695261776447296
step 191/275, epoch 3/301 --> loss:0.16893633008003234
step 201/275, epoch 3/301 --> loss:0.15737687349319457
step 211/275, epoch 3/301 --> loss:0.15404675602912904
step 221/275, epoch 3/301 --> loss:0.17648417949676515
step 231/275, epoch 3/301 --> loss:0.14628445506095886
step 241/275, epoch 3/301 --> loss:0.16349818110466002
step 251/275, epoch 3/301 --> loss:0.16342127919197083
step 261/275, epoch 3/301 --> loss:0.15507237911224364
step 271/275, epoch 3/301 --> loss:0.1422687828540802
  1%|▏         | 4/301 [25:14<29:02:48, 352.08s/it]step 11/275, epoch 4/301 --> loss:0.15305042862892151
step 21/275, epoch 4/301 --> loss:0.1744456708431244
step 31/275, epoch 4/301 --> loss:0.1512458622455597
step 41/275, epoch 4/301 --> loss:0.14353299140930176
step 51/275, epoch 4/301 --> loss:0.17163095474243165
step 61/275, epoch 4/301 --> loss:0.14129890203475953
step 71/275, epoch 4/301 --> loss:0.1465619146823883
step 81/275, epoch 4/301 --> loss:0.1876024067401886
step 91/275, epoch 4/301 --> loss:0.1577967882156372
step 101/275, epoch 4/301 --> loss:0.16378601789474487
step 111/275, epoch 4/301 --> loss:0.1493024706840515
step 121/275, epoch 4/301 --> loss:0.1543944239616394
step 131/275, epoch 4/301 --> loss:0.14390586614608764
step 141/275, epoch 4/301 --> loss:0.16623217463493348
step 151/275, epoch 4/301 --> loss:0.14887771606445313
step 161/275, epoch 4/301 --> loss:0.16501925587654115
step 171/275, epoch 4/301 --> loss:0.18126128911972045
step 181/275, epoch 4/301 --> loss:0.17304864525794983
step 191/275, epoch 4/301 --> loss:0.17865068912506105
step 201/275, epoch 4/301 --> loss:0.14369943737983704
step 211/275, epoch 4/301 --> loss:0.167448890209198
step 221/275, epoch 4/301 --> loss:0.13503463864326476
step 231/275, epoch 4/301 --> loss:0.16490944623947143
step 241/275, epoch 4/301 --> loss:0.14541815519332885
step 251/275, epoch 4/301 --> loss:0.1497607171535492
step 261/275, epoch 4/301 --> loss:0.1255161166191101
step 271/275, epoch 4/301 --> loss:0.14366059899330139
  2%|▏         | 5/301 [30:37<28:04:26, 341.44s/it]step 11/275, epoch 5/301 --> loss:0.18146494030952454
step 21/275, epoch 5/301 --> loss:0.15570420026779175
step 31/275, epoch 5/301 --> loss:0.1640845000743866
step 41/275, epoch 5/301 --> loss:0.1689690113067627
step 51/275, epoch 5/301 --> loss:0.1484318792819977
step 61/275, epoch 5/301 --> loss:0.14394358396530152
step 71/275, epoch 5/301 --> loss:0.16459292769432068
step 81/275, epoch 5/301 --> loss:0.17695844173431396
step 91/275, epoch 5/301 --> loss:0.15542297959327697
step 101/275, epoch 5/301 --> loss:0.14107431173324586
step 111/275, epoch 5/301 --> loss:0.15185200572013854
step 121/275, epoch 5/301 --> loss:0.13341805338859558
step 131/275, epoch 5/301 --> loss:0.1410051941871643
step 141/275, epoch 5/301 --> loss:0.14384880661964417
step 151/275, epoch 5/301 --> loss:0.1698474943637848
step 161/275, epoch 5/301 --> loss:0.14877891540527344
step 171/275, epoch 5/301 --> loss:0.14985384345054625
step 181/275, epoch 5/301 --> loss:0.1503729462623596
step 191/275, epoch 5/301 --> loss:0.16210004687309265
step 201/275, epoch 5/301 --> loss:0.15172430276870727
step 211/275, epoch 5/301 --> loss:0.14561656713485718
step 221/275, epoch 5/301 --> loss:0.13989717960357667
step 231/275, epoch 5/301 --> loss:0.15126113295555116
step 241/275, epoch 5/301 --> loss:0.1425317645072937
step 251/275, epoch 5/301 --> loss:0.15444468855857849
step 261/275, epoch 5/301 --> loss:0.11197183132171631
step 271/275, epoch 5/301 --> loss:0.13212339878082274
  2%|▏         | 6/301 [35:59<27:26:16, 334.84s/it]step 11/275, epoch 6/301 --> loss:0.1340264856815338
step 21/275, epoch 6/301 --> loss:0.14184300899505614
step 31/275, epoch 6/301 --> loss:0.15253753662109376
step 41/275, epoch 6/301 --> loss:0.18065823912620543
step 51/275, epoch 6/301 --> loss:0.16682738661766053
step 61/275, epoch 6/301 --> loss:0.15954023599624634
step 71/275, epoch 6/301 --> loss:0.15528458952903748
step 81/275, epoch 6/301 --> loss:0.13097693920135497
step 91/275, epoch 6/301 --> loss:0.16356025338172914
step 101/275, epoch 6/301 --> loss:0.15916138291358947
step 111/275, epoch 6/301 --> loss:0.1342075765132904
step 121/275, epoch 6/301 --> loss:0.16032925248146057
step 131/275, epoch 6/301 --> loss:0.14763237833976744
step 141/275, epoch 6/301 --> loss:0.14386263489723206
step 151/275, epoch 6/301 --> loss:0.14735350608825684
step 161/275, epoch 6/301 --> loss:0.1699862003326416
step 171/275, epoch 6/301 --> loss:0.18943848609924316
step 181/275, epoch 6/301 --> loss:0.14805181622505187
step 191/275, epoch 6/301 --> loss:0.16098265051841737
step 201/275, epoch 6/301 --> loss:0.12391286492347717
step 211/275, epoch 6/301 --> loss:0.15204688310623168
step 221/275, epoch 6/301 --> loss:0.1572529911994934
step 231/275, epoch 6/301 --> loss:0.13811056613922118
step 241/275, epoch 6/301 --> loss:0.14593909978866576
step 251/275, epoch 6/301 --> loss:0.1357879102230072
step 261/275, epoch 6/301 --> loss:0.16898640990257263
step 271/275, epoch 6/301 --> loss:0.12397769093513489
  2%|▏         | 7/301 [41:19<26:57:33, 330.11s/it]step 11/275, epoch 7/301 --> loss:0.13613436222076417
step 21/275, epoch 7/301 --> loss:0.15751129984855652
step 31/275, epoch 7/301 --> loss:0.14655883312225343
step 41/275, epoch 7/301 --> loss:0.12645274996757508
step 51/275, epoch 7/301 --> loss:0.18092198967933654
step 61/275, epoch 7/301 --> loss:0.1502813518047333
step 71/275, epoch 7/301 --> loss:0.1245088517665863
step 81/275, epoch 7/301 --> loss:0.15534805059432982
step 91/275, epoch 7/301 --> loss:0.14414339065551757
step 101/275, epoch 7/301 --> loss:0.13235012888908387
step 111/275, epoch 7/301 --> loss:0.15152904987335206
step 121/275, epoch 7/301 --> loss:0.1330155611038208
step 131/275, epoch 7/301 --> loss:0.15724440813064575
step 141/275, epoch 7/301 --> loss:0.16128357052803038
step 151/275, epoch 7/301 --> loss:0.15092522501945496
step 161/275, epoch 7/301 --> loss:0.14898168444633483
step 171/275, epoch 7/301 --> loss:0.13892472982406617
step 181/275, epoch 7/301 --> loss:0.14633359909057617
step 191/275, epoch 7/301 --> loss:0.14279152154922486
step 201/275, epoch 7/301 --> loss:0.12593899965286254
step 211/275, epoch 7/301 --> loss:0.13164169192314149
step 221/275, epoch 7/301 --> loss:0.16174938082695006
step 231/275, epoch 7/301 --> loss:0.12578336000442505
step 241/275, epoch 7/301 --> loss:0.15820228457450866
step 251/275, epoch 7/301 --> loss:0.131321918964386
step 261/275, epoch 7/301 --> loss:0.15780983567237855
step 271/275, epoch 7/301 --> loss:0.12267836928367615
  3%|▎         | 8/301 [46:39<26:35:36, 326.75s/it]step 11/275, epoch 8/301 --> loss:0.1314890444278717
step 21/275, epoch 8/301 --> loss:0.1683802843093872
step 31/275, epoch 8/301 --> loss:0.16498395204544067
step 41/275, epoch 8/301 --> loss:0.1286171555519104
step 51/275, epoch 8/301 --> loss:0.13821030259132386
step 61/275, epoch 8/301 --> loss:0.14134466052055358
step 71/275, epoch 8/301 --> loss:0.12872838973999023
step 81/275, epoch 8/301 --> loss:0.1346199929714203
step 91/275, epoch 8/301 --> loss:0.1591540038585663
step 101/275, epoch 8/301 --> loss:0.16898611783981324
step 111/275, epoch 8/301 --> loss:0.13616583943367006
step 121/275, epoch 8/301 --> loss:0.14598963856697084
step 131/275, epoch 8/301 --> loss:0.1431917130947113
step 141/275, epoch 8/301 --> loss:0.12714065313339235
step 151/275, epoch 8/301 --> loss:0.1416789174079895
step 161/275, epoch 8/301 --> loss:0.1277604579925537
step 171/275, epoch 8/301 --> loss:0.13865251541137696
step 181/275, epoch 8/301 --> loss:0.13971444368362426
step 191/275, epoch 8/301 --> loss:0.12815316319465636
step 201/275, epoch 8/301 --> loss:0.12933142781257628
step 211/275, epoch 8/301 --> loss:0.1501043438911438
step 221/275, epoch 8/301 --> loss:0.10729189515113831
step 231/275, epoch 8/301 --> loss:0.1278272271156311
step 241/275, epoch 8/301 --> loss:0.1467638611793518
step 251/275, epoch 8/301 --> loss:0.1375629723072052
step 261/275, epoch 8/301 --> loss:0.1251414716243744
step 271/275, epoch 8/301 --> loss:0.12709758281707764
  3%|▎         | 9/301 [51:56<26:15:37, 323.76s/it]step 11/275, epoch 9/301 --> loss:0.12573838829994202
step 21/275, epoch 9/301 --> loss:0.14302777647972106
step 31/275, epoch 9/301 --> loss:0.1585923731327057
step 41/275, epoch 9/301 --> loss:0.1484753370285034
step 51/275, epoch 9/301 --> loss:0.1320604145526886
step 61/275, epoch 9/301 --> loss:0.1415183961391449
step 71/275, epoch 9/301 --> loss:0.1664925754070282
step 81/275, epoch 9/301 --> loss:0.14256731271743775
step 91/275, epoch 9/301 --> loss:0.13727691769599915
step 101/275, epoch 9/301 --> loss:0.13288440108299254
step 111/275, epoch 9/301 --> loss:0.16031166315078735
step 121/275, epoch 9/301 --> loss:0.14514822959899903
step 131/275, epoch 9/301 --> loss:0.1187707543373108
step 141/275, epoch 9/301 --> loss:0.15415900349617004
step 151/275, epoch 9/301 --> loss:0.11494696140289307
step 161/275, epoch 9/301 --> loss:0.12226135730743408
step 171/275, epoch 9/301 --> loss:0.1339699685573578
step 181/275, epoch 9/301 --> loss:0.12054479718208314
step 191/275, epoch 9/301 --> loss:0.12207662463188171
step 201/275, epoch 9/301 --> loss:0.16451968550682067
step 211/275, epoch 9/301 --> loss:0.1536652386188507
step 221/275, epoch 9/301 --> loss:0.1533370792865753
step 231/275, epoch 9/301 --> loss:0.16173848509788513
step 241/275, epoch 9/301 --> loss:0.11522457003593445
step 251/275, epoch 9/301 --> loss:0.13466516733169556
step 261/275, epoch 9/301 --> loss:0.1422666311264038
step 271/275, epoch 9/301 --> loss:0.12130768895149231
  3%|▎         | 10/301 [57:13<26:00:30, 321.75s/it]step 11/275, epoch 10/301 --> loss:0.1356888771057129
step 21/275, epoch 10/301 --> loss:0.13302191495895385
step 31/275, epoch 10/301 --> loss:0.147429895401001
step 41/275, epoch 10/301 --> loss:0.14028489589691162
step 51/275, epoch 10/301 --> loss:0.13112902045249938
step 61/275, epoch 10/301 --> loss:0.1545250952243805
step 71/275, epoch 10/301 --> loss:0.1392540752887726
step 81/275, epoch 10/301 --> loss:0.13319143652915955
step 91/275, epoch 10/301 --> loss:0.14442546367645265
step 101/275, epoch 10/301 --> loss:0.11277146935462952
step 111/275, epoch 10/301 --> loss:0.12892423272132875
step 121/275, epoch 10/301 --> loss:0.13957238793373108
step 131/275, epoch 10/301 --> loss:0.1162954568862915
step 141/275, epoch 10/301 --> loss:0.12508822083473206
step 151/275, epoch 10/301 --> loss:0.12130823731422424
step 161/275, epoch 10/301 --> loss:0.11435588598251342
step 171/275, epoch 10/301 --> loss:0.13884915113449098
step 181/275, epoch 10/301 --> loss:0.14633225202560424
step 191/275, epoch 10/301 --> loss:0.12814797163009645
step 201/275, epoch 10/301 --> loss:0.15954213738441467
step 211/275, epoch 10/301 --> loss:0.10808814764022827
step 221/275, epoch 10/301 --> loss:0.15138688087463378
step 231/275, epoch 10/301 --> loss:0.11773172616958619
step 241/275, epoch 10/301 --> loss:0.12888528108596803
step 251/275, epoch 10/301 --> loss:0.1264532208442688
step 261/275, epoch 10/301 --> loss:0.10597351789474488
step 271/275, epoch 10/301 --> loss:0.14199614524841309
step 11/275, epoch 11/301 --> loss:0.13111408948898315
step 21/275, epoch 11/301 --> loss:0.13565406799316407
step 31/275, epoch 11/301 --> loss:0.10910753011703492
step 41/275, epoch 11/301 --> loss:0.12015135884284973
step 51/275, epoch 11/301 --> loss:0.12510709166526796
step 61/275, epoch 11/301 --> loss:0.12771400809288025
step 71/275, epoch 11/301 --> loss:0.13825119137763978
step 81/275, epoch 11/301 --> loss:0.13316926956176758
step 91/275, epoch 11/301 --> loss:0.12790387272834777
step 101/275, epoch 11/301 --> loss:0.1350823998451233
step 111/275, epoch 11/301 --> loss:0.13851886987686157
step 121/275, epoch 11/301 --> loss:0.11951168179512024
step 131/275, epoch 11/301 --> loss:0.12854265570640563
step 141/275, epoch 11/301 --> loss:0.12787733674049379
step 151/275, epoch 11/301 --> loss:0.11996408104896546
step 161/275, epoch 11/301 --> loss:0.12978411316871644
step 171/275, epoch 11/301 --> loss:0.12878860235214235
step 181/275, epoch 11/301 --> loss:0.14385654926300048
step 191/275, epoch 11/301 --> loss:0.13090514540672302
step 201/275, epoch 11/301 --> loss:0.11993377208709717
step 211/275, epoch 11/301 --> loss:0.14242621064186095
step 221/275, epoch 11/301 --> loss:0.13754069209098815
step 231/275, epoch 11/301 --> loss:0.1663455367088318
step 241/275, epoch 11/301 --> loss:0.1335601329803467
step 251/275, epoch 11/301 --> loss:0.13123075366020204
step 261/275, epoch 11/301 --> loss:0.1304473340511322
step 271/275, epoch 11/301 --> loss:0.12002181410789489
########## train dataset ##########
PLout index:  2
acc -->  [89.82035203015602]
F1 -->  {'F1': [0.8761714672407915], 'precision': [0.8811641342391946], 'recall': [0.8712449456041399]}
########## eval dataset ##########
  4%|▎         | 11/301 [1:06:27<31:38:48, 392.86s/it]PLout index:  2
acc -->  [89.6519966662759]
F1 -->  {'F1': [0.8762128031981488], 'precision': [0.8855178582378775], 'recall': [0.8671110623828516]}
save model!
  4%|▍         | 12/301 [1:11:48<29:46:54, 370.99s/it]step 11/275, epoch 12/301 --> loss:0.12140274047851562
step 21/275, epoch 12/301 --> loss:0.12919539213180542
step 31/275, epoch 12/301 --> loss:0.1411445140838623
step 41/275, epoch 12/301 --> loss:0.12380244135856629
step 51/275, epoch 12/301 --> loss:0.1398772418498993
step 61/275, epoch 12/301 --> loss:0.12229598164558411
step 71/275, epoch 12/301 --> loss:0.12394322156906128
step 81/275, epoch 12/301 --> loss:0.14018497467041016
step 91/275, epoch 12/301 --> loss:0.11252522468566895
step 101/275, epoch 12/301 --> loss:0.11997612714767455
step 111/275, epoch 12/301 --> loss:0.14376842379570007
step 121/275, epoch 12/301 --> loss:0.12175016403198242
step 131/275, epoch 12/301 --> loss:0.13182123899459838
step 141/275, epoch 12/301 --> loss:0.13644851446151735
step 151/275, epoch 12/301 --> loss:0.13979898691177367
step 161/275, epoch 12/301 --> loss:0.13169339895248414
step 171/275, epoch 12/301 --> loss:0.1254323124885559
step 181/275, epoch 12/301 --> loss:0.12721454501152038
step 191/275, epoch 12/301 --> loss:0.1302199363708496
step 201/275, epoch 12/301 --> loss:0.12239907383918762
step 211/275, epoch 12/301 --> loss:0.11560115218162537
step 221/275, epoch 12/301 --> loss:0.12394105792045593
step 231/275, epoch 12/301 --> loss:0.11468327045440674
step 241/275, epoch 12/301 --> loss:0.12791541814804078
step 251/275, epoch 12/301 --> loss:0.11026597619056702
step 261/275, epoch 12/301 --> loss:0.12985124588012695
step 271/275, epoch 12/301 --> loss:0.15913227200508118
  4%|▍         | 13/301 [1:17:09<28:27:59, 355.83s/it]step 11/275, epoch 13/301 --> loss:0.14825086593627929
step 21/275, epoch 13/301 --> loss:0.15439972877502442
step 31/275, epoch 13/301 --> loss:0.15427764654159545
step 41/275, epoch 13/301 --> loss:0.14541893005371093
step 51/275, epoch 13/301 --> loss:0.1453410267829895
step 61/275, epoch 13/301 --> loss:0.11254416108131408
step 71/275, epoch 13/301 --> loss:0.1210561752319336
step 81/275, epoch 13/301 --> loss:0.11361131668090821
step 91/275, epoch 13/301 --> loss:0.12527592182159425
step 101/275, epoch 13/301 --> loss:0.0965042233467102
step 111/275, epoch 13/301 --> loss:0.09937962889671326
step 121/275, epoch 13/301 --> loss:0.13304686546325684
step 131/275, epoch 13/301 --> loss:0.13911111354827882
step 141/275, epoch 13/301 --> loss:0.1322701692581177
step 151/275, epoch 13/301 --> loss:0.14156134724617003
step 161/275, epoch 13/301 --> loss:0.14522114992141724
step 171/275, epoch 13/301 --> loss:0.1426770269870758
step 181/275, epoch 13/301 --> loss:0.12452048063278198
step 191/275, epoch 13/301 --> loss:0.13596605658531188
step 201/275, epoch 13/301 --> loss:0.13291080594062804
step 211/275, epoch 13/301 --> loss:0.12565364837646484
step 221/275, epoch 13/301 --> loss:0.11269049048423767
step 231/275, epoch 13/301 --> loss:0.12792762517929077
step 241/275, epoch 13/301 --> loss:0.10280537605285645
step 251/275, epoch 13/301 --> loss:0.1088502824306488
step 261/275, epoch 13/301 --> loss:0.11096363067626953
step 271/275, epoch 13/301 --> loss:0.1085336148738861
  5%|▍         | 14/301 [1:22:31<27:32:37, 345.50s/it]step 11/275, epoch 14/301 --> loss:0.1338493049144745
step 21/275, epoch 14/301 --> loss:0.1055513322353363
step 31/275, epoch 14/301 --> loss:0.1506028413772583
step 41/275, epoch 14/301 --> loss:0.11531118154525757
step 51/275, epoch 14/301 --> loss:0.12345778346061706
step 61/275, epoch 14/301 --> loss:0.11090375781059265
step 71/275, epoch 14/301 --> loss:0.10966779589653015
step 81/275, epoch 14/301 --> loss:0.11539313793182374
step 91/275, epoch 14/301 --> loss:0.13520891666412355
step 101/275, epoch 14/301 --> loss:0.1449154257774353
step 111/275, epoch 14/301 --> loss:0.11307513117790222
step 121/275, epoch 14/301 --> loss:0.11271492838859558
step 131/275, epoch 14/301 --> loss:0.11171061396598816
step 141/275, epoch 14/301 --> loss:0.10964382886886596
step 151/275, epoch 14/301 --> loss:0.13902652859687806
step 161/275, epoch 14/301 --> loss:0.12062348127365112
step 171/275, epoch 14/301 --> loss:0.12282306551933289
step 181/275, epoch 14/301 --> loss:0.1313115894794464
step 191/275, epoch 14/301 --> loss:0.1290137827396393
step 201/275, epoch 14/301 --> loss:0.10531505942344666
step 211/275, epoch 14/301 --> loss:0.12022170424461365
step 221/275, epoch 14/301 --> loss:0.12682936787605287
step 231/275, epoch 14/301 --> loss:0.153899621963501
step 241/275, epoch 14/301 --> loss:0.13051941990852356
step 251/275, epoch 14/301 --> loss:0.12266249656677246
step 261/275, epoch 14/301 --> loss:0.14305433630943298
step 271/275, epoch 14/301 --> loss:0.1230134129524231
  5%|▍         | 15/301 [1:27:54<26:54:16, 338.66s/it]step 11/275, epoch 15/301 --> loss:0.13312052488327025
step 21/275, epoch 15/301 --> loss:0.13584411144256592
step 31/275, epoch 15/301 --> loss:0.12830448150634766
step 41/275, epoch 15/301 --> loss:0.11687572002410888
step 51/275, epoch 15/301 --> loss:0.14107174277305604
step 61/275, epoch 15/301 --> loss:0.12620782256126403
step 71/275, epoch 15/301 --> loss:0.12331124544143676
step 81/275, epoch 15/301 --> loss:0.11440111994743347
step 91/275, epoch 15/301 --> loss:0.11253564357757569
step 101/275, epoch 15/301 --> loss:0.11963950395584107
step 111/275, epoch 15/301 --> loss:0.12819132208824158
step 121/275, epoch 15/301 --> loss:0.12958503365516663
step 131/275, epoch 15/301 --> loss:0.1276176393032074
step 141/275, epoch 15/301 --> loss:0.12362982034683227
step 151/275, epoch 15/301 --> loss:0.1261427640914917
step 161/275, epoch 15/301 --> loss:0.1335859477519989
step 171/275, epoch 15/301 --> loss:0.11422251462936402
step 181/275, epoch 15/301 --> loss:0.13875673413276673
step 191/275, epoch 15/301 --> loss:0.12009234428405761
step 201/275, epoch 15/301 --> loss:0.11161116361618043
step 211/275, epoch 15/301 --> loss:0.11424489617347718
step 221/275, epoch 15/301 --> loss:0.11914744973182678
step 231/275, epoch 15/301 --> loss:0.1195487380027771
step 241/275, epoch 15/301 --> loss:0.13192492127418518
step 251/275, epoch 15/301 --> loss:0.15156147480010987
step 261/275, epoch 15/301 --> loss:0.10752665400505065
step 271/275, epoch 15/301 --> loss:0.1141280174255371
  5%|▌         | 16/301 [1:33:16<26:25:59, 333.89s/it]step 11/275, epoch 16/301 --> loss:0.11972787380218505
step 21/275, epoch 16/301 --> loss:0.1493973672389984
step 31/275, epoch 16/301 --> loss:0.1219397246837616
step 41/275, epoch 16/301 --> loss:0.10443475842475891
step 51/275, epoch 16/301 --> loss:0.10243242383003234
step 61/275, epoch 16/301 --> loss:0.11007332801818848
step 71/275, epoch 16/301 --> loss:0.11240294575691223
step 81/275, epoch 16/301 --> loss:0.13159960508346558
step 91/275, epoch 16/301 --> loss:0.11952158808708191
step 101/275, epoch 16/301 --> loss:0.10509452819824219
step 111/275, epoch 16/301 --> loss:0.10686250925064086
step 121/275, epoch 16/301 --> loss:0.1272722840309143
step 131/275, epoch 16/301 --> loss:0.10941491723060608
step 141/275, epoch 16/301 --> loss:0.1087621033191681
step 151/275, epoch 16/301 --> loss:0.10631952285766602
step 161/275, epoch 16/301 --> loss:0.1387663960456848
step 171/275, epoch 16/301 --> loss:0.11366097331047058
step 181/275, epoch 16/301 --> loss:0.1238800048828125
step 191/275, epoch 16/301 --> loss:0.12524573802947997
step 201/275, epoch 16/301 --> loss:0.1275607168674469
step 211/275, epoch 16/301 --> loss:0.13833618760108948
step 221/275, epoch 16/301 --> loss:0.09410101771354676
step 231/275, epoch 16/301 --> loss:0.1291031539440155
step 241/275, epoch 16/301 --> loss:0.10529024600982666
step 251/275, epoch 16/301 --> loss:0.14489502906799318
step 261/275, epoch 16/301 --> loss:0.13889335989952087
step 271/275, epoch 16/301 --> loss:0.12422491908073426
  6%|▌         | 17/301 [1:38:36<25:59:39, 329.51s/it]step 11/275, epoch 17/301 --> loss:0.10787189602851868
step 21/275, epoch 17/301 --> loss:0.12135689854621887
step 31/275, epoch 17/301 --> loss:0.12616292834281922
step 41/275, epoch 17/301 --> loss:0.10884911417961121
step 51/275, epoch 17/301 --> loss:0.11885799169540405
step 61/275, epoch 17/301 --> loss:0.13508507013320922
step 71/275, epoch 17/301 --> loss:0.13124291896820067
step 81/275, epoch 17/301 --> loss:0.11656326055526733
step 91/275, epoch 17/301 --> loss:0.12237027287483215
step 101/275, epoch 17/301 --> loss:0.11056790351867676
step 111/275, epoch 17/301 --> loss:0.11339221000671387
step 121/275, epoch 17/301 --> loss:0.09388270378112792
step 131/275, epoch 17/301 --> loss:0.11196798086166382
step 141/275, epoch 17/301 --> loss:0.13035733699798585
step 151/275, epoch 17/301 --> loss:0.10336005687713623
step 161/275, epoch 17/301 --> loss:0.12397975325584412
step 171/275, epoch 17/301 --> loss:0.12376837730407715
step 181/275, epoch 17/301 --> loss:0.12224883437156678
step 191/275, epoch 17/301 --> loss:0.10709127187728881
step 201/275, epoch 17/301 --> loss:0.11209090948104858
step 211/275, epoch 17/301 --> loss:0.11126690506935119
step 221/275, epoch 17/301 --> loss:0.11258721351623535
step 231/275, epoch 17/301 --> loss:0.14592649340629577
step 241/275, epoch 17/301 --> loss:0.12174395322799683
step 251/275, epoch 17/301 --> loss:0.12148698568344116
step 261/275, epoch 17/301 --> loss:0.12950157523155212
step 271/275, epoch 17/301 --> loss:0.11722007393836975
  6%|▌         | 18/301 [1:43:53<25:36:21, 325.73s/it]step 11/275, epoch 18/301 --> loss:0.10793527364730834
step 21/275, epoch 18/301 --> loss:0.12517477869987487
step 31/275, epoch 18/301 --> loss:0.10870863199234009
step 41/275, epoch 18/301 --> loss:0.09790282845497131
step 51/275, epoch 18/301 --> loss:0.11228160858154297
step 61/275, epoch 18/301 --> loss:0.13283061385154724
step 71/275, epoch 18/301 --> loss:0.13203608989715576
step 81/275, epoch 18/301 --> loss:0.1277506947517395
step 91/275, epoch 18/301 --> loss:0.11676235198974609
step 101/275, epoch 18/301 --> loss:0.12977048754692078
step 111/275, epoch 18/301 --> loss:0.11903144121170044
step 121/275, epoch 18/301 --> loss:0.11811565160751343
step 131/275, epoch 18/301 --> loss:0.11537274122238159
step 141/275, epoch 18/301 --> loss:0.09817458391189575
step 151/275, epoch 18/301 --> loss:0.12497506737709045
step 161/275, epoch 18/301 --> loss:0.11166799068450928
step 171/275, epoch 18/301 --> loss:0.12816984653472902
step 181/275, epoch 18/301 --> loss:0.11651333570480346
step 191/275, epoch 18/301 --> loss:0.10889771580696106
step 201/275, epoch 18/301 --> loss:0.10253029465675353
step 211/275, epoch 18/301 --> loss:0.10733808875083924
step 221/275, epoch 18/301 --> loss:0.11605116128921508
step 231/275, epoch 18/301 --> loss:0.10811966061592101
step 241/275, epoch 18/301 --> loss:0.12029598355293274
step 251/275, epoch 18/301 --> loss:0.11885823607444763
step 261/275, epoch 18/301 --> loss:0.12962864637374877
step 271/275, epoch 18/301 --> loss:0.1305431306362152
  6%|▋         | 19/301 [1:49:10<25:18:41, 323.13s/it]step 11/275, epoch 19/301 --> loss:0.11139598488807678
step 21/275, epoch 19/301 --> loss:0.11664380431175232
step 31/275, epoch 19/301 --> loss:0.12330427169799804
step 41/275, epoch 19/301 --> loss:0.12753778100013732
step 51/275, epoch 19/301 --> loss:0.1054747760295868
step 61/275, epoch 19/301 --> loss:0.10766631960868836
step 71/275, epoch 19/301 --> loss:0.13121820092201233
step 81/275, epoch 19/301 --> loss:0.11306594610214234
step 91/275, epoch 19/301 --> loss:0.12139972448348998
step 101/275, epoch 19/301 --> loss:0.10570902228355408
step 111/275, epoch 19/301 --> loss:0.13155098557472228
step 121/275, epoch 19/301 --> loss:0.14097297191619873
step 131/275, epoch 19/301 --> loss:0.11895908117294311
step 141/275, epoch 19/301 --> loss:0.12361078262329102
step 151/275, epoch 19/301 --> loss:0.11358409523963928
step 161/275, epoch 19/301 --> loss:0.10770389437675476
step 171/275, epoch 19/301 --> loss:0.10460653901100159
step 181/275, epoch 19/301 --> loss:0.12486370801925659
step 191/275, epoch 19/301 --> loss:0.12793350219726562
step 201/275, epoch 19/301 --> loss:0.11379085183143615
step 211/275, epoch 19/301 --> loss:0.1191716730594635
step 221/275, epoch 19/301 --> loss:0.08932802677154542
step 231/275, epoch 19/301 --> loss:0.11667924523353576
step 241/275, epoch 19/301 --> loss:0.10559056401252746
step 251/275, epoch 19/301 --> loss:0.1337683916091919
step 261/275, epoch 19/301 --> loss:0.11507974863052368
step 271/275, epoch 19/301 --> loss:0.12386924624443055
  7%|▋         | 20/301 [1:54:27<25:05:27, 321.45s/it]step 11/275, epoch 20/301 --> loss:0.12185331583023071
step 21/275, epoch 20/301 --> loss:0.09448312520980835
step 31/275, epoch 20/301 --> loss:0.10802039504051208
step 41/275, epoch 20/301 --> loss:0.12525715231895446
step 51/275, epoch 20/301 --> loss:0.11969687938690185
step 61/275, epoch 20/301 --> loss:0.11101776361465454
step 71/275, epoch 20/301 --> loss:0.13046036958694457
step 81/275, epoch 20/301 --> loss:0.11239830255508423
step 91/275, epoch 20/301 --> loss:0.12109792232513428
step 101/275, epoch 20/301 --> loss:0.11058883666992188
step 111/275, epoch 20/301 --> loss:0.11406956911087036
step 121/275, epoch 20/301 --> loss:0.11924954056739807
step 131/275, epoch 20/301 --> loss:0.10395426750183105
step 141/275, epoch 20/301 --> loss:0.11333721876144409
step 151/275, epoch 20/301 --> loss:0.11726049780845642
step 161/275, epoch 20/301 --> loss:0.11061670184135437
step 171/275, epoch 20/301 --> loss:0.10826213359832763
step 181/275, epoch 20/301 --> loss:0.11176413893699647
step 191/275, epoch 20/301 --> loss:0.09942671060562133
step 201/275, epoch 20/301 --> loss:0.11658024191856384
step 211/275, epoch 20/301 --> loss:0.11184601783752442
step 221/275, epoch 20/301 --> loss:0.10984931588172912
step 231/275, epoch 20/301 --> loss:0.10907143950462342
step 241/275, epoch 20/301 --> loss:0.10522308349609374
step 251/275, epoch 20/301 --> loss:0.11655080914497376
step 261/275, epoch 20/301 --> loss:0.12659992575645446
step 271/275, epoch 20/301 --> loss:0.10490924715995789
step 11/275, epoch 21/301 --> loss:0.10461825728416443
step 21/275, epoch 21/301 --> loss:0.10553351044654846
step 31/275, epoch 21/301 --> loss:0.10577495098114013
step 41/275, epoch 21/301 --> loss:0.10601109266281128
step 51/275, epoch 21/301 --> loss:0.10438726544380188
step 61/275, epoch 21/301 --> loss:0.11806191802024842
step 71/275, epoch 21/301 --> loss:0.10359207987785339
step 81/275, epoch 21/301 --> loss:0.11801063418388366
step 91/275, epoch 21/301 --> loss:0.09850924611091613
step 101/275, epoch 21/301 --> loss:0.11178460121154785
step 111/275, epoch 21/301 --> loss:0.10879234075546265
step 121/275, epoch 21/301 --> loss:0.12865405678749084
step 131/275, epoch 21/301 --> loss:0.12470001578330994
step 141/275, epoch 21/301 --> loss:0.09347849488258361
step 151/275, epoch 21/301 --> loss:0.0999211847782135
step 161/275, epoch 21/301 --> loss:0.12005025744438172
step 171/275, epoch 21/301 --> loss:0.13922805190086365
step 181/275, epoch 21/301 --> loss:0.11606419086456299
step 191/275, epoch 21/301 --> loss:0.11200940012931823
step 201/275, epoch 21/301 --> loss:0.1252268671989441
step 211/275, epoch 21/301 --> loss:0.1235775351524353
step 221/275, epoch 21/301 --> loss:0.12828837633132933
step 231/275, epoch 21/301 --> loss:0.11530407667160034
step 241/275, epoch 21/301 --> loss:0.11068041920661927
step 251/275, epoch 21/301 --> loss:0.12660515904426575
step 261/275, epoch 21/301 --> loss:0.09430457353591919
step 271/275, epoch 21/301 --> loss:0.11079460382461548
########## train dataset ##########
PLout index:  2
acc -->  [83.4181162922017]
F1 -->  {'F1': [0.8234942561734475], 'precision': [0.7352818430593805], 'recall': [0.9357706937596513]}
########## eval dataset ##########
  7%|▋         | 21/301 [2:03:44<30:30:15, 392.20s/it]PLout index:  2
acc -->  [83.20542416943917]
F1 -->  {'F1': [0.8241722583994258], 'precision': [0.7387655943250778], 'recall': [0.931920146544285]}
  7%|▋         | 22/301 [2:09:06<28:44:37, 370.89s/it]step 11/275, epoch 22/301 --> loss:0.11223056316375732
step 21/275, epoch 22/301 --> loss:0.10825526714324951
step 31/275, epoch 22/301 --> loss:0.11768245100975036
step 41/275, epoch 22/301 --> loss:0.12637653350830078
step 51/275, epoch 22/301 --> loss:0.12891722917556764
step 61/275, epoch 22/301 --> loss:0.0950042188167572
step 71/275, epoch 22/301 --> loss:0.11176313757896424
step 81/275, epoch 22/301 --> loss:0.10806867480278015
step 91/275, epoch 22/301 --> loss:0.10898899435997009
step 101/275, epoch 22/301 --> loss:0.1049423336982727
step 111/275, epoch 22/301 --> loss:0.10753552913665772
step 121/275, epoch 22/301 --> loss:0.12928580045700072
step 131/275, epoch 22/301 --> loss:0.10940284132957459
step 141/275, epoch 22/301 --> loss:0.12065797448158264
step 151/275, epoch 22/301 --> loss:0.1202494740486145
step 161/275, epoch 22/301 --> loss:0.10003692507743836
step 171/275, epoch 22/301 --> loss:0.12227340340614319
step 181/275, epoch 22/301 --> loss:0.10467734932899475
step 191/275, epoch 22/301 --> loss:0.11125286817550659
step 201/275, epoch 22/301 --> loss:0.12770459651947022
step 211/275, epoch 22/301 --> loss:0.11049176454544067
step 221/275, epoch 22/301 --> loss:0.11375576257705688
step 231/275, epoch 22/301 --> loss:0.12541640400886536
step 241/275, epoch 22/301 --> loss:0.10657618641853332
step 251/275, epoch 22/301 --> loss:0.106083744764328
step 261/275, epoch 22/301 --> loss:0.10784997940063476
step 271/275, epoch 22/301 --> loss:0.1194379985332489
  8%|▊         | 23/301 [2:14:26<27:28:47, 355.85s/it]step 11/275, epoch 23/301 --> loss:0.11532614827156067
step 21/275, epoch 23/301 --> loss:0.10740740299224853
step 31/275, epoch 23/301 --> loss:0.12769227027893065
step 41/275, epoch 23/301 --> loss:0.10708937644958497
step 51/275, epoch 23/301 --> loss:0.10063328742980956
step 61/275, epoch 23/301 --> loss:0.11659241914749145
step 71/275, epoch 23/301 --> loss:0.1319075882434845
step 81/275, epoch 23/301 --> loss:0.13640366196632386
step 91/275, epoch 23/301 --> loss:0.1301455795764923
step 101/275, epoch 23/301 --> loss:0.1233875572681427
step 111/275, epoch 23/301 --> loss:0.1078728199005127
step 121/275, epoch 23/301 --> loss:0.10337887406349182
step 131/275, epoch 23/301 --> loss:0.10933408737182618
step 141/275, epoch 23/301 --> loss:0.13235835433006288
step 151/275, epoch 23/301 --> loss:0.1204218864440918
step 161/275, epoch 23/301 --> loss:0.1396206796169281
step 171/275, epoch 23/301 --> loss:0.10949347615242004
step 181/275, epoch 23/301 --> loss:0.12027027606964111
step 191/275, epoch 23/301 --> loss:0.13334768414497375
step 201/275, epoch 23/301 --> loss:0.09841750860214234
step 211/275, epoch 23/301 --> loss:0.11901665329933167
step 221/275, epoch 23/301 --> loss:0.12968797683715821
step 231/275, epoch 23/301 --> loss:0.10532525777816773
step 241/275, epoch 23/301 --> loss:0.13152379393577576
step 251/275, epoch 23/301 --> loss:0.12155217528343201
step 261/275, epoch 23/301 --> loss:0.0950792133808136
step 271/275, epoch 23/301 --> loss:0.09253522753715515
  8%|▊         | 24/301 [2:19:47<26:34:40, 345.42s/it]step 11/275, epoch 24/301 --> loss:0.10790263414382935
step 21/275, epoch 24/301 --> loss:0.10956551432609558
step 31/275, epoch 24/301 --> loss:0.09431554675102234
step 41/275, epoch 24/301 --> loss:0.11203919053077697
step 51/275, epoch 24/301 --> loss:0.10772077441215515
step 61/275, epoch 24/301 --> loss:0.10998688936233521
step 71/275, epoch 24/301 --> loss:0.12047293782234192
step 81/275, epoch 24/301 --> loss:0.10184946060180664
step 91/275, epoch 24/301 --> loss:0.11683055758476257
step 101/275, epoch 24/301 --> loss:0.11689136624336242
step 111/275, epoch 24/301 --> loss:0.11271389126777649
step 121/275, epoch 24/301 --> loss:0.1053478479385376
step 131/275, epoch 24/301 --> loss:0.1029040515422821
step 141/275, epoch 24/301 --> loss:0.11968362927436829
step 151/275, epoch 24/301 --> loss:0.11428297758102417
step 161/275, epoch 24/301 --> loss:0.10748667120933533
step 171/275, epoch 24/301 --> loss:0.12251882553100586
step 181/275, epoch 24/301 --> loss:0.11677811145782471
step 191/275, epoch 24/301 --> loss:0.11514661312103272
step 201/275, epoch 24/301 --> loss:0.10843958258628845
step 211/275, epoch 24/301 --> loss:0.11972919702529908
step 221/275, epoch 24/301 --> loss:0.11180292367935181
step 231/275, epoch 24/301 --> loss:0.10911809802055358
step 241/275, epoch 24/301 --> loss:0.08848031163215637
step 251/275, epoch 24/301 --> loss:0.12122096419334412
step 261/275, epoch 24/301 --> loss:0.0813046395778656
step 271/275, epoch 24/301 --> loss:0.10167202353477478
  8%|▊         | 25/301 [2:25:09<25:55:29, 338.15s/it]step 11/275, epoch 25/301 --> loss:0.11754000186920166
step 21/275, epoch 25/301 --> loss:0.12336986064910889
step 31/275, epoch 25/301 --> loss:0.12883661389350892
step 41/275, epoch 25/301 --> loss:0.1108400583267212
step 51/275, epoch 25/301 --> loss:0.11765748262405396
step 61/275, epoch 25/301 --> loss:0.1123847246170044
step 71/275, epoch 25/301 --> loss:0.11281946301460266
step 81/275, epoch 25/301 --> loss:0.11399785876274109
step 91/275, epoch 25/301 --> loss:0.09877345561981202
step 101/275, epoch 25/301 --> loss:0.11638136506080628
step 111/275, epoch 25/301 --> loss:0.11849316358566284
step 121/275, epoch 25/301 --> loss:0.10138465166091919
step 131/275, epoch 25/301 --> loss:0.12259029150009156
step 141/275, epoch 25/301 --> loss:0.10751850008964539
step 151/275, epoch 25/301 --> loss:0.10330274105072021
step 161/275, epoch 25/301 --> loss:0.10862860679626465
step 171/275, epoch 25/301 --> loss:0.11103531122207641
step 181/275, epoch 25/301 --> loss:0.12211052775382995
step 191/275, epoch 25/301 --> loss:0.10177251696586609
step 201/275, epoch 25/301 --> loss:0.10128012895584107
step 211/275, epoch 25/301 --> loss:0.10860609412193298
step 221/275, epoch 25/301 --> loss:0.12233765721321106
step 231/275, epoch 25/301 --> loss:0.1087664544582367
step 241/275, epoch 25/301 --> loss:0.11272391676902771
step 251/275, epoch 25/301 --> loss:0.13152135014533997
step 261/275, epoch 25/301 --> loss:0.10586877465248108
step 271/275, epoch 25/301 --> loss:0.09741291999816895
  9%|▊         | 26/301 [2:30:30<25:26:57, 333.15s/it]step 11/275, epoch 26/301 --> loss:0.10655127167701721
step 21/275, epoch 26/301 --> loss:0.10716967582702637
step 31/275, epoch 26/301 --> loss:0.10837412476539612
step 41/275, epoch 26/301 --> loss:0.1140100598335266
step 51/275, epoch 26/301 --> loss:0.09119307994842529
step 61/275, epoch 26/301 --> loss:0.09464295506477356
step 71/275, epoch 26/301 --> loss:0.10275624990463257
step 81/275, epoch 26/301 --> loss:0.12134875655174256
step 91/275, epoch 26/301 --> loss:0.12231482863426209
step 101/275, epoch 26/301 --> loss:0.119904625415802
step 111/275, epoch 26/301 --> loss:0.11603612303733826
step 121/275, epoch 26/301 --> loss:0.125660240650177
step 131/275, epoch 26/301 --> loss:0.10346969962120056
step 141/275, epoch 26/301 --> loss:0.1030568778514862
step 151/275, epoch 26/301 --> loss:0.11795535683631897
step 161/275, epoch 26/301 --> loss:0.10642859935760499
step 171/275, epoch 26/301 --> loss:0.10805040001869201
step 181/275, epoch 26/301 --> loss:0.11351611018180847
step 191/275, epoch 26/301 --> loss:0.11272887587547302
step 201/275, epoch 26/301 --> loss:0.10160041451454163
step 211/275, epoch 26/301 --> loss:0.09616512060165405
step 221/275, epoch 26/301 --> loss:0.10632762312889099
step 231/275, epoch 26/301 --> loss:0.11906746029853821
step 241/275, epoch 26/301 --> loss:0.08856446146965027
step 251/275, epoch 26/301 --> loss:0.10126188397407532
step 261/275, epoch 26/301 --> loss:0.10765783190727234
step 271/275, epoch 26/301 --> loss:0.10571056604385376
  9%|▉         | 27/301 [2:35:51<25:04:49, 329.53s/it]step 11/275, epoch 27/301 --> loss:0.11396733522415162
step 21/275, epoch 27/301 --> loss:0.11394221782684326
step 31/275, epoch 27/301 --> loss:0.1268148183822632
step 41/275, epoch 27/301 --> loss:0.09905480742454528
step 51/275, epoch 27/301 --> loss:0.11708877086639405
step 61/275, epoch 27/301 --> loss:0.1162286102771759
step 71/275, epoch 27/301 --> loss:0.08943042755126954
step 81/275, epoch 27/301 --> loss:0.09631099700927734
step 91/275, epoch 27/301 --> loss:0.11751675605773926
step 101/275, epoch 27/301 --> loss:0.08375016450881959
step 111/275, epoch 27/301 --> loss:0.10789937376976014
step 121/275, epoch 27/301 --> loss:0.113314688205719
step 131/275, epoch 27/301 --> loss:0.10539979934692383
step 141/275, epoch 27/301 --> loss:0.10639839172363282
step 151/275, epoch 27/301 --> loss:0.1083620011806488
step 161/275, epoch 27/301 --> loss:0.11340495944023132
step 171/275, epoch 27/301 --> loss:0.11665468215942383
step 181/275, epoch 27/301 --> loss:0.10275631546974182
step 191/275, epoch 27/301 --> loss:0.11590034365653992
step 201/275, epoch 27/301 --> loss:0.09816102385520935
step 211/275, epoch 27/301 --> loss:0.09861511588096619
step 221/275, epoch 27/301 --> loss:0.08917805552482605
step 231/275, epoch 27/301 --> loss:0.13377211689949037
step 241/275, epoch 27/301 --> loss:0.09988231658935547
step 251/275, epoch 27/301 --> loss:0.10368287563323975
step 261/275, epoch 27/301 --> loss:0.10393669605255126
step 271/275, epoch 27/301 --> loss:0.09777406454086304
  9%|▉         | 28/301 [2:41:09<24:43:07, 325.96s/it]step 11/275, epoch 28/301 --> loss:0.11112584471702576
step 21/275, epoch 28/301 --> loss:0.11176286339759826
step 31/275, epoch 28/301 --> loss:0.09357924461364746
step 41/275, epoch 28/301 --> loss:0.11021799445152283
step 51/275, epoch 28/301 --> loss:0.09623563885688782
step 61/275, epoch 28/301 --> loss:0.10368650555610656
step 71/275, epoch 28/301 --> loss:0.11831345558166503
step 81/275, epoch 28/301 --> loss:0.11775931119918823
step 91/275, epoch 28/301 --> loss:0.10173538327217102
step 101/275, epoch 28/301 --> loss:0.09402695894241334
step 111/275, epoch 28/301 --> loss:0.10290817618370056
step 121/275, epoch 28/301 --> loss:0.10834805965423584
step 131/275, epoch 28/301 --> loss:0.10065785646438599
step 141/275, epoch 28/301 --> loss:0.08609414696693421
step 151/275, epoch 28/301 --> loss:0.11337184309959411
step 161/275, epoch 28/301 --> loss:0.11045950651168823
step 171/275, epoch 28/301 --> loss:0.10022250413894654
step 181/275, epoch 28/301 --> loss:0.14475465416908265
step 191/275, epoch 28/301 --> loss:0.10865401029586792
step 201/275, epoch 28/301 --> loss:0.1097860336303711
step 211/275, epoch 28/301 --> loss:0.10020930171012879
step 221/275, epoch 28/301 --> loss:0.10255602598190308
step 231/275, epoch 28/301 --> loss:0.11436513662338257
step 241/275, epoch 28/301 --> loss:0.10743516683578491
step 251/275, epoch 28/301 --> loss:0.12043382525444031
step 261/275, epoch 28/301 --> loss:0.10884958505630493
step 271/275, epoch 28/301 --> loss:0.11863700747489929
 10%|▉         | 29/301 [2:46:26<24:25:51, 323.35s/it]step 11/275, epoch 29/301 --> loss:0.09793951511383056
step 21/275, epoch 29/301 --> loss:0.11515995860099792
step 31/275, epoch 29/301 --> loss:0.09260674715042114
step 41/275, epoch 29/301 --> loss:0.12185235619544983
step 51/275, epoch 29/301 --> loss:0.111170095205307
step 61/275, epoch 29/301 --> loss:0.09140804409980774
step 71/275, epoch 29/301 --> loss:0.09982120990753174
step 81/275, epoch 29/301 --> loss:0.10333476662635803
step 91/275, epoch 29/301 --> loss:0.107151859998703
step 101/275, epoch 29/301 --> loss:0.11099784374237061
step 111/275, epoch 29/301 --> loss:0.11283622980117798
step 121/275, epoch 29/301 --> loss:0.10035827159881591
step 131/275, epoch 29/301 --> loss:0.10840534567832946
step 141/275, epoch 29/301 --> loss:0.10778534412384033
step 151/275, epoch 29/301 --> loss:0.09920644760131836
step 161/275, epoch 29/301 --> loss:0.10090248584747315
step 171/275, epoch 29/301 --> loss:0.10382307171821595
step 181/275, epoch 29/301 --> loss:0.09914157390594483
step 191/275, epoch 29/301 --> loss:0.1112496554851532
step 201/275, epoch 29/301 --> loss:0.08772256970405579
step 211/275, epoch 29/301 --> loss:0.1197438657283783
step 221/275, epoch 29/301 --> loss:0.12204217910766602
step 231/275, epoch 29/301 --> loss:0.10767439007759094
step 241/275, epoch 29/301 --> loss:0.08785609602928161
step 251/275, epoch 29/301 --> loss:0.1199999988079071
step 261/275, epoch 29/301 --> loss:0.10859676599502563
step 271/275, epoch 29/301 --> loss:0.12831698656082152
 10%|▉         | 30/301 [2:51:44<24:12:27, 321.58s/it]step 11/275, epoch 30/301 --> loss:0.08817529678344727
step 21/275, epoch 30/301 --> loss:0.104509836435318
step 31/275, epoch 30/301 --> loss:0.097553551197052
step 41/275, epoch 30/301 --> loss:0.08817574977874756
step 51/275, epoch 30/301 --> loss:0.12376992702484131
step 61/275, epoch 30/301 --> loss:0.10543819665908813
step 71/275, epoch 30/301 --> loss:0.09618473649024964
step 81/275, epoch 30/301 --> loss:0.09475586414337159
step 91/275, epoch 30/301 --> loss:0.09413476586341858
step 101/275, epoch 30/301 --> loss:0.1207590639591217
step 111/275, epoch 30/301 --> loss:0.11389076709747314
step 121/275, epoch 30/301 --> loss:0.12214828729629516
step 131/275, epoch 30/301 --> loss:0.09455885291099549
step 141/275, epoch 30/301 --> loss:0.12821876406669616
step 151/275, epoch 30/301 --> loss:0.11207854151725768
step 161/275, epoch 30/301 --> loss:0.0955644965171814
step 171/275, epoch 30/301 --> loss:0.10985925793647766
step 181/275, epoch 30/301 --> loss:0.102227121591568
step 191/275, epoch 30/301 --> loss:0.09388824105262757
step 201/275, epoch 30/301 --> loss:0.1213938057422638
step 211/275, epoch 30/301 --> loss:0.10747085213661194
step 221/275, epoch 30/301 --> loss:0.10567858219146728
step 231/275, epoch 30/301 --> loss:0.09859700798988343
step 241/275, epoch 30/301 --> loss:0.11056118607521057
step 251/275, epoch 30/301 --> loss:0.09222128391265869
step 261/275, epoch 30/301 --> loss:0.12677695155143737
step 271/275, epoch 30/301 --> loss:0.09987176656723022
step 11/275, epoch 31/301 --> loss:0.09379826784133911
step 21/275, epoch 31/301 --> loss:0.09267587065696717
step 31/275, epoch 31/301 --> loss:0.09656341075897217
step 41/275, epoch 31/301 --> loss:0.08347802758216857
step 51/275, epoch 31/301 --> loss:0.11773194670677185
step 61/275, epoch 31/301 --> loss:0.11216638088226319
step 71/275, epoch 31/301 --> loss:0.10672279596328735
step 81/275, epoch 31/301 --> loss:0.11808651089668273
step 91/275, epoch 31/301 --> loss:0.09526455402374268
step 101/275, epoch 31/301 --> loss:0.10221211910247803
step 111/275, epoch 31/301 --> loss:0.08627418875694275
step 121/275, epoch 31/301 --> loss:0.08870053291320801
step 131/275, epoch 31/301 --> loss:0.1062017023563385
step 141/275, epoch 31/301 --> loss:0.10226544737815857
step 151/275, epoch 31/301 --> loss:0.11954947710037231
step 161/275, epoch 31/301 --> loss:0.12238111495971679
step 171/275, epoch 31/301 --> loss:0.12221835255622863
step 181/275, epoch 31/301 --> loss:0.10527964234352112
step 191/275, epoch 31/301 --> loss:0.10593833327293396
step 201/275, epoch 31/301 --> loss:0.1179354190826416
step 211/275, epoch 31/301 --> loss:0.10074513554573059
step 221/275, epoch 31/301 --> loss:0.10189538598060607
step 231/275, epoch 31/301 --> loss:0.1083044707775116
step 241/275, epoch 31/301 --> loss:0.09810564517974854
step 251/275, epoch 31/301 --> loss:0.11304922699928284
step 261/275, epoch 31/301 --> loss:0.09115145802497863
step 271/275, epoch 31/301 --> loss:0.09632733464241028
########## train dataset ##########
PLout index:  2
acc -->  [91.87829603760271]
F1 -->  {'F1': [0.9029115907061507], 'precision': [0.892454468034581], 'recall': [0.913626913639026]}
########## eval dataset ##########
 10%|█         | 31/301 [3:01:02<29:27:03, 392.68s/it]PLout index:  2
acc -->  [91.2839848425684]
F1 -->  {'F1': [0.8977521602341494], 'precision': [0.8897031220209749], 'recall': [0.9059583480102434]}
save model!
 11%|█         | 32/301 [3:06:25<27:46:27, 371.70s/it]step 11/275, epoch 32/301 --> loss:0.10899685025215149
step 21/275, epoch 32/301 --> loss:0.10749812126159668
step 31/275, epoch 32/301 --> loss:0.10050534605979919
step 41/275, epoch 32/301 --> loss:0.11492607593536378
step 51/275, epoch 32/301 --> loss:0.09871012568473816
step 61/275, epoch 32/301 --> loss:0.09787598252296448
step 71/275, epoch 32/301 --> loss:0.09900107383728027
step 81/275, epoch 32/301 --> loss:0.09780415296554565
step 91/275, epoch 32/301 --> loss:0.11379649043083191
step 101/275, epoch 32/301 --> loss:0.11655672192573548
step 111/275, epoch 32/301 --> loss:0.11157511472702027
step 121/275, epoch 32/301 --> loss:0.11389394402503968
step 131/275, epoch 32/301 --> loss:0.10569003224372864
step 141/275, epoch 32/301 --> loss:0.09526976943016052
step 151/275, epoch 32/301 --> loss:0.09582809209823609
step 161/275, epoch 32/301 --> loss:0.10583869218826295
step 171/275, epoch 32/301 --> loss:0.09405852556228637
step 181/275, epoch 32/301 --> loss:0.10503170490264893
step 191/275, epoch 32/301 --> loss:0.10701368451118469
step 201/275, epoch 32/301 --> loss:0.1143530249595642
step 211/275, epoch 32/301 --> loss:0.09811760187149048
step 221/275, epoch 32/301 --> loss:0.11489013433456421
step 231/275, epoch 32/301 --> loss:0.11722533106803894
step 241/275, epoch 32/301 --> loss:0.1008930742740631
step 251/275, epoch 32/301 --> loss:0.10381498336791992
step 261/275, epoch 32/301 --> loss:0.08929910063743592
step 271/275, epoch 32/301 --> loss:0.08317919969558715
 11%|█         | 33/301 [3:11:48<26:34:48, 357.05s/it]step 11/275, epoch 33/301 --> loss:0.12586780786514282
step 21/275, epoch 33/301 --> loss:0.10840997099876404
step 31/275, epoch 33/301 --> loss:0.10962825417518615
step 41/275, epoch 33/301 --> loss:0.11672132611274719
step 51/275, epoch 33/301 --> loss:0.06971606612205505
step 61/275, epoch 33/301 --> loss:0.10691239833831787
step 71/275, epoch 33/301 --> loss:0.10165832638740539
step 81/275, epoch 33/301 --> loss:0.0978841245174408
step 91/275, epoch 33/301 --> loss:0.10298013687133789
step 101/275, epoch 33/301 --> loss:0.1169606626033783
step 111/275, epoch 33/301 --> loss:0.10349841117858886
step 121/275, epoch 33/301 --> loss:0.10939581394195556
step 131/275, epoch 33/301 --> loss:0.11158344149589539
step 141/275, epoch 33/301 --> loss:0.08930057287216187
step 151/275, epoch 33/301 --> loss:0.09723283648490906
step 161/275, epoch 33/301 --> loss:0.1311889410018921
step 171/275, epoch 33/301 --> loss:0.10170304775238037
step 181/275, epoch 33/301 --> loss:0.10713842511177063
step 191/275, epoch 33/301 --> loss:0.10459893941879272
step 201/275, epoch 33/301 --> loss:0.12290822267532349
step 211/275, epoch 33/301 --> loss:0.08709586262702942
step 221/275, epoch 33/301 --> loss:0.10806469917297364
step 231/275, epoch 33/301 --> loss:0.09079409241676331
step 241/275, epoch 33/301 --> loss:0.12151824831962585
step 251/275, epoch 33/301 --> loss:0.10012366771697997
step 261/275, epoch 33/301 --> loss:0.10940302610397339
step 271/275, epoch 33/301 --> loss:0.09349551796913147
 11%|█▏        | 34/301 [3:17:09<25:41:15, 346.35s/it]step 11/275, epoch 34/301 --> loss:0.0989881694316864
step 21/275, epoch 34/301 --> loss:0.09786028861999511
step 31/275, epoch 34/301 --> loss:0.0870701789855957
step 41/275, epoch 34/301 --> loss:0.10427054166793823
step 51/275, epoch 34/301 --> loss:0.0839260995388031
step 61/275, epoch 34/301 --> loss:0.10692508220672607
step 71/275, epoch 34/301 --> loss:0.09889445304870606
step 81/275, epoch 34/301 --> loss:0.10285443067550659
step 91/275, epoch 34/301 --> loss:0.08915122151374817
step 101/275, epoch 34/301 --> loss:0.09668400883674622
step 111/275, epoch 34/301 --> loss:0.11383225917816162
step 121/275, epoch 34/301 --> loss:0.08932623267173767
step 131/275, epoch 34/301 --> loss:0.09108456373214721
step 141/275, epoch 34/301 --> loss:0.08857651352882386
step 151/275, epoch 34/301 --> loss:0.11144129633903503
step 161/275, epoch 34/301 --> loss:0.09950089454650879
step 171/275, epoch 34/301 --> loss:0.12087328433990478
step 181/275, epoch 34/301 --> loss:0.0970836877822876
step 191/275, epoch 34/301 --> loss:0.10541625618934632
step 201/275, epoch 34/301 --> loss:0.10536314249038696
step 211/275, epoch 34/301 --> loss:0.10842939019203186
step 221/275, epoch 34/301 --> loss:0.10464515686035156
step 231/275, epoch 34/301 --> loss:0.10631333589553833
step 241/275, epoch 34/301 --> loss:0.089757639169693
step 251/275, epoch 34/301 --> loss:0.11918455362319946
step 261/275, epoch 34/301 --> loss:0.08420683145523071
step 271/275, epoch 34/301 --> loss:0.0965712308883667
 12%|█▏        | 35/301 [3:22:27<24:57:57, 337.89s/it]step 11/275, epoch 35/301 --> loss:0.10752471089363098
step 21/275, epoch 35/301 --> loss:0.09568440318107604
step 31/275, epoch 35/301 --> loss:0.0908801257610321
step 41/275, epoch 35/301 --> loss:0.09821003079414367
step 51/275, epoch 35/301 --> loss:0.08800389170646668
step 61/275, epoch 35/301 --> loss:0.10783910751342773
step 71/275, epoch 35/301 --> loss:0.1261711001396179
step 81/275, epoch 35/301 --> loss:0.09428971409797668
step 91/275, epoch 35/301 --> loss:0.10373645424842834
step 101/275, epoch 35/301 --> loss:0.10915161371231079
step 111/275, epoch 35/301 --> loss:0.08236388564109802
step 121/275, epoch 35/301 --> loss:0.08510720729827881
step 131/275, epoch 35/301 --> loss:0.10961032509803773
step 141/275, epoch 35/301 --> loss:0.1137677252292633
step 151/275, epoch 35/301 --> loss:0.12073317170143127
step 161/275, epoch 35/301 --> loss:0.12284976243972778
step 171/275, epoch 35/301 --> loss:0.09984384775161743
step 181/275, epoch 35/301 --> loss:0.1134037971496582
step 191/275, epoch 35/301 --> loss:0.10024356842041016
step 201/275, epoch 35/301 --> loss:0.09021019339561462
step 211/275, epoch 35/301 --> loss:0.09520779252052307
step 221/275, epoch 35/301 --> loss:0.13033984303474427
step 231/275, epoch 35/301 --> loss:0.09923821687698364
step 241/275, epoch 35/301 --> loss:0.0923802137374878
step 251/275, epoch 35/301 --> loss:0.11131818294525146
step 261/275, epoch 35/301 --> loss:0.09353344440460205
step 271/275, epoch 35/301 --> loss:0.09906048178672791
 12%|█▏        | 36/301 [3:27:44<24:24:49, 331.66s/it]step 11/275, epoch 36/301 --> loss:0.10051934719085694
step 21/275, epoch 36/301 --> loss:0.11652986407279968
step 31/275, epoch 36/301 --> loss:0.09674031734466552
step 41/275, epoch 36/301 --> loss:0.11328339576721191
step 51/275, epoch 36/301 --> loss:0.10291129350662231
step 61/275, epoch 36/301 --> loss:0.1122476577758789
step 71/275, epoch 36/301 --> loss:0.08953885436058044
step 81/275, epoch 36/301 --> loss:0.09170005321502686
step 91/275, epoch 36/301 --> loss:0.09543929696083069
step 101/275, epoch 36/301 --> loss:0.09520456790924073
step 111/275, epoch 36/301 --> loss:0.09847942590713502
step 121/275, epoch 36/301 --> loss:0.09823084473609925
step 131/275, epoch 36/301 --> loss:0.09726441502571107
step 141/275, epoch 36/301 --> loss:0.10402320623397827
step 151/275, epoch 36/301 --> loss:0.0878695547580719
step 161/275, epoch 36/301 --> loss:0.12035641670227051
step 171/275, epoch 36/301 --> loss:0.11481819152832032
step 181/275, epoch 36/301 --> loss:0.09732204675674438
step 191/275, epoch 36/301 --> loss:0.10843423008918762
step 201/275, epoch 36/301 --> loss:0.09836142659187316
step 211/275, epoch 36/301 --> loss:0.10514152646064759
step 221/275, epoch 36/301 --> loss:0.08661438226699829
step 231/275, epoch 36/301 --> loss:0.09525294303894043
step 241/275, epoch 36/301 --> loss:0.10578156113624573
step 251/275, epoch 36/301 --> loss:0.09128940105438232
step 261/275, epoch 36/301 --> loss:0.10138833522796631
step 271/275, epoch 36/301 --> loss:0.09085161089897156
 12%|█▏        | 37/301 [3:33:01<24:00:06, 327.30s/it]step 11/275, epoch 37/301 --> loss:0.09254012107849122
step 21/275, epoch 37/301 --> loss:0.09693992137908936
step 31/275, epoch 37/301 --> loss:0.11218265891075134
step 41/275, epoch 37/301 --> loss:0.11057443022727967
step 51/275, epoch 37/301 --> loss:0.1056056022644043
step 61/275, epoch 37/301 --> loss:0.09830518960952758
step 71/275, epoch 37/301 --> loss:0.09916282892227173
step 81/275, epoch 37/301 --> loss:0.10500385165214539
step 91/275, epoch 37/301 --> loss:0.09879699349403381
step 101/275, epoch 37/301 --> loss:0.09617183208465577
step 111/275, epoch 37/301 --> loss:0.08531016111373901
step 121/275, epoch 37/301 --> loss:0.10955221652984619
step 131/275, epoch 37/301 --> loss:0.10802317857742309
step 141/275, epoch 37/301 --> loss:0.10163507461547852
step 151/275, epoch 37/301 --> loss:0.10035728812217712
step 161/275, epoch 37/301 --> loss:0.1375745415687561
step 171/275, epoch 37/301 --> loss:0.10121318101882934
step 181/275, epoch 37/301 --> loss:0.10156432390213013
step 191/275, epoch 37/301 --> loss:0.0955783486366272
step 201/275, epoch 37/301 --> loss:0.08327603340148926
step 211/275, epoch 37/301 --> loss:0.10166203379631042
step 221/275, epoch 37/301 --> loss:0.08560201525688171
step 231/275, epoch 37/301 --> loss:0.1053905427455902
step 241/275, epoch 37/301 --> loss:0.0943964183330536
step 251/275, epoch 37/301 --> loss:0.10176584124565125
step 261/275, epoch 37/301 --> loss:0.10249062180519104
step 271/275, epoch 37/301 --> loss:0.09525490999221801
 13%|█▎        | 38/301 [3:38:19<23:42:21, 324.49s/it]step 11/275, epoch 38/301 --> loss:0.0922873318195343
step 21/275, epoch 38/301 --> loss:0.09633436799049377
step 31/275, epoch 38/301 --> loss:0.11105905175209045
step 41/275, epoch 38/301 --> loss:0.09723286628723145
step 51/275, epoch 38/301 --> loss:0.09313446879386902
step 61/275, epoch 38/301 --> loss:0.08863412141799927
step 71/275, epoch 38/301 --> loss:0.10072685480117798
step 81/275, epoch 38/301 --> loss:0.10730332136154175
step 91/275, epoch 38/301 --> loss:0.10125382542610169
step 101/275, epoch 38/301 --> loss:0.10416548252105713
step 111/275, epoch 38/301 --> loss:0.09865972399711609
step 121/275, epoch 38/301 --> loss:0.10444912910461426
step 131/275, epoch 38/301 --> loss:0.09038965702056885
step 141/275, epoch 38/301 --> loss:0.09832156896591186
step 151/275, epoch 38/301 --> loss:0.10003437399864197
step 161/275, epoch 38/301 --> loss:0.12326242923736572
step 171/275, epoch 38/301 --> loss:0.10060598850250244
step 181/275, epoch 38/301 --> loss:0.08318040370941163
step 191/275, epoch 38/301 --> loss:0.09678552746772766
step 201/275, epoch 38/301 --> loss:0.08953480124473571
step 211/275, epoch 38/301 --> loss:0.09577144384384155
step 221/275, epoch 38/301 --> loss:0.09593800306320191
step 231/275, epoch 38/301 --> loss:0.1143319547176361
step 241/275, epoch 38/301 --> loss:0.09277378916740417
step 251/275, epoch 38/301 --> loss:0.09586135149002076
step 261/275, epoch 38/301 --> loss:0.09568862915039063
step 271/275, epoch 38/301 --> loss:0.08804994225502014
 13%|█▎        | 39/301 [3:43:40<23:31:17, 323.20s/it]step 11/275, epoch 39/301 --> loss:0.09919739961624145
step 21/275, epoch 39/301 --> loss:0.1045756220817566
step 31/275, epoch 39/301 --> loss:0.10122199654579163
step 41/275, epoch 39/301 --> loss:0.074529367685318
step 51/275, epoch 39/301 --> loss:0.09499849081039428
step 61/275, epoch 39/301 --> loss:0.08714178204536438
step 71/275, epoch 39/301 --> loss:0.12208252549171447
step 81/275, epoch 39/301 --> loss:0.0936346173286438
step 91/275, epoch 39/301 --> loss:0.09354750514030456
step 101/275, epoch 39/301 --> loss:0.10562555193901062
step 111/275, epoch 39/301 --> loss:0.10504375100135803
step 121/275, epoch 39/301 --> loss:0.10266265273094177
step 131/275, epoch 39/301 --> loss:0.08193169236183166
step 141/275, epoch 39/301 --> loss:0.07927826046943665
step 151/275, epoch 39/301 --> loss:0.08381879329681396
step 161/275, epoch 39/301 --> loss:0.10837410688400269
step 171/275, epoch 39/301 --> loss:0.07562888860702514
step 181/275, epoch 39/301 --> loss:0.09108536243438721
step 191/275, epoch 39/301 --> loss:0.11509408950805664
step 201/275, epoch 39/301 --> loss:0.09230321049690246
step 211/275, epoch 39/301 --> loss:0.09091121554374695
step 221/275, epoch 39/301 --> loss:0.09621655941009521
step 231/275, epoch 39/301 --> loss:0.10620682835578918
step 241/275, epoch 39/301 --> loss:0.09918712377548218
step 251/275, epoch 39/301 --> loss:0.09272555112838746
step 261/275, epoch 39/301 --> loss:0.11184432506561279
step 271/275, epoch 39/301 --> loss:0.10831648111343384
 13%|█▎        | 40/301 [3:49:01<23:23:36, 322.67s/it]step 11/275, epoch 40/301 --> loss:0.09563897252082824
step 21/275, epoch 40/301 --> loss:0.0994059681892395
step 31/275, epoch 40/301 --> loss:0.08999052047729492
step 41/275, epoch 40/301 --> loss:0.0964537262916565
step 51/275, epoch 40/301 --> loss:0.0906744122505188
step 61/275, epoch 40/301 --> loss:0.0967209815979004
step 71/275, epoch 40/301 --> loss:0.08663383722305298
step 81/275, epoch 40/301 --> loss:0.08710846900939942
step 91/275, epoch 40/301 --> loss:0.10834127068519592
step 101/275, epoch 40/301 --> loss:0.10553969740867615
step 111/275, epoch 40/301 --> loss:0.09927178621292114
step 121/275, epoch 40/301 --> loss:0.11363133192062377
step 131/275, epoch 40/301 --> loss:0.1097553551197052
step 141/275, epoch 40/301 --> loss:0.10536364912986755
step 151/275, epoch 40/301 --> loss:0.08530007004737854
step 161/275, epoch 40/301 --> loss:0.10586633682250976
step 171/275, epoch 40/301 --> loss:0.09363481998443604
step 181/275, epoch 40/301 --> loss:0.08952773213386536
step 191/275, epoch 40/301 --> loss:0.10443581938743592
step 201/275, epoch 40/301 --> loss:0.09624511003494263
step 211/275, epoch 40/301 --> loss:0.09892036914825439
step 221/275, epoch 40/301 --> loss:0.12162085771560668
step 231/275, epoch 40/301 --> loss:0.08218347430229186
step 241/275, epoch 40/301 --> loss:0.08315775990486145
step 251/275, epoch 40/301 --> loss:0.09882454872131348
step 261/275, epoch 40/301 --> loss:0.11789854168891907
step 271/275, epoch 40/301 --> loss:0.095781010389328
step 11/275, epoch 41/301 --> loss:0.10200836062431336
step 21/275, epoch 41/301 --> loss:0.08786358833312988
step 31/275, epoch 41/301 --> loss:0.11319606900215148
step 41/275, epoch 41/301 --> loss:0.12018435597419738
step 51/275, epoch 41/301 --> loss:0.08436904549598694
step 61/275, epoch 41/301 --> loss:0.08655537962913513
step 71/275, epoch 41/301 --> loss:0.11643987298011779
step 81/275, epoch 41/301 --> loss:0.10644082427024841
step 91/275, epoch 41/301 --> loss:0.10124253630638122
step 101/275, epoch 41/301 --> loss:0.09294867515563965
step 111/275, epoch 41/301 --> loss:0.0925420343875885
step 121/275, epoch 41/301 --> loss:0.08682745099067687
step 131/275, epoch 41/301 --> loss:0.09075290560722352
step 141/275, epoch 41/301 --> loss:0.09181510210037232
step 151/275, epoch 41/301 --> loss:0.10961048603057862
step 161/275, epoch 41/301 --> loss:0.09039607644081116
step 171/275, epoch 41/301 --> loss:0.10524001121520996
step 181/275, epoch 41/301 --> loss:0.11635718941688537
step 191/275, epoch 41/301 --> loss:0.08237347602844239
step 201/275, epoch 41/301 --> loss:0.11041738986968994
step 211/275, epoch 41/301 --> loss:0.09485328793525696
step 221/275, epoch 41/301 --> loss:0.1151442289352417
step 231/275, epoch 41/301 --> loss:0.10596846342086792
step 241/275, epoch 41/301 --> loss:0.08500447869300842
step 251/275, epoch 41/301 --> loss:0.08488278388977051
step 261/275, epoch 41/301 --> loss:0.09541448354721069
step 271/275, epoch 41/301 --> loss:0.09053047895431518
########## train dataset ##########
PLout index:  2
acc -->  [90.81645413160243]
F1 -->  {'F1': [0.8821312245236015], 'precision': [0.9395289963542968], 'recall': [0.8313516215946344]}
########## eval dataset ##########
 14%|█▎        | 41/301 [3:58:19<28:23:37, 393.15s/it]PLout index:  2
acc -->  [89.79436331964106]
F1 -->  {'F1': [0.871255415334787], 'precision': [0.9324608966908557], 'recall': [0.8175986793281913]}
 14%|█▍        | 42/301 [4:03:39<26:42:55, 371.33s/it]step 11/275, epoch 42/301 --> loss:0.09404121041297912
step 21/275, epoch 42/301 --> loss:0.10745808482170105
step 31/275, epoch 42/301 --> loss:0.11261899471282959
step 41/275, epoch 42/301 --> loss:0.10082259774208069
step 51/275, epoch 42/301 --> loss:0.12142615914344787
step 61/275, epoch 42/301 --> loss:0.10434250831604004
step 71/275, epoch 42/301 --> loss:0.10299032330513
step 81/275, epoch 42/301 --> loss:0.09384536147117614
step 91/275, epoch 42/301 --> loss:0.11172394156455993
step 101/275, epoch 42/301 --> loss:0.08587999939918518
step 111/275, epoch 42/301 --> loss:0.11517464518547058
step 121/275, epoch 42/301 --> loss:0.11878032088279725
step 131/275, epoch 42/301 --> loss:0.07915526628494263
step 141/275, epoch 42/301 --> loss:0.08449357748031616
step 151/275, epoch 42/301 --> loss:0.09870085120201111
step 161/275, epoch 42/301 --> loss:0.09860330820083618
step 171/275, epoch 42/301 --> loss:0.09435528516769409
step 181/275, epoch 42/301 --> loss:0.08636460900306701
step 191/275, epoch 42/301 --> loss:0.10893064141273498
step 201/275, epoch 42/301 --> loss:0.07344424128532409
step 211/275, epoch 42/301 --> loss:0.07749183177947998
step 221/275, epoch 42/301 --> loss:0.08357569575309753
step 231/275, epoch 42/301 --> loss:0.09368857741355896
step 241/275, epoch 42/301 --> loss:0.09952043890953063
step 251/275, epoch 42/301 --> loss:0.09463205933570862
step 261/275, epoch 42/301 --> loss:0.09453084468841552
step 271/275, epoch 42/301 --> loss:0.09130460023880005
 14%|█▍        | 43/301 [4:09:00<25:31:39, 356.20s/it]step 11/275, epoch 43/301 --> loss:0.105003821849823
step 21/275, epoch 43/301 --> loss:0.1029109537601471
step 31/275, epoch 43/301 --> loss:0.0966006875038147
step 41/275, epoch 43/301 --> loss:0.11521211862564087
step 51/275, epoch 43/301 --> loss:0.0883401870727539
step 61/275, epoch 43/301 --> loss:0.11376960277557373
step 71/275, epoch 43/301 --> loss:0.10080858469009399
step 81/275, epoch 43/301 --> loss:0.1077628493309021
step 91/275, epoch 43/301 --> loss:0.08088917136192322
step 101/275, epoch 43/301 --> loss:0.10463904142379761
step 111/275, epoch 43/301 --> loss:0.10601325631141663
step 121/275, epoch 43/301 --> loss:0.08876434564590455
step 131/275, epoch 43/301 --> loss:0.09378369450569153
step 141/275, epoch 43/301 --> loss:0.0766920268535614
step 151/275, epoch 43/301 --> loss:0.08957374691963196
step 161/275, epoch 43/301 --> loss:0.09476613998413086
step 171/275, epoch 43/301 --> loss:0.08872960209846496
step 181/275, epoch 43/301 --> loss:0.1112034797668457
step 191/275, epoch 43/301 --> loss:0.09348528981208801
step 201/275, epoch 43/301 --> loss:0.08713438510894775
step 211/275, epoch 43/301 --> loss:0.09052098393440247
step 221/275, epoch 43/301 --> loss:0.09969936609268189
step 231/275, epoch 43/301 --> loss:0.09692006707191467
step 241/275, epoch 43/301 --> loss:0.07491028308868408
step 251/275, epoch 43/301 --> loss:0.09883124828338623
step 261/275, epoch 43/301 --> loss:0.09280679821968078
step 271/275, epoch 43/301 --> loss:0.09549795985221862
 15%|█▍        | 44/301 [4:14:21<24:40:46, 345.71s/it]step 11/275, epoch 44/301 --> loss:0.10123399496078492
step 21/275, epoch 44/301 --> loss:0.10540498495101928
step 31/275, epoch 44/301 --> loss:0.0913021981716156
step 41/275, epoch 44/301 --> loss:0.10328580141067505
step 51/275, epoch 44/301 --> loss:0.09191452860832214
step 61/275, epoch 44/301 --> loss:0.08509491086006164
step 71/275, epoch 44/301 --> loss:0.09032171964645386
step 81/275, epoch 44/301 --> loss:0.08891093134880065
step 91/275, epoch 44/301 --> loss:0.10019646286964416
step 101/275, epoch 44/301 --> loss:0.09980891346931457
step 111/275, epoch 44/301 --> loss:0.09024204015731811
step 121/275, epoch 44/301 --> loss:0.10960675477981567
step 131/275, epoch 44/301 --> loss:0.09856077432632446
step 141/275, epoch 44/301 --> loss:0.10666877031326294
step 151/275, epoch 44/301 --> loss:0.10746360421180726
step 161/275, epoch 44/301 --> loss:0.08426258563995362
step 171/275, epoch 44/301 --> loss:0.08947893977165222
step 181/275, epoch 44/301 --> loss:0.10749994516372681
step 191/275, epoch 44/301 --> loss:0.10737380385398865
step 201/275, epoch 44/301 --> loss:0.09810740947723388
step 211/275, epoch 44/301 --> loss:0.1118420660495758
step 221/275, epoch 44/301 --> loss:0.09683504700660706
step 231/275, epoch 44/301 --> loss:0.11431621313095093
step 241/275, epoch 44/301 --> loss:0.10065664649009705
step 251/275, epoch 44/301 --> loss:0.09377711415290832
step 261/275, epoch 44/301 --> loss:0.08482332825660706
step 271/275, epoch 44/301 --> loss:0.08546230792999268
 15%|█▍        | 45/301 [4:19:43<24:03:55, 338.42s/it]step 11/275, epoch 45/301 --> loss:0.10050702095031738
step 21/275, epoch 45/301 --> loss:0.10914939045906066
step 31/275, epoch 45/301 --> loss:0.07460687160491944
step 41/275, epoch 45/301 --> loss:0.09333733320236207
step 51/275, epoch 45/301 --> loss:0.09891478419303894
step 61/275, epoch 45/301 --> loss:0.10021147131919861
step 71/275, epoch 45/301 --> loss:0.10135675072669983
step 81/275, epoch 45/301 --> loss:0.09931894540786743
step 91/275, epoch 45/301 --> loss:0.08774245381355286
step 101/275, epoch 45/301 --> loss:0.09517000317573547
step 111/275, epoch 45/301 --> loss:0.1011537492275238
step 121/275, epoch 45/301 --> loss:0.0846797525882721
step 131/275, epoch 45/301 --> loss:0.09590048789978027
step 141/275, epoch 45/301 --> loss:0.0972991168498993
step 151/275, epoch 45/301 --> loss:0.08658729195594787
step 161/275, epoch 45/301 --> loss:0.08889123797416687
step 171/275, epoch 45/301 --> loss:0.08551325798034667
step 181/275, epoch 45/301 --> loss:0.09126341342926025
step 191/275, epoch 45/301 --> loss:0.10032856464385986
step 201/275, epoch 45/301 --> loss:0.07796486616134643
step 211/275, epoch 45/301 --> loss:0.09355561137199402
step 221/275, epoch 45/301 --> loss:0.07174119353294373
step 231/275, epoch 45/301 --> loss:0.0971778929233551
step 241/275, epoch 45/301 --> loss:0.09218848943710327
step 251/275, epoch 45/301 --> loss:0.09963252544403076
step 261/275, epoch 45/301 --> loss:0.09215893149375916
step 271/275, epoch 45/301 --> loss:0.09297756552696228
 15%|█▌        | 46/301 [4:25:02<23:34:40, 332.86s/it]step 11/275, epoch 46/301 --> loss:0.09531770348548889
step 21/275, epoch 46/301 --> loss:0.09511630535125733
step 31/275, epoch 46/301 --> loss:0.09393309950828552
step 41/275, epoch 46/301 --> loss:0.1026580810546875
step 51/275, epoch 46/301 --> loss:0.09110342860221862
step 61/275, epoch 46/301 --> loss:0.0932625949382782
step 71/275, epoch 46/301 --> loss:0.10372908115386963
step 81/275, epoch 46/301 --> loss:0.09928906559944153
step 91/275, epoch 46/301 --> loss:0.08595066070556641
step 101/275, epoch 46/301 --> loss:0.08571730256080627
step 111/275, epoch 46/301 --> loss:0.09447504878044129
step 121/275, epoch 46/301 --> loss:0.08800281286239624
step 131/275, epoch 46/301 --> loss:0.09234821200370788
step 141/275, epoch 46/301 --> loss:0.08883222341537475
step 151/275, epoch 46/301 --> loss:0.09064576029777527
step 161/275, epoch 46/301 --> loss:0.09147102236747742
step 171/275, epoch 46/301 --> loss:0.08869279623031616
step 181/275, epoch 46/301 --> loss:0.08941269516944886
step 191/275, epoch 46/301 --> loss:0.07656753659248353
step 201/275, epoch 46/301 --> loss:0.10156441926956176
step 211/275, epoch 46/301 --> loss:0.1030013084411621
step 221/275, epoch 46/301 --> loss:0.09817133545875549
step 231/275, epoch 46/301 --> loss:0.12378093600273132
step 241/275, epoch 46/301 --> loss:0.1021998405456543
step 251/275, epoch 46/301 --> loss:0.08328808546066284
step 261/275, epoch 46/301 --> loss:0.09477651715278626
step 271/275, epoch 46/301 --> loss:0.09103003144264221
 16%|█▌        | 47/301 [4:30:20<23:09:37, 328.26s/it]step 11/275, epoch 47/301 --> loss:0.09556902647018432
step 21/275, epoch 47/301 --> loss:0.09170927405357361
step 31/275, epoch 47/301 --> loss:0.09323365688323974
step 41/275, epoch 47/301 --> loss:0.09452710747718811
step 51/275, epoch 47/301 --> loss:0.09335883259773255
step 61/275, epoch 47/301 --> loss:0.08462759256362914
step 71/275, epoch 47/301 --> loss:0.09116650819778442
step 81/275, epoch 47/301 --> loss:0.09134750962257385
step 91/275, epoch 47/301 --> loss:0.08881664276123047
step 101/275, epoch 47/301 --> loss:0.08522898554801941
step 111/275, epoch 47/301 --> loss:0.09012911319732667
step 121/275, epoch 47/301 --> loss:0.09226292967796326
step 131/275, epoch 47/301 --> loss:0.11870847344398498
step 141/275, epoch 47/301 --> loss:0.08835025429725647
step 151/275, epoch 47/301 --> loss:0.08723466396331787
step 161/275, epoch 47/301 --> loss:0.11680155992507935
step 171/275, epoch 47/301 --> loss:0.08672550320625305
step 181/275, epoch 47/301 --> loss:0.1006566822528839
step 191/275, epoch 47/301 --> loss:0.085910964012146
step 201/275, epoch 47/301 --> loss:0.09843186140060425
step 211/275, epoch 47/301 --> loss:0.081716388463974
step 221/275, epoch 47/301 --> loss:0.08955711722373963
step 231/275, epoch 47/301 --> loss:0.0952390193939209
step 241/275, epoch 47/301 --> loss:0.09814161658287049
step 251/275, epoch 47/301 --> loss:0.08874312639236451
step 261/275, epoch 47/301 --> loss:0.1100118637084961
step 271/275, epoch 47/301 --> loss:0.09763743281364441
 16%|█▌        | 48/301 [4:35:37<22:50:15, 324.96s/it]step 11/275, epoch 48/301 --> loss:0.0873410165309906
step 21/275, epoch 48/301 --> loss:0.09255746603012086
step 31/275, epoch 48/301 --> loss:0.09647135734558106
step 41/275, epoch 48/301 --> loss:0.07768545746803283
step 51/275, epoch 48/301 --> loss:0.09303749799728393
step 61/275, epoch 48/301 --> loss:0.10266494750976562
step 71/275, epoch 48/301 --> loss:0.09283235669136047
step 81/275, epoch 48/301 --> loss:0.0797411859035492
step 91/275, epoch 48/301 --> loss:0.08326088190078736
step 101/275, epoch 48/301 --> loss:0.09203059077262879
step 111/275, epoch 48/301 --> loss:0.1076853632926941
step 121/275, epoch 48/301 --> loss:0.09563027620315552
step 131/275, epoch 48/301 --> loss:0.09948615431785583
step 141/275, epoch 48/301 --> loss:0.0891978919506073
step 151/275, epoch 48/301 --> loss:0.09439226984977722
step 161/275, epoch 48/301 --> loss:0.08606123328208923
step 171/275, epoch 48/301 --> loss:0.10083798766136169
step 181/275, epoch 48/301 --> loss:0.08448624610900879
step 191/275, epoch 48/301 --> loss:0.0828140139579773
step 201/275, epoch 48/301 --> loss:0.10136868357658387
step 211/275, epoch 48/301 --> loss:0.08590373396873474
step 221/275, epoch 48/301 --> loss:0.09568735957145691
step 231/275, epoch 48/301 --> loss:0.084468674659729
step 241/275, epoch 48/301 --> loss:0.08992602229118347
step 251/275, epoch 48/301 --> loss:0.08181487321853638
step 261/275, epoch 48/301 --> loss:0.09166283011436463
step 271/275, epoch 48/301 --> loss:0.10082173943519593
 16%|█▋        | 49/301 [4:40:55<22:35:17, 322.69s/it]step 11/275, epoch 49/301 --> loss:0.08791896104812622
step 21/275, epoch 49/301 --> loss:0.09956378936767578
step 31/275, epoch 49/301 --> loss:0.08827404379844665
step 41/275, epoch 49/301 --> loss:0.09762750864028931
step 51/275, epoch 49/301 --> loss:0.08462575674057007
step 61/275, epoch 49/301 --> loss:0.08946965336799621
step 71/275, epoch 49/301 --> loss:0.08209477663040161
step 81/275, epoch 49/301 --> loss:0.09709070920944214
step 91/275, epoch 49/301 --> loss:0.10030224323272705
step 101/275, epoch 49/301 --> loss:0.08415365815162659
step 111/275, epoch 49/301 --> loss:0.10264670252799987
step 121/275, epoch 49/301 --> loss:0.08902055025100708
step 131/275, epoch 49/301 --> loss:0.07285947799682617
step 141/275, epoch 49/301 --> loss:0.09309455752372742
step 151/275, epoch 49/301 --> loss:0.08418281674385071
step 161/275, epoch 49/301 --> loss:0.0761633574962616
step 171/275, epoch 49/301 --> loss:0.09265707731246949
step 181/275, epoch 49/301 --> loss:0.09556186795234681
step 191/275, epoch 49/301 --> loss:0.09114120602607727
step 201/275, epoch 49/301 --> loss:0.09117859601974487
step 211/275, epoch 49/301 --> loss:0.09544680714607238
step 221/275, epoch 49/301 --> loss:0.09177723526954651
step 231/275, epoch 49/301 --> loss:0.1265644609928131
step 241/275, epoch 49/301 --> loss:0.09698981046676636
step 251/275, epoch 49/301 --> loss:0.08709733486175537
step 261/275, epoch 49/301 --> loss:0.0773020088672638
step 271/275, epoch 49/301 --> loss:0.08117173314094543
 17%|█▋        | 50/301 [4:46:14<22:25:48, 321.71s/it]step 11/275, epoch 50/301 --> loss:0.09283624887466431
step 21/275, epoch 50/301 --> loss:0.07972565293312073
step 31/275, epoch 50/301 --> loss:0.09003358483314514
step 41/275, epoch 50/301 --> loss:0.09485004544258117
step 51/275, epoch 50/301 --> loss:0.08578014969825745
step 61/275, epoch 50/301 --> loss:0.08698027729988098
step 71/275, epoch 50/301 --> loss:0.07560490369796753
step 81/275, epoch 50/301 --> loss:0.09009364247322083
step 91/275, epoch 50/301 --> loss:0.09105710983276367
step 101/275, epoch 50/301 --> loss:0.09631916880607605
step 111/275, epoch 50/301 --> loss:0.07970047593116761
step 121/275, epoch 50/301 --> loss:0.10112348198890686
step 131/275, epoch 50/301 --> loss:0.10152374505996704
step 141/275, epoch 50/301 --> loss:0.09068530201911926
step 151/275, epoch 50/301 --> loss:0.1020173728466034
step 161/275, epoch 50/301 --> loss:0.08468725681304931
step 171/275, epoch 50/301 --> loss:0.08871949315071107
step 181/275, epoch 50/301 --> loss:0.08541052937507629
step 191/275, epoch 50/301 --> loss:0.08830533027648926
step 201/275, epoch 50/301 --> loss:0.10150513648986817
step 211/275, epoch 50/301 --> loss:0.10199702978134155
step 221/275, epoch 50/301 --> loss:0.09043521881103515
step 231/275, epoch 50/301 --> loss:0.10734726786613465
step 241/275, epoch 50/301 --> loss:0.10133162140846252
step 251/275, epoch 50/301 --> loss:0.09774945974349976
step 261/275, epoch 50/301 --> loss:0.08479945659637451
step 271/275, epoch 50/301 --> loss:0.08468008637428284
step 11/275, epoch 51/301 --> loss:0.08683147430419921
step 21/275, epoch 51/301 --> loss:0.11193502545356751
step 31/275, epoch 51/301 --> loss:0.0999156653881073
step 41/275, epoch 51/301 --> loss:0.09557904601097107
step 51/275, epoch 51/301 --> loss:0.11101374626159669
step 61/275, epoch 51/301 --> loss:0.07576199173927307
step 71/275, epoch 51/301 --> loss:0.08586715459823609
step 81/275, epoch 51/301 --> loss:0.0821344017982483
step 91/275, epoch 51/301 --> loss:0.08446373343467713
step 101/275, epoch 51/301 --> loss:0.1076942503452301
step 111/275, epoch 51/301 --> loss:0.09781795740127563
step 121/275, epoch 51/301 --> loss:0.10995767712593078
step 131/275, epoch 51/301 --> loss:0.10390754342079163
step 141/275, epoch 51/301 --> loss:0.09130005836486817
step 151/275, epoch 51/301 --> loss:0.08794252276420593
step 161/275, epoch 51/301 --> loss:0.08357924222946167
step 171/275, epoch 51/301 --> loss:0.07787926197052002
step 181/275, epoch 51/301 --> loss:0.10735645890235901
step 191/275, epoch 51/301 --> loss:0.09007046222686768
step 201/275, epoch 51/301 --> loss:0.09253753423690796
step 211/275, epoch 51/301 --> loss:0.1091825544834137
step 221/275, epoch 51/301 --> loss:0.09103235006332397
step 231/275, epoch 51/301 --> loss:0.09003337621688842
step 241/275, epoch 51/301 --> loss:0.09274386167526245
step 251/275, epoch 51/301 --> loss:0.09370309710502625
step 261/275, epoch 51/301 --> loss:0.07770329117774963
step 271/275, epoch 51/301 --> loss:0.0757469117641449
########## train dataset ##########
PLout index:  2
acc -->  [92.43898989806435]
F1 -->  {'F1': [0.9088431521089103], 'precision': [0.9058631329086693], 'recall': [0.9118529087801275]}
########## eval dataset ##########
 17%|█▋        | 51/301 [4:55:34<27:18:08, 393.15s/it]PLout index:  2
acc -->  [91.52031218818875]
F1 -->  {'F1': [0.8998903875441978], 'precision': [0.8974395833756089], 'recall': [0.9023646688630139]}
save model!
 17%|█▋        | 52/301 [5:00:56<25:42:55, 371.79s/it]step 11/275, epoch 52/301 --> loss:0.08520551919937133
step 21/275, epoch 52/301 --> loss:0.08784316778182984
step 31/275, epoch 52/301 --> loss:0.10083245635032653
step 41/275, epoch 52/301 --> loss:0.09494827389717102
step 51/275, epoch 52/301 --> loss:0.08475088477134704
step 61/275, epoch 52/301 --> loss:0.09851804971694947
step 71/275, epoch 52/301 --> loss:0.10848705172538757
step 81/275, epoch 52/301 --> loss:0.0853237509727478
step 91/275, epoch 52/301 --> loss:0.11096994280815124
step 101/275, epoch 52/301 --> loss:0.07099765539169312
step 111/275, epoch 52/301 --> loss:0.08918722867965698
step 121/275, epoch 52/301 --> loss:0.07372335195541382
step 131/275, epoch 52/301 --> loss:0.10080527067184449
step 141/275, epoch 52/301 --> loss:0.07589991092681884
step 151/275, epoch 52/301 --> loss:0.09455297589302063
step 161/275, epoch 52/301 --> loss:0.08214086890220643
step 171/275, epoch 52/301 --> loss:0.0995239794254303
step 181/275, epoch 52/301 --> loss:0.08242791295051574
step 191/275, epoch 52/301 --> loss:0.09649584293365479
step 201/275, epoch 52/301 --> loss:0.09238306283950806
step 211/275, epoch 52/301 --> loss:0.09634652137756347
step 221/275, epoch 52/301 --> loss:0.10101129412651062
step 231/275, epoch 52/301 --> loss:0.08804090023040771
step 241/275, epoch 52/301 --> loss:0.08351659178733825
step 251/275, epoch 52/301 --> loss:0.09001739025115967
step 261/275, epoch 52/301 --> loss:0.09589601159095765
step 271/275, epoch 52/301 --> loss:0.08590830564498901
 18%|█▊        | 53/301 [5:06:16<24:32:23, 356.22s/it]step 11/275, epoch 53/301 --> loss:0.10189958810806274
step 21/275, epoch 53/301 --> loss:0.08405576348304748
step 31/275, epoch 53/301 --> loss:0.08652095198631286
step 41/275, epoch 53/301 --> loss:0.09854333400726319
step 51/275, epoch 53/301 --> loss:0.08009400367736816
step 61/275, epoch 53/301 --> loss:0.08904152512550353
step 71/275, epoch 53/301 --> loss:0.08339963555335998
step 81/275, epoch 53/301 --> loss:0.09526216387748718
step 91/275, epoch 53/301 --> loss:0.10519484877586364
step 101/275, epoch 53/301 --> loss:0.0882765769958496
step 111/275, epoch 53/301 --> loss:0.08838322162628173
step 121/275, epoch 53/301 --> loss:0.07685475945472717
step 131/275, epoch 53/301 --> loss:0.08414255380630493
step 141/275, epoch 53/301 --> loss:0.08380579352378845
step 151/275, epoch 53/301 --> loss:0.07636433839797974
step 161/275, epoch 53/301 --> loss:0.12410680651664734
step 171/275, epoch 53/301 --> loss:0.07099925875663757
step 181/275, epoch 53/301 --> loss:0.0850774884223938
step 191/275, epoch 53/301 --> loss:0.09312778115272521
step 201/275, epoch 53/301 --> loss:0.0828790545463562
step 211/275, epoch 53/301 --> loss:0.08009141683578491
step 221/275, epoch 53/301 --> loss:0.0982854962348938
step 231/275, epoch 53/301 --> loss:0.08520678877830505
step 241/275, epoch 53/301 --> loss:0.10635753273963929
step 251/275, epoch 53/301 --> loss:0.08906523585319519
step 261/275, epoch 53/301 --> loss:0.07003800868988037
step 271/275, epoch 53/301 --> loss:0.08641403317451476
 18%|█▊        | 54/301 [5:11:35<23:41:12, 345.23s/it]step 11/275, epoch 54/301 --> loss:0.07820539474487305
step 21/275, epoch 54/301 --> loss:0.09565971493721008
step 31/275, epoch 54/301 --> loss:0.07341604828834533
step 41/275, epoch 54/301 --> loss:0.10532675385475158
step 51/275, epoch 54/301 --> loss:0.08406051397323608
step 61/275, epoch 54/301 --> loss:0.09423872828483582
step 71/275, epoch 54/301 --> loss:0.10535914301872254
step 81/275, epoch 54/301 --> loss:0.08942748904228211
step 91/275, epoch 54/301 --> loss:0.082699453830719
step 101/275, epoch 54/301 --> loss:0.09211828708648681
step 111/275, epoch 54/301 --> loss:0.08118565082550049
step 121/275, epoch 54/301 --> loss:0.07727083563804626
step 131/275, epoch 54/301 --> loss:0.07983799576759339
step 141/275, epoch 54/301 --> loss:0.08954376578330994
step 151/275, epoch 54/301 --> loss:0.0995050311088562
step 161/275, epoch 54/301 --> loss:0.08739039301872253
step 171/275, epoch 54/301 --> loss:0.09905922412872314
step 181/275, epoch 54/301 --> loss:0.07807703018188476
step 191/275, epoch 54/301 --> loss:0.10344910621643066
step 201/275, epoch 54/301 --> loss:0.10139088034629821
step 211/275, epoch 54/301 --> loss:0.07448492646217346
step 221/275, epoch 54/301 --> loss:0.10168005228042602
step 231/275, epoch 54/301 --> loss:0.09692908525466919
step 241/275, epoch 54/301 --> loss:0.09657956957817078
step 251/275, epoch 54/301 --> loss:0.08298126459121705
step 261/275, epoch 54/301 --> loss:0.08944449424743653
step 271/275, epoch 54/301 --> loss:0.08547894954681397
 18%|█▊        | 55/301 [5:16:55<23:03:32, 337.45s/it]step 11/275, epoch 55/301 --> loss:0.08298052549362182
step 21/275, epoch 55/301 --> loss:0.09248632788658143
step 31/275, epoch 55/301 --> loss:0.10307924747467041
step 41/275, epoch 55/301 --> loss:0.08364453315734863
step 51/275, epoch 55/301 --> loss:0.07710594534873963
step 61/275, epoch 55/301 --> loss:0.0849638044834137
step 71/275, epoch 55/301 --> loss:0.08813250660896302
step 81/275, epoch 55/301 --> loss:0.09148165583610535
step 91/275, epoch 55/301 --> loss:0.08120636940002442
step 101/275, epoch 55/301 --> loss:0.0984270453453064
step 111/275, epoch 55/301 --> loss:0.08627201914787293
step 121/275, epoch 55/301 --> loss:0.08435325622558594
step 131/275, epoch 55/301 --> loss:0.09278272390365601
step 141/275, epoch 55/301 --> loss:0.09805303215980529
step 151/275, epoch 55/301 --> loss:0.07763485908508301
step 161/275, epoch 55/301 --> loss:0.07715356349945068
step 171/275, epoch 55/301 --> loss:0.10275618433952331
step 181/275, epoch 55/301 --> loss:0.08677653670310974
step 191/275, epoch 55/301 --> loss:0.1011763334274292
step 201/275, epoch 55/301 --> loss:0.0918688416481018
step 211/275, epoch 55/301 --> loss:0.10535808205604554
step 221/275, epoch 55/301 --> loss:0.08101961612701417
step 231/275, epoch 55/301 --> loss:0.09275670647621155
step 241/275, epoch 55/301 --> loss:0.10142759084701539
step 251/275, epoch 55/301 --> loss:0.07635819315910339
step 261/275, epoch 55/301 --> loss:0.09943382740020752
step 271/275, epoch 55/301 --> loss:0.07272481918334961
 19%|█▊        | 56/301 [5:22:14<22:35:23, 331.93s/it]step 11/275, epoch 56/301 --> loss:0.09250203371047974
step 21/275, epoch 56/301 --> loss:0.08023651242256165
step 31/275, epoch 56/301 --> loss:0.09072036743164062
step 41/275, epoch 56/301 --> loss:0.07543696761131287
step 51/275, epoch 56/301 --> loss:0.080344557762146
step 61/275, epoch 56/301 --> loss:0.08461405634880066
step 71/275, epoch 56/301 --> loss:0.1103376567363739
step 81/275, epoch 56/301 --> loss:0.08471347093582153
step 91/275, epoch 56/301 --> loss:0.10111042857170105
step 101/275, epoch 56/301 --> loss:0.08738812208175659
step 111/275, epoch 56/301 --> loss:0.0949901282787323
step 121/275, epoch 56/301 --> loss:0.10561105608940125
step 131/275, epoch 56/301 --> loss:0.09282196164131165
step 141/275, epoch 56/301 --> loss:0.08587059974670411
step 151/275, epoch 56/301 --> loss:0.07579847574234008
step 161/275, epoch 56/301 --> loss:0.09333658814430237
step 171/275, epoch 56/301 --> loss:0.09867159128189087
step 181/275, epoch 56/301 --> loss:0.07574637532234192
step 191/275, epoch 56/301 --> loss:0.07991986274719239
step 201/275, epoch 56/301 --> loss:0.08770357370376587
step 211/275, epoch 56/301 --> loss:0.09684532880783081
step 221/275, epoch 56/301 --> loss:0.08336955904960633
step 231/275, epoch 56/301 --> loss:0.09054526090621948
step 241/275, epoch 56/301 --> loss:0.0837501585483551
step 251/275, epoch 56/301 --> loss:0.08638159036636353
step 261/275, epoch 56/301 --> loss:0.08634863495826721
step 271/275, epoch 56/301 --> loss:0.09257280826568604
 19%|█▉        | 57/301 [5:27:32<22:13:45, 327.97s/it]step 11/275, epoch 57/301 --> loss:0.07830529808998107
step 21/275, epoch 57/301 --> loss:0.087660813331604
step 31/275, epoch 57/301 --> loss:0.09227126836776733
step 41/275, epoch 57/301 --> loss:0.09273331165313721
step 51/275, epoch 57/301 --> loss:0.08104791045188904
step 61/275, epoch 57/301 --> loss:0.0869179368019104
step 71/275, epoch 57/301 --> loss:0.09784091711044311
step 81/275, epoch 57/301 --> loss:0.08331185579299927
step 91/275, epoch 57/301 --> loss:0.0954491674900055
step 101/275, epoch 57/301 --> loss:0.08223511576652527
step 111/275, epoch 57/301 --> loss:0.08953729271888733
step 121/275, epoch 57/301 --> loss:0.08486871719360352
step 131/275, epoch 57/301 --> loss:0.08246831893920899
step 141/275, epoch 57/301 --> loss:0.0861266553401947
step 151/275, epoch 57/301 --> loss:0.09920408129692078
step 161/275, epoch 57/301 --> loss:0.0923297643661499
step 171/275, epoch 57/301 --> loss:0.09843391180038452
step 181/275, epoch 57/301 --> loss:0.07056907415390015
step 191/275, epoch 57/301 --> loss:0.09617050886154174
step 201/275, epoch 57/301 --> loss:0.07716947197914123
step 211/275, epoch 57/301 --> loss:0.09405991435050964
step 221/275, epoch 57/301 --> loss:0.08331342339515686
step 231/275, epoch 57/301 --> loss:0.09829378128051758
step 241/275, epoch 57/301 --> loss:0.08921699523925782
step 251/275, epoch 57/301 --> loss:0.08133584856987
step 261/275, epoch 57/301 --> loss:0.08782512545585633
step 271/275, epoch 57/301 --> loss:0.09506874084472657
 19%|█▉        | 58/301 [5:32:52<21:58:09, 325.47s/it]step 11/275, epoch 58/301 --> loss:0.091560959815979
step 21/275, epoch 58/301 --> loss:0.0779086709022522
step 31/275, epoch 58/301 --> loss:0.08459739685058594
step 41/275, epoch 58/301 --> loss:0.08215691447257996
step 51/275, epoch 58/301 --> loss:0.08451517820358276
step 61/275, epoch 58/301 --> loss:0.08442201018333435
step 71/275, epoch 58/301 --> loss:0.08435927033424377
step 81/275, epoch 58/301 --> loss:0.0884609878063202
step 91/275, epoch 58/301 --> loss:0.08759450912475586
step 101/275, epoch 58/301 --> loss:0.08820984363555909
step 111/275, epoch 58/301 --> loss:0.10300227403640747
step 121/275, epoch 58/301 --> loss:0.07873927950859069
step 131/275, epoch 58/301 --> loss:0.09198963642120361
step 141/275, epoch 58/301 --> loss:0.09049885272979737
step 151/275, epoch 58/301 --> loss:0.08818243741989136
step 161/275, epoch 58/301 --> loss:0.08567147850990295
step 171/275, epoch 58/301 --> loss:0.0947272539138794
step 181/275, epoch 58/301 --> loss:0.07690279483795166
step 191/275, epoch 58/301 --> loss:0.08243554830551147
step 201/275, epoch 58/301 --> loss:0.07456387281417846
step 211/275, epoch 58/301 --> loss:0.07748048305511475
step 221/275, epoch 58/301 --> loss:0.08378639221191406
step 231/275, epoch 58/301 --> loss:0.08578736186027527
step 241/275, epoch 58/301 --> loss:0.10628787279129029
step 251/275, epoch 58/301 --> loss:0.092438805103302
step 261/275, epoch 58/301 --> loss:0.10238161087036132
step 271/275, epoch 58/301 --> loss:0.09364703297615051
 20%|█▉        | 59/301 [5:38:12<21:46:13, 323.86s/it]step 11/275, epoch 59/301 --> loss:0.08592502474784851
step 21/275, epoch 59/301 --> loss:0.0867766261100769
step 31/275, epoch 59/301 --> loss:0.07630127072334289
step 41/275, epoch 59/301 --> loss:0.08148860335350036
step 51/275, epoch 59/301 --> loss:0.08382925391197205
step 61/275, epoch 59/301 --> loss:0.106296706199646
step 71/275, epoch 59/301 --> loss:0.07936026453971863
step 81/275, epoch 59/301 --> loss:0.08385993838310242
step 91/275, epoch 59/301 --> loss:0.08740745186805725
step 101/275, epoch 59/301 --> loss:0.08703972101211548
step 111/275, epoch 59/301 --> loss:0.1004384696483612
step 121/275, epoch 59/301 --> loss:0.0870435893535614
step 131/275, epoch 59/301 --> loss:0.08398998975753784
step 141/275, epoch 59/301 --> loss:0.08615886569023132
step 151/275, epoch 59/301 --> loss:0.08823610544204712
step 161/275, epoch 59/301 --> loss:0.09342802762985229
step 171/275, epoch 59/301 --> loss:0.07753642201423645
step 181/275, epoch 59/301 --> loss:0.08219653367996216
step 191/275, epoch 59/301 --> loss:0.0854587972164154
step 201/275, epoch 59/301 --> loss:0.07326220273971558
step 211/275, epoch 59/301 --> loss:0.09380972981452942
step 221/275, epoch 59/301 --> loss:0.07960862517356873
step 231/275, epoch 59/301 --> loss:0.0972120225429535
step 241/275, epoch 59/301 --> loss:0.08102511763572692
step 251/275, epoch 59/301 --> loss:0.08287439942359924
step 261/275, epoch 59/301 --> loss:0.07897410988807678
step 271/275, epoch 59/301 --> loss:0.0876033365726471
 20%|█▉        | 60/301 [5:43:32<21:36:23, 322.75s/it]step 11/275, epoch 60/301 --> loss:0.08237347602844239
step 21/275, epoch 60/301 --> loss:0.0852544665336609
step 31/275, epoch 60/301 --> loss:0.08316919207572937
step 41/275, epoch 60/301 --> loss:0.08505197763442993
step 51/275, epoch 60/301 --> loss:0.08855175375938415
step 61/275, epoch 60/301 --> loss:0.07668241858482361
step 71/275, epoch 60/301 --> loss:0.09092950820922852
step 81/275, epoch 60/301 --> loss:0.08670828342437745
step 91/275, epoch 60/301 --> loss:0.08646718859672546
step 101/275, epoch 60/301 --> loss:0.0845418930053711
step 111/275, epoch 60/301 --> loss:0.08145648837089539
step 121/275, epoch 60/301 --> loss:0.08493584394454956
step 131/275, epoch 60/301 --> loss:0.10049718022346496
step 141/275, epoch 60/301 --> loss:0.08754432201385498
step 151/275, epoch 60/301 --> loss:0.08973119258880616
step 161/275, epoch 60/301 --> loss:0.07920268177986145
step 171/275, epoch 60/301 --> loss:0.09242623448371887
step 181/275, epoch 60/301 --> loss:0.09677172899246216
step 191/275, epoch 60/301 --> loss:0.09131836891174316
step 201/275, epoch 60/301 --> loss:0.09178397655487061
step 211/275, epoch 60/301 --> loss:0.07773379683494568
step 221/275, epoch 60/301 --> loss:0.08804912567138672
step 231/275, epoch 60/301 --> loss:0.0823428750038147
step 241/275, epoch 60/301 --> loss:0.08797863721847535
step 251/275, epoch 60/301 --> loss:0.08394176959991455
step 261/275, epoch 60/301 --> loss:0.0892684280872345
step 271/275, epoch 60/301 --> loss:0.08960444331169129
step 11/275, epoch 61/301 --> loss:0.07410925030708312
step 21/275, epoch 61/301 --> loss:0.08251179456710815
step 31/275, epoch 61/301 --> loss:0.08017363548278808
step 41/275, epoch 61/301 --> loss:0.10341713428497315
step 51/275, epoch 61/301 --> loss:0.07660315036773682
step 61/275, epoch 61/301 --> loss:0.09071305394172668
step 71/275, epoch 61/301 --> loss:0.10222934484481812
step 81/275, epoch 61/301 --> loss:0.0859485387802124
step 91/275, epoch 61/301 --> loss:0.07670705318450928
step 101/275, epoch 61/301 --> loss:0.07473731637001038
step 111/275, epoch 61/301 --> loss:0.09257476925849914
step 121/275, epoch 61/301 --> loss:0.08784370422363282
step 131/275, epoch 61/301 --> loss:0.08649393320083618
step 141/275, epoch 61/301 --> loss:0.08453903198242188
step 151/275, epoch 61/301 --> loss:0.08733158707618713
step 161/275, epoch 61/301 --> loss:0.08826090097427368
step 171/275, epoch 61/301 --> loss:0.0808732807636261
step 181/275, epoch 61/301 --> loss:0.08230995535850524
step 191/275, epoch 61/301 --> loss:0.08779016137123108
step 201/275, epoch 61/301 --> loss:0.08685992956161499
step 211/275, epoch 61/301 --> loss:0.08011043667793274
step 221/275, epoch 61/301 --> loss:0.07470510005950928
step 231/275, epoch 61/301 --> loss:0.09276365637779235
step 241/275, epoch 61/301 --> loss:0.08508132696151734
step 251/275, epoch 61/301 --> loss:0.08038461208343506
step 261/275, epoch 61/301 --> loss:0.09223252534866333
step 271/275, epoch 61/301 --> loss:0.08887938857078552
########## train dataset ##########
PLout index:  2
acc -->  [89.94573786699321]
F1 -->  {'F1': [0.8676631484416036], 'precision': [0.9515637818271427], 'recall': [0.7973673371914348]}
########## eval dataset ##########
 20%|██        | 61/301 [5:52:50<26:12:49, 393.21s/it]PLout index:  2
acc -->  [88.49308534511411]
F1 -->  {'F1': [0.8506852307154927], 'precision': [0.9411725106950252], 'recall': [0.7760795453048276]}
 21%|██        | 62/301 [5:58:10<24:38:52, 371.27s/it]step 11/275, epoch 62/301 --> loss:0.09033992290496826
step 21/275, epoch 62/301 --> loss:0.07197286486625672
step 31/275, epoch 62/301 --> loss:0.09633949398994446
step 41/275, epoch 62/301 --> loss:0.10962209105491638
step 51/275, epoch 62/301 --> loss:0.07993239760398865
step 61/275, epoch 62/301 --> loss:0.08699744939804077
step 71/275, epoch 62/301 --> loss:0.08694136738777161
step 81/275, epoch 62/301 --> loss:0.06629613637924195
step 91/275, epoch 62/301 --> loss:0.094640052318573
step 101/275, epoch 62/301 --> loss:0.09537176489830017
step 111/275, epoch 62/301 --> loss:0.08175358772277833
step 121/275, epoch 62/301 --> loss:0.09402323961257934
step 131/275, epoch 62/301 --> loss:0.08013489246368408
step 141/275, epoch 62/301 --> loss:0.0691230297088623
step 151/275, epoch 62/301 --> loss:0.0787692904472351
step 161/275, epoch 62/301 --> loss:0.08721927404403687
step 171/275, epoch 62/301 --> loss:0.09358128905296326
step 181/275, epoch 62/301 --> loss:0.07502773404121399
step 191/275, epoch 62/301 --> loss:0.08672350645065308
step 201/275, epoch 62/301 --> loss:0.06859655380249023
step 211/275, epoch 62/301 --> loss:0.07989003658294677
step 221/275, epoch 62/301 --> loss:0.0784081757068634
step 231/275, epoch 62/301 --> loss:0.09431506395339966
step 241/275, epoch 62/301 --> loss:0.0839610755443573
step 251/275, epoch 62/301 --> loss:0.08308934569358825
step 261/275, epoch 62/301 --> loss:0.07314093708992005
step 271/275, epoch 62/301 --> loss:0.08876963853836059
 21%|██        | 63/301 [6:03:32<23:34:01, 356.48s/it]step 11/275, epoch 63/301 --> loss:0.0698466181755066
step 21/275, epoch 63/301 --> loss:0.0843171238899231
step 31/275, epoch 63/301 --> loss:0.08693381547927856
step 41/275, epoch 63/301 --> loss:0.07053204774856567
step 51/275, epoch 63/301 --> loss:0.08862749934196472
step 61/275, epoch 63/301 --> loss:0.09328004717826843
step 71/275, epoch 63/301 --> loss:0.08435192704200745
step 81/275, epoch 63/301 --> loss:0.09031974077224732
step 91/275, epoch 63/301 --> loss:0.06996119618415833
step 101/275, epoch 63/301 --> loss:0.09093107581138611
step 111/275, epoch 63/301 --> loss:0.09044702649116516
step 121/275, epoch 63/301 --> loss:0.07911792993545533
step 131/275, epoch 63/301 --> loss:0.06630324721336364
step 141/275, epoch 63/301 --> loss:0.07833269834518433
step 151/275, epoch 63/301 --> loss:0.07791601419448853
step 161/275, epoch 63/301 --> loss:0.08889915943145751
step 171/275, epoch 63/301 --> loss:0.06931925415992737
step 181/275, epoch 63/301 --> loss:0.08502362370491028
step 191/275, epoch 63/301 --> loss:0.07603827118873596
step 201/275, epoch 63/301 --> loss:0.08322745561599731
step 211/275, epoch 63/301 --> loss:0.08816572427749633
step 221/275, epoch 63/301 --> loss:0.0823667287826538
step 231/275, epoch 63/301 --> loss:0.085422682762146
step 241/275, epoch 63/301 --> loss:0.07968065738677979
step 251/275, epoch 63/301 --> loss:0.0868360936641693
step 261/275, epoch 63/301 --> loss:0.09407479763031006
step 271/275, epoch 63/301 --> loss:0.08007808327674866
 21%|██▏       | 64/301 [6:08:53<22:46:37, 345.98s/it]step 11/275, epoch 64/301 --> loss:0.08623970746994018
step 21/275, epoch 64/301 --> loss:0.08473833203315735
step 31/275, epoch 64/301 --> loss:0.08430086374282837
step 41/275, epoch 64/301 --> loss:0.07735599875450135
step 51/275, epoch 64/301 --> loss:0.07434101700782776
step 61/275, epoch 64/301 --> loss:0.06852028369903565
step 71/275, epoch 64/301 --> loss:0.09858818054199218
step 81/275, epoch 64/301 --> loss:0.08003892302513123
step 91/275, epoch 64/301 --> loss:0.0811852753162384
step 101/275, epoch 64/301 --> loss:0.08265036344528198
step 111/275, epoch 64/301 --> loss:0.0762908399105072
step 121/275, epoch 64/301 --> loss:0.06550605297088623
step 131/275, epoch 64/301 --> loss:0.07927003502845764
step 141/275, epoch 64/301 --> loss:0.08103040456771851
step 151/275, epoch 64/301 --> loss:0.08040658235549927
step 161/275, epoch 64/301 --> loss:0.09975966811180115
step 171/275, epoch 64/301 --> loss:0.07902199029922485
step 181/275, epoch 64/301 --> loss:0.06316670179367065
step 191/275, epoch 64/301 --> loss:0.09269009232521057
step 201/275, epoch 64/301 --> loss:0.09022389650344849
step 211/275, epoch 64/301 --> loss:0.09381868839263915
step 221/275, epoch 64/301 --> loss:0.0950854778289795
step 231/275, epoch 64/301 --> loss:0.07534083127975463
step 241/275, epoch 64/301 --> loss:0.08098707795143127
step 251/275, epoch 64/301 --> loss:0.08256279230117798
step 261/275, epoch 64/301 --> loss:0.07980420589447021
step 271/275, epoch 64/301 --> loss:0.0805206537246704
 22%|██▏       | 65/301 [6:14:12<22:08:57, 337.87s/it]step 11/275, epoch 65/301 --> loss:0.07876358032226563
step 21/275, epoch 65/301 --> loss:0.0842431366443634
step 31/275, epoch 65/301 --> loss:0.07944442629814148
step 41/275, epoch 65/301 --> loss:0.06959249377250672
step 51/275, epoch 65/301 --> loss:0.0885823130607605
step 61/275, epoch 65/301 --> loss:0.07542834877967834
step 71/275, epoch 65/301 --> loss:0.0915128767490387
step 81/275, epoch 65/301 --> loss:0.09270570874214172
step 91/275, epoch 65/301 --> loss:0.086728435754776
step 101/275, epoch 65/301 --> loss:0.09640159010887146
step 111/275, epoch 65/301 --> loss:0.07614688277244568
step 121/275, epoch 65/301 --> loss:0.07081069946289062
step 131/275, epoch 65/301 --> loss:0.0741856038570404
step 141/275, epoch 65/301 --> loss:0.0814957082271576
step 151/275, epoch 65/301 --> loss:0.08436624407768249
step 161/275, epoch 65/301 --> loss:0.06384276151657105
step 171/275, epoch 65/301 --> loss:0.08805798888206481
step 181/275, epoch 65/301 --> loss:0.09112762808799743
step 191/275, epoch 65/301 --> loss:0.0866626262664795
step 201/275, epoch 65/301 --> loss:0.0918377935886383
step 211/275, epoch 65/301 --> loss:0.08450850248336791
step 221/275, epoch 65/301 --> loss:0.09570773839950561
step 231/275, epoch 65/301 --> loss:0.0906294584274292
step 241/275, epoch 65/301 --> loss:0.08066810369491577
step 251/275, epoch 65/301 --> loss:0.07880246639251709
step 261/275, epoch 65/301 --> loss:0.07722901701927185
step 271/275, epoch 65/301 --> loss:0.08127143979072571
 22%|██▏       | 66/301 [6:19:31<21:40:03, 331.93s/it]step 11/275, epoch 66/301 --> loss:0.08579456806182861
step 21/275, epoch 66/301 --> loss:0.08133792281150817
step 31/275, epoch 66/301 --> loss:0.09207403063774108
step 41/275, epoch 66/301 --> loss:0.09587655067443848
step 51/275, epoch 66/301 --> loss:0.10013446807861329
step 61/275, epoch 66/301 --> loss:0.07955902218818664
step 71/275, epoch 66/301 --> loss:0.08222940564155579
step 81/275, epoch 66/301 --> loss:0.08038630485534667
step 91/275, epoch 66/301 --> loss:0.08418654799461364
step 101/275, epoch 66/301 --> loss:0.06776890754699708
step 111/275, epoch 66/301 --> loss:0.09186395406723022
step 121/275, epoch 66/301 --> loss:0.08735433220863342
step 131/275, epoch 66/301 --> loss:0.08967176079750061
step 141/275, epoch 66/301 --> loss:0.08230307102203369
step 151/275, epoch 66/301 --> loss:0.08459287881851196
step 161/275, epoch 66/301 --> loss:0.07642238736152648
step 171/275, epoch 66/301 --> loss:0.08474603295326233
step 181/275, epoch 66/301 --> loss:0.07559453248977661
step 191/275, epoch 66/301 --> loss:0.0715186357498169
step 201/275, epoch 66/301 --> loss:0.07531708478927612
step 211/275, epoch 66/301 --> loss:0.08219867944717407
step 221/275, epoch 66/301 --> loss:0.07388757467269898
step 231/275, epoch 66/301 --> loss:0.0877734363079071
step 241/275, epoch 66/301 --> loss:0.0737200140953064
step 251/275, epoch 66/301 --> loss:0.0827706515789032
step 261/275, epoch 66/301 --> loss:0.09127935171127319
step 271/275, epoch 66/301 --> loss:0.08314992189407348
 22%|██▏       | 67/301 [6:24:48<21:17:50, 327.65s/it]step 11/275, epoch 67/301 --> loss:0.09105403423309326
step 21/275, epoch 67/301 --> loss:0.08654913306236267
step 31/275, epoch 67/301 --> loss:0.10233206152915955
step 41/275, epoch 67/301 --> loss:0.10397548675537109
step 51/275, epoch 67/301 --> loss:0.08538452982902527
step 61/275, epoch 67/301 --> loss:0.06789278984069824
step 71/275, epoch 67/301 --> loss:0.07447896003723145
step 81/275, epoch 67/301 --> loss:0.08678247928619384
step 91/275, epoch 67/301 --> loss:0.08217341303825379
step 101/275, epoch 67/301 --> loss:0.08883950114250183
step 111/275, epoch 67/301 --> loss:0.09333866834640503
step 121/275, epoch 67/301 --> loss:0.07784014344215393
step 131/275, epoch 67/301 --> loss:0.08128662705421448
step 141/275, epoch 67/301 --> loss:0.08099194765090942
step 151/275, epoch 67/301 --> loss:0.07396982312202453
step 161/275, epoch 67/301 --> loss:0.08877020478248596
step 171/275, epoch 67/301 --> loss:0.0916315495967865
step 181/275, epoch 67/301 --> loss:0.09752534627914429
step 191/275, epoch 67/301 --> loss:0.07251666188240051
step 201/275, epoch 67/301 --> loss:0.09100855588912964
step 211/275, epoch 67/301 --> loss:0.09909036755561829
step 221/275, epoch 67/301 --> loss:0.09173542261123657
step 231/275, epoch 67/301 --> loss:0.08032920956611633
step 241/275, epoch 67/301 --> loss:0.08752684593200684
step 251/275, epoch 67/301 --> loss:0.08658238649368286
step 261/275, epoch 67/301 --> loss:0.07837634682655334
step 271/275, epoch 67/301 --> loss:0.08626232743263244
 23%|██▎       | 68/301 [6:30:07<21:02:15, 325.04s/it]step 11/275, epoch 68/301 --> loss:0.08842730522155762
step 21/275, epoch 68/301 --> loss:0.07441246509552002
step 31/275, epoch 68/301 --> loss:0.07008174657821656
step 41/275, epoch 68/301 --> loss:0.08818577527999878
step 51/275, epoch 68/301 --> loss:0.06258239150047303
step 61/275, epoch 68/301 --> loss:0.08002372980117797
step 71/275, epoch 68/301 --> loss:0.09963310956954956
step 81/275, epoch 68/301 --> loss:0.08090263605117798
step 91/275, epoch 68/301 --> loss:0.08256024718284607
step 101/275, epoch 68/301 --> loss:0.08243757486343384
step 111/275, epoch 68/301 --> loss:0.08759027123451232
step 121/275, epoch 68/301 --> loss:0.07644513249397278
step 131/275, epoch 68/301 --> loss:0.07333321571350097
step 141/275, epoch 68/301 --> loss:0.07654557824134826
step 151/275, epoch 68/301 --> loss:0.07688026428222657
step 161/275, epoch 68/301 --> loss:0.07715482115745545
step 171/275, epoch 68/301 --> loss:0.08444215655326844
step 181/275, epoch 68/301 --> loss:0.08033966422080993
step 191/275, epoch 68/301 --> loss:0.07001838088035583
step 201/275, epoch 68/301 --> loss:0.08073868155479431
step 211/275, epoch 68/301 --> loss:0.05108522176742554
step 221/275, epoch 68/301 --> loss:0.07054318189620971
step 231/275, epoch 68/301 --> loss:0.08917905688285828
step 241/275, epoch 68/301 --> loss:0.09818766713142395
step 251/275, epoch 68/301 --> loss:0.08014808297157287
step 261/275, epoch 68/301 --> loss:0.08070672154426575
step 271/275, epoch 68/301 --> loss:0.09288147687911988
 23%|██▎       | 69/301 [6:35:28<20:52:26, 323.91s/it]step 11/275, epoch 69/301 --> loss:0.08333854079246521
step 21/275, epoch 69/301 --> loss:0.07551401853561401
step 31/275, epoch 69/301 --> loss:0.06545079946517944
step 41/275, epoch 69/301 --> loss:0.07484672665596008
step 51/275, epoch 69/301 --> loss:0.08344405889511108
step 61/275, epoch 69/301 --> loss:0.08598074316978455
step 71/275, epoch 69/301 --> loss:0.07871026992797851
step 81/275, epoch 69/301 --> loss:0.07914877533912659
step 91/275, epoch 69/301 --> loss:0.08380712866783142
step 101/275, epoch 69/301 --> loss:0.07324707508087158
step 111/275, epoch 69/301 --> loss:0.0897577702999115
step 121/275, epoch 69/301 --> loss:0.08144020438194274
step 131/275, epoch 69/301 --> loss:0.06416367292404175
step 141/275, epoch 69/301 --> loss:0.08051609992980957
step 151/275, epoch 69/301 --> loss:0.11573042273521424
step 161/275, epoch 69/301 --> loss:0.0746384620666504
step 171/275, epoch 69/301 --> loss:0.08564317226409912
step 181/275, epoch 69/301 --> loss:0.08048244118690491
step 191/275, epoch 69/301 --> loss:0.06811256408691406
step 201/275, epoch 69/301 --> loss:0.07148106694221497
step 211/275, epoch 69/301 --> loss:0.08638043403625488
step 221/275, epoch 69/301 --> loss:0.07688071727752685
step 231/275, epoch 69/301 --> loss:0.09698026776313781
step 241/275, epoch 69/301 --> loss:0.08455560207366944
step 251/275, epoch 69/301 --> loss:0.07701576948165893
step 261/275, epoch 69/301 --> loss:0.08364258408546447
step 271/275, epoch 69/301 --> loss:0.0880815863609314
 23%|██▎       | 70/301 [6:40:51<20:45:36, 323.53s/it]step 11/275, epoch 70/301 --> loss:0.09589170813560485
step 21/275, epoch 70/301 --> loss:0.0605587899684906
step 31/275, epoch 70/301 --> loss:0.06868224740028381
step 41/275, epoch 70/301 --> loss:0.0780681848526001
step 51/275, epoch 70/301 --> loss:0.05877283811569214
step 61/275, epoch 70/301 --> loss:0.07431433200836182
step 71/275, epoch 70/301 --> loss:0.08807964324951172
step 81/275, epoch 70/301 --> loss:0.09740270972251892
step 91/275, epoch 70/301 --> loss:0.06895056366920471
step 101/275, epoch 70/301 --> loss:0.0782768189907074
step 111/275, epoch 70/301 --> loss:0.0814304530620575
step 121/275, epoch 70/301 --> loss:0.06574618816375732
step 131/275, epoch 70/301 --> loss:0.0776247262954712
step 141/275, epoch 70/301 --> loss:0.08478849530220031
step 151/275, epoch 70/301 --> loss:0.07383140325546264
step 161/275, epoch 70/301 --> loss:0.08290457725524902
step 171/275, epoch 70/301 --> loss:0.09166587591171264
step 181/275, epoch 70/301 --> loss:0.0853796660900116
step 191/275, epoch 70/301 --> loss:0.07832945585250854
step 201/275, epoch 70/301 --> loss:0.09332627058029175
step 211/275, epoch 70/301 --> loss:0.07736218571662903
step 221/275, epoch 70/301 --> loss:0.08668837547302247
step 231/275, epoch 70/301 --> loss:0.08656641244888305
step 241/275, epoch 70/301 --> loss:0.07006123065948486
step 251/275, epoch 70/301 --> loss:0.0871621012687683
step 261/275, epoch 70/301 --> loss:0.0877003788948059
step 271/275, epoch 70/301 --> loss:0.08710098266601562
step 11/275, epoch 71/301 --> loss:0.0722558081150055
step 21/275, epoch 71/301 --> loss:0.08813863396644592
step 31/275, epoch 71/301 --> loss:0.08152435421943664
step 41/275, epoch 71/301 --> loss:0.070868581533432
step 51/275, epoch 71/301 --> loss:0.07231826186180115
step 61/275, epoch 71/301 --> loss:0.07346792817115784
step 71/275, epoch 71/301 --> loss:0.09396218657493591
step 81/275, epoch 71/301 --> loss:0.059140390157699584
step 91/275, epoch 71/301 --> loss:0.07539907097816467
step 101/275, epoch 71/301 --> loss:0.08035932779312134
step 111/275, epoch 71/301 --> loss:0.0789028286933899
step 121/275, epoch 71/301 --> loss:0.07349908351898193
step 131/275, epoch 71/301 --> loss:0.06764647364616394
step 141/275, epoch 71/301 --> loss:0.07653957605361938
step 151/275, epoch 71/301 --> loss:0.07825328707695008
step 161/275, epoch 71/301 --> loss:0.08218448758125305
step 171/275, epoch 71/301 --> loss:0.09615920782089234
step 181/275, epoch 71/301 --> loss:0.08567125201225281
step 191/275, epoch 71/301 --> loss:0.1067433476448059
step 201/275, epoch 71/301 --> loss:0.0945753037929535
step 211/275, epoch 71/301 --> loss:0.07087348103523254
step 221/275, epoch 71/301 --> loss:0.08071386814117432
step 231/275, epoch 71/301 --> loss:0.11114927530288696
step 241/275, epoch 71/301 --> loss:0.08133750557899475
step 251/275, epoch 71/301 --> loss:0.09478053450584412
step 261/275, epoch 71/301 --> loss:0.06728811860084534
step 271/275, epoch 71/301 --> loss:0.08522300720214844
########## train dataset ##########
PLout index:  2
acc -->  [94.07618523728853]
F1 -->  {'F1': [0.9288734250887273], 'precision': [0.9220688296944449], 'recall': [0.9357893476466769]}
########## eval dataset ##########
 24%|██▎       | 71/301 [6:50:09<25:09:31, 393.79s/it]PLout index:  2
acc -->  [92.56388183977428]
F1 -->  {'F1': [0.9124304498069086], 'precision': [0.9076780605394614], 'recall': [0.9172429710583321]}
save model!
 24%|██▍       | 72/301 [6:55:27<23:36:35, 371.16s/it]step 11/275, epoch 72/301 --> loss:0.0744697093963623
step 21/275, epoch 72/301 --> loss:0.08433325290679931
step 31/275, epoch 72/301 --> loss:0.08453023433685303
step 41/275, epoch 72/301 --> loss:0.08452107310295105
step 51/275, epoch 72/301 --> loss:0.09132288098335266
step 61/275, epoch 72/301 --> loss:0.07763854265213013
step 71/275, epoch 72/301 --> loss:0.060200554132461545
step 81/275, epoch 72/301 --> loss:0.0959037959575653
step 91/275, epoch 72/301 --> loss:0.0687409520149231
step 101/275, epoch 72/301 --> loss:0.07511215806007385
step 111/275, epoch 72/301 --> loss:0.08279352188110352
step 121/275, epoch 72/301 --> loss:0.07774311900138856
step 131/275, epoch 72/301 --> loss:0.07874161005020142
step 141/275, epoch 72/301 --> loss:0.0811718225479126
step 151/275, epoch 72/301 --> loss:0.07797346115112305
step 161/275, epoch 72/301 --> loss:0.07905734777450561
step 171/275, epoch 72/301 --> loss:0.07502135634422302
step 181/275, epoch 72/301 --> loss:0.07138006687164307
step 191/275, epoch 72/301 --> loss:0.08246336579322815
step 201/275, epoch 72/301 --> loss:0.06967738866806031
step 211/275, epoch 72/301 --> loss:0.07571210265159607
step 221/275, epoch 72/301 --> loss:0.06648752093315125
step 231/275, epoch 72/301 --> loss:0.0827295422554016
step 241/275, epoch 72/301 --> loss:0.07745707035064697
step 251/275, epoch 72/301 --> loss:0.06964254975318909
step 261/275, epoch 72/301 --> loss:0.082343590259552
step 271/275, epoch 72/301 --> loss:0.08270456790924072
 24%|██▍       | 73/301 [7:00:44<22:28:34, 354.89s/it]step 11/275, epoch 73/301 --> loss:0.0802573323249817
step 21/275, epoch 73/301 --> loss:0.09188049435615539
step 31/275, epoch 73/301 --> loss:0.08963013291358948
step 41/275, epoch 73/301 --> loss:0.07639826536178589
step 51/275, epoch 73/301 --> loss:0.08022494912147522
step 61/275, epoch 73/301 --> loss:0.06898915767669678
step 71/275, epoch 73/301 --> loss:0.07488343119621277
step 81/275, epoch 73/301 --> loss:0.07513904571533203
step 91/275, epoch 73/301 --> loss:0.06793258786201477
step 101/275, epoch 73/301 --> loss:0.08275604248046875
step 111/275, epoch 73/301 --> loss:0.0829444944858551
step 121/275, epoch 73/301 --> loss:0.0757520318031311
step 131/275, epoch 73/301 --> loss:0.08975006341934204
step 141/275, epoch 73/301 --> loss:0.08608481287956238
step 151/275, epoch 73/301 --> loss:0.079263573884964
step 161/275, epoch 73/301 --> loss:0.07293244004249573
step 171/275, epoch 73/301 --> loss:0.07753356099128723
step 181/275, epoch 73/301 --> loss:0.08091084361076355
step 191/275, epoch 73/301 --> loss:0.08111360669136047
step 201/275, epoch 73/301 --> loss:0.08178331851959228
step 211/275, epoch 73/301 --> loss:0.09051349759101868
step 221/275, epoch 73/301 --> loss:0.08164184689521789
step 231/275, epoch 73/301 --> loss:0.07837535738945008
step 241/275, epoch 73/301 --> loss:0.0755354106426239
step 251/275, epoch 73/301 --> loss:0.07283286452293396
step 261/275, epoch 73/301 --> loss:0.06678431630134582
step 271/275, epoch 73/301 --> loss:0.06450724601745605
 25%|██▍       | 74/301 [7:06:01<21:39:23, 343.45s/it]step 11/275, epoch 74/301 --> loss:0.07759162187576293
step 21/275, epoch 74/301 --> loss:0.09568970799446105
step 31/275, epoch 74/301 --> loss:0.09003925919532776
step 41/275, epoch 74/301 --> loss:0.08526772856712342
step 51/275, epoch 74/301 --> loss:0.06978573203086853
step 61/275, epoch 74/301 --> loss:0.07246196269989014
step 71/275, epoch 74/301 --> loss:0.06794039011001587
step 81/275, epoch 74/301 --> loss:0.0718803882598877
step 91/275, epoch 74/301 --> loss:0.08621283769607543
step 101/275, epoch 74/301 --> loss:0.07356211543083191
step 111/275, epoch 74/301 --> loss:0.08192437887191772
step 121/275, epoch 74/301 --> loss:0.08026030659675598
step 131/275, epoch 74/301 --> loss:0.06965195536613464
step 141/275, epoch 74/301 --> loss:0.07357748746871948
step 151/275, epoch 74/301 --> loss:0.07581596970558166
step 161/275, epoch 74/301 --> loss:0.08631541132926941
step 171/275, epoch 74/301 --> loss:0.0742537796497345
step 181/275, epoch 74/301 --> loss:0.08980123400688171
step 191/275, epoch 74/301 --> loss:0.0917630672454834
step 201/275, epoch 74/301 --> loss:0.0807224154472351
step 211/275, epoch 74/301 --> loss:0.07450734376907349
step 221/275, epoch 74/301 --> loss:0.07452195286750793
step 231/275, epoch 74/301 --> loss:0.07713316082954406
step 241/275, epoch 74/301 --> loss:0.06622164249420166
step 251/275, epoch 74/301 --> loss:0.0725351870059967
step 261/275, epoch 74/301 --> loss:0.07529361248016357
step 271/275, epoch 74/301 --> loss:0.07994400858879089
 25%|██▍       | 75/301 [7:11:18<21:04:15, 335.64s/it]step 11/275, epoch 75/301 --> loss:0.0750552237033844
step 21/275, epoch 75/301 --> loss:0.10258220434188843
step 31/275, epoch 75/301 --> loss:0.06641151309013367
step 41/275, epoch 75/301 --> loss:0.07268471121788025
step 51/275, epoch 75/301 --> loss:0.07364303469657899
step 61/275, epoch 75/301 --> loss:0.08971401453018188
step 71/275, epoch 75/301 --> loss:0.0975568413734436
step 81/275, epoch 75/301 --> loss:0.10140077471733093
step 91/275, epoch 75/301 --> loss:0.07112579345703125
step 101/275, epoch 75/301 --> loss:0.08386138677597046
step 111/275, epoch 75/301 --> loss:0.07157561779022217
step 121/275, epoch 75/301 --> loss:0.07896727323532104
step 131/275, epoch 75/301 --> loss:0.0867429494857788
step 141/275, epoch 75/301 --> loss:0.06687512397766113
step 151/275, epoch 75/301 --> loss:0.07854781150817872
step 161/275, epoch 75/301 --> loss:0.06161569952964783
step 171/275, epoch 75/301 --> loss:0.07337691187858582
step 181/275, epoch 75/301 --> loss:0.08540874719619751
step 191/275, epoch 75/301 --> loss:0.07540881633758545
step 201/275, epoch 75/301 --> loss:0.07244908213615417
step 211/275, epoch 75/301 --> loss:0.0794927179813385
step 221/275, epoch 75/301 --> loss:0.08064429759979248
step 231/275, epoch 75/301 --> loss:0.09519818425178528
step 241/275, epoch 75/301 --> loss:0.07914631366729737
step 251/275, epoch 75/301 --> loss:0.0773603618144989
step 261/275, epoch 75/301 --> loss:0.05664607882499695
step 271/275, epoch 75/301 --> loss:0.07037497758865356
 25%|██▌       | 76/301 [7:16:38<20:40:28, 330.79s/it]step 11/275, epoch 76/301 --> loss:0.0743344783782959
step 21/275, epoch 76/301 --> loss:0.08309051990509034
step 31/275, epoch 76/301 --> loss:0.07143638730049133
step 41/275, epoch 76/301 --> loss:0.07672499418258667
step 51/275, epoch 76/301 --> loss:0.07518140077590943
step 61/275, epoch 76/301 --> loss:0.07766830325126647
step 71/275, epoch 76/301 --> loss:0.07109066247940063
step 81/275, epoch 76/301 --> loss:0.07824119329452514
step 91/275, epoch 76/301 --> loss:0.09803265333175659
step 101/275, epoch 76/301 --> loss:0.06936149001121521
step 111/275, epoch 76/301 --> loss:0.08248952627182007
step 121/275, epoch 76/301 --> loss:0.05971679091453552
step 131/275, epoch 76/301 --> loss:0.08029034733772278
step 141/275, epoch 76/301 --> loss:0.06788608431816101
step 151/275, epoch 76/301 --> loss:0.0892193615436554
step 161/275, epoch 76/301 --> loss:0.0986661434173584
step 171/275, epoch 76/301 --> loss:0.0820140540599823
step 181/275, epoch 76/301 --> loss:0.10015280246734619
step 191/275, epoch 76/301 --> loss:0.07277528643608093
step 201/275, epoch 76/301 --> loss:0.06855939626693726
step 211/275, epoch 76/301 --> loss:0.07541300654411316
step 221/275, epoch 76/301 --> loss:0.07450869679450989
step 231/275, epoch 76/301 --> loss:0.07640100717544555
step 241/275, epoch 76/301 --> loss:0.05932639837265015
step 251/275, epoch 76/301 --> loss:0.07490296959877014
step 261/275, epoch 76/301 --> loss:0.07306821346282959
step 271/275, epoch 76/301 --> loss:0.067313152551651
 26%|██▌       | 77/301 [7:21:59<20:24:05, 327.88s/it]step 11/275, epoch 77/301 --> loss:0.07549437880516052
step 21/275, epoch 77/301 --> loss:0.07422150373458862
step 31/275, epoch 77/301 --> loss:0.0670329213142395
step 41/275, epoch 77/301 --> loss:0.0772493064403534
step 51/275, epoch 77/301 --> loss:0.07227570414543152
step 61/275, epoch 77/301 --> loss:0.07395397424697876
step 71/275, epoch 77/301 --> loss:0.0758030891418457
step 81/275, epoch 77/301 --> loss:0.08319722414016724
step 91/275, epoch 77/301 --> loss:0.0765946626663208
step 101/275, epoch 77/301 --> loss:0.07757835984230041
step 111/275, epoch 77/301 --> loss:0.07403244972229003
step 121/275, epoch 77/301 --> loss:0.06754444241523742
step 131/275, epoch 77/301 --> loss:0.06354340314865112
step 141/275, epoch 77/301 --> loss:0.06494754552841187
step 151/275, epoch 77/301 --> loss:0.06626809239387513
step 161/275, epoch 77/301 --> loss:0.07780166268348694
step 171/275, epoch 77/301 --> loss:0.08767822980880738
step 181/275, epoch 77/301 --> loss:0.07870641946792603
step 191/275, epoch 77/301 --> loss:0.07006993889808655
step 201/275, epoch 77/301 --> loss:0.07764429450035096
step 211/275, epoch 77/301 --> loss:0.08351571559906006
step 221/275, epoch 77/301 --> loss:0.09184298515319825
step 231/275, epoch 77/301 --> loss:0.09053134322166442
step 241/275, epoch 77/301 --> loss:0.08168593049049377
step 251/275, epoch 77/301 --> loss:0.08559476137161255
step 261/275, epoch 77/301 --> loss:0.08053563237190246
step 271/275, epoch 77/301 --> loss:0.07467399835586548
 26%|██▌       | 78/301 [7:27:19<20:09:52, 325.53s/it]step 11/275, epoch 78/301 --> loss:0.08709043860435486
step 21/275, epoch 78/301 --> loss:0.0794718861579895
step 31/275, epoch 78/301 --> loss:0.07150166034698487
step 41/275, epoch 78/301 --> loss:0.06349865198135377
step 51/275, epoch 78/301 --> loss:0.09002774357795715
step 61/275, epoch 78/301 --> loss:0.07109379172325134
step 71/275, epoch 78/301 --> loss:0.08453885316848755
step 81/275, epoch 78/301 --> loss:0.06344305276870728
step 91/275, epoch 78/301 --> loss:0.07345237731933593
step 101/275, epoch 78/301 --> loss:0.08393164873123168
step 111/275, epoch 78/301 --> loss:0.07643819451332093
step 121/275, epoch 78/301 --> loss:0.07062898874282837
step 131/275, epoch 78/301 --> loss:0.06725125312805176
step 141/275, epoch 78/301 --> loss:0.07269888520240783
step 151/275, epoch 78/301 --> loss:0.06794173121452332
step 161/275, epoch 78/301 --> loss:0.08682377934455872
step 171/275, epoch 78/301 --> loss:0.08453920483589172
step 181/275, epoch 78/301 --> loss:0.08679906725883484
step 191/275, epoch 78/301 --> loss:0.08619171380996704
step 201/275, epoch 78/301 --> loss:0.07063730359077454
step 211/275, epoch 78/301 --> loss:0.07179345488548279
step 221/275, epoch 78/301 --> loss:0.07250398397445679
step 231/275, epoch 78/301 --> loss:0.07069501876831055
step 241/275, epoch 78/301 --> loss:0.07214857339859009
step 251/275, epoch 78/301 --> loss:0.08201203346252442
step 261/275, epoch 78/301 --> loss:0.0854637861251831
step 271/275, epoch 78/301 --> loss:0.08000798225402832
 26%|██▌       | 79/301 [7:32:40<19:59:06, 324.08s/it]step 11/275, epoch 79/301 --> loss:0.06891880035400391
step 21/275, epoch 79/301 --> loss:0.07194451093673707
step 31/275, epoch 79/301 --> loss:0.0721649169921875
step 41/275, epoch 79/301 --> loss:0.0684499204158783
step 51/275, epoch 79/301 --> loss:0.075121408700943
step 61/275, epoch 79/301 --> loss:0.06409296989440919
step 71/275, epoch 79/301 --> loss:0.06938594579696655
step 81/275, epoch 79/301 --> loss:0.07056511044502259
step 91/275, epoch 79/301 --> loss:0.07398057579994202
step 101/275, epoch 79/301 --> loss:0.09035784006118774
step 111/275, epoch 79/301 --> loss:0.08874301910400391
step 121/275, epoch 79/301 --> loss:0.0696541428565979
step 131/275, epoch 79/301 --> loss:0.07080390453338622
step 141/275, epoch 79/301 --> loss:0.1019405722618103
step 151/275, epoch 79/301 --> loss:0.06931341290473939
step 161/275, epoch 79/301 --> loss:0.06866949200630187
step 171/275, epoch 79/301 --> loss:0.08842484951019287
step 181/275, epoch 79/301 --> loss:0.07760713696479797
step 191/275, epoch 79/301 --> loss:0.07709616422653198
step 201/275, epoch 79/301 --> loss:0.06703171730041504
step 211/275, epoch 79/301 --> loss:0.07333419919013977
step 221/275, epoch 79/301 --> loss:0.07180660963058472
step 231/275, epoch 79/301 --> loss:0.07385569214820861
step 241/275, epoch 79/301 --> loss:0.06865656971931458
step 251/275, epoch 79/301 --> loss:0.07241839766502381
step 261/275, epoch 79/301 --> loss:0.07603517770767212
step 271/275, epoch 79/301 --> loss:0.07229076027870178
 27%|██▋       | 80/301 [7:38:02<19:52:00, 323.62s/it]step 11/275, epoch 80/301 --> loss:0.07366420030593872
step 21/275, epoch 80/301 --> loss:0.07417104244232178
step 31/275, epoch 80/301 --> loss:0.07329006195068359
step 41/275, epoch 80/301 --> loss:0.07863262295722961
step 51/275, epoch 80/301 --> loss:0.07209550738334655
step 61/275, epoch 80/301 --> loss:0.07530581355094909
step 71/275, epoch 80/301 --> loss:0.0751662015914917
step 81/275, epoch 80/301 --> loss:0.07401155829429626
step 91/275, epoch 80/301 --> loss:0.07191997766494751
step 101/275, epoch 80/301 --> loss:0.0689183533191681
step 111/275, epoch 80/301 --> loss:0.07365714907646179
step 121/275, epoch 80/301 --> loss:0.07059001326560974
step 131/275, epoch 80/301 --> loss:0.08092982769012451
step 141/275, epoch 80/301 --> loss:0.06879108548164367
step 151/275, epoch 80/301 --> loss:0.06957688331604003
step 161/275, epoch 80/301 --> loss:0.07987507581710815
step 171/275, epoch 80/301 --> loss:0.07212014198303222
step 181/275, epoch 80/301 --> loss:0.08138096332550049
step 191/275, epoch 80/301 --> loss:0.06624870896339416
step 201/275, epoch 80/301 --> loss:0.06922956109046936
step 211/275, epoch 80/301 --> loss:0.05885140895843506
step 221/275, epoch 80/301 --> loss:0.08096776604652405
step 231/275, epoch 80/301 --> loss:0.08418168425559998
step 241/275, epoch 80/301 --> loss:0.06893827319145203
step 251/275, epoch 80/301 --> loss:0.07568172812461853
step 261/275, epoch 80/301 --> loss:0.06885976791381836
step 271/275, epoch 80/301 --> loss:0.08983646631240845
step 11/275, epoch 81/301 --> loss:0.07899917364120483
step 21/275, epoch 81/301 --> loss:0.08447461128234864
step 31/275, epoch 81/301 --> loss:0.07784458398818969
step 41/275, epoch 81/301 --> loss:0.08296740651130677
step 51/275, epoch 81/301 --> loss:0.07255268096923828
step 61/275, epoch 81/301 --> loss:0.07141149640083314
step 71/275, epoch 81/301 --> loss:0.07357677221298217
step 81/275, epoch 81/301 --> loss:0.06894646286964416
step 91/275, epoch 81/301 --> loss:0.06667405962944031
step 101/275, epoch 81/301 --> loss:0.08059346675872803
step 111/275, epoch 81/301 --> loss:0.07593677639961242
step 121/275, epoch 81/301 --> loss:0.07601614594459534
step 131/275, epoch 81/301 --> loss:0.07591054439544678
step 141/275, epoch 81/301 --> loss:0.06875282526016235
step 151/275, epoch 81/301 --> loss:0.0619586169719696
step 161/275, epoch 81/301 --> loss:0.07538593411445618
step 171/275, epoch 81/301 --> loss:0.07783620953559875
step 181/275, epoch 81/301 --> loss:0.07059485316276551
step 191/275, epoch 81/301 --> loss:0.05755802392959595
step 201/275, epoch 81/301 --> loss:0.06538094878196717
step 211/275, epoch 81/301 --> loss:0.07430541515350342
step 221/275, epoch 81/301 --> loss:0.07787553071975709
step 231/275, epoch 81/301 --> loss:0.075813627243042
step 241/275, epoch 81/301 --> loss:0.07441331744194031
step 251/275, epoch 81/301 --> loss:0.06857501268386841
step 261/275, epoch 81/301 --> loss:0.06849804520606995
step 271/275, epoch 81/301 --> loss:0.06996044516563416
########## train dataset ##########
PLout index:  2
acc -->  [93.96656971562379]
F1 -->  {'F1': [0.9272685204969351], 'precision': [0.9241066728870195], 'recall': [0.9304621476934432]}
########## eval dataset ##########
 27%|██▋       | 81/301 [7:47:22<24:06:32, 394.51s/it]PLout index:  2
acc -->  [92.45875653633593]
F1 -->  {'F1': [0.9108836302272839], 'precision': [0.9092693127522624], 'recall': [0.9125137255894951]}
 27%|██▋       | 82/301 [7:52:39<22:35:08, 371.27s/it]step 11/275, epoch 82/301 --> loss:0.09080544114112854
step 21/275, epoch 82/301 --> loss:0.0692765772342682
step 31/275, epoch 82/301 --> loss:0.0720597267150879
step 41/275, epoch 82/301 --> loss:0.05959989428520203
step 51/275, epoch 82/301 --> loss:0.06484129428863525
step 61/275, epoch 82/301 --> loss:0.06938875913619995
step 71/275, epoch 82/301 --> loss:0.07275844812393188
step 81/275, epoch 82/301 --> loss:0.07125178575515748
step 91/275, epoch 82/301 --> loss:0.07295592427253723
step 101/275, epoch 82/301 --> loss:0.08264577984809876
step 111/275, epoch 82/301 --> loss:0.08493877053260804
step 121/275, epoch 82/301 --> loss:0.06207899451255798
step 131/275, epoch 82/301 --> loss:0.06908446550369263
step 141/275, epoch 82/301 --> loss:0.06325576901435852
step 151/275, epoch 82/301 --> loss:0.06043859124183655
step 161/275, epoch 82/301 --> loss:0.08495107293128967
step 171/275, epoch 82/301 --> loss:0.07488474249839783
step 181/275, epoch 82/301 --> loss:0.07283914089202881
step 191/275, epoch 82/301 --> loss:0.06310532093048096
step 201/275, epoch 82/301 --> loss:0.06210982799530029
step 211/275, epoch 82/301 --> loss:0.07013740539550781
step 221/275, epoch 82/301 --> loss:0.09594225287437438
step 231/275, epoch 82/301 --> loss:0.08126800060272217
step 241/275, epoch 82/301 --> loss:0.07676359415054321
step 251/275, epoch 82/301 --> loss:0.0724814772605896
step 261/275, epoch 82/301 --> loss:0.07242152094841003
step 271/275, epoch 82/301 --> loss:0.07054017782211304
 28%|██▊       | 83/301 [7:57:56<21:29:47, 354.99s/it]step 11/275, epoch 83/301 --> loss:0.057217979431152345
step 21/275, epoch 83/301 --> loss:0.06062573194503784
step 31/275, epoch 83/301 --> loss:0.07115183472633362
step 41/275, epoch 83/301 --> loss:0.06460660099983215
step 51/275, epoch 83/301 --> loss:0.061480087041854856
step 61/275, epoch 83/301 --> loss:0.07211125493049622
step 71/275, epoch 83/301 --> loss:0.08706588745117187
step 81/275, epoch 83/301 --> loss:0.07560184001922607
step 91/275, epoch 83/301 --> loss:0.06760565638542175
step 101/275, epoch 83/301 --> loss:0.07260034680366516
step 111/275, epoch 83/301 --> loss:0.06770999431610107
step 121/275, epoch 83/301 --> loss:0.06441653966903686
step 131/275, epoch 83/301 --> loss:0.07828489542007447
step 141/275, epoch 83/301 --> loss:0.0800796926021576
step 151/275, epoch 83/301 --> loss:0.07961024045944214
step 161/275, epoch 83/301 --> loss:0.07762717604637145
step 171/275, epoch 83/301 --> loss:0.07670274376869202
step 181/275, epoch 83/301 --> loss:0.06593208312988282
step 191/275, epoch 83/301 --> loss:0.07274473905563354
step 201/275, epoch 83/301 --> loss:0.06200907230377197
step 211/275, epoch 83/301 --> loss:0.06449422240257263
step 221/275, epoch 83/301 --> loss:0.08229933977127075
step 231/275, epoch 83/301 --> loss:0.07313682436943054
step 241/275, epoch 83/301 --> loss:0.08198214769363403
step 251/275, epoch 83/301 --> loss:0.06942567825317383
step 261/275, epoch 83/301 --> loss:0.07913858890533447
step 271/275, epoch 83/301 --> loss:0.07754933834075928
 28%|██▊       | 84/301 [8:03:13<20:42:28, 343.54s/it]step 11/275, epoch 84/301 --> loss:0.0729927122592926
step 21/275, epoch 84/301 --> loss:0.08840320110321045
step 31/275, epoch 84/301 --> loss:0.057850205898284913
step 41/275, epoch 84/301 --> loss:0.07358680963516236
step 51/275, epoch 84/301 --> loss:0.06815479993820191
step 61/275, epoch 84/301 --> loss:0.06840715408325196
step 71/275, epoch 84/301 --> loss:0.07961033582687378
step 81/275, epoch 84/301 --> loss:0.06422351002693176
step 91/275, epoch 84/301 --> loss:0.07246833443641662
step 101/275, epoch 84/301 --> loss:0.06857312321662903
step 111/275, epoch 84/301 --> loss:0.07460178136825561
step 121/275, epoch 84/301 --> loss:0.06800320148468017
step 131/275, epoch 84/301 --> loss:0.06116098165512085
step 141/275, epoch 84/301 --> loss:0.05696020126342773
step 151/275, epoch 84/301 --> loss:0.07786793112754822
step 161/275, epoch 84/301 --> loss:0.06679843068122863
step 171/275, epoch 84/301 --> loss:0.07225618958473205
step 181/275, epoch 84/301 --> loss:0.07194122672080994
step 191/275, epoch 84/301 --> loss:0.06664034724235535
step 201/275, epoch 84/301 --> loss:0.06966884136199951
step 211/275, epoch 84/301 --> loss:0.07633548974990845
step 221/275, epoch 84/301 --> loss:0.06723556518554688
step 231/275, epoch 84/301 --> loss:0.07569669485092163
step 241/275, epoch 84/301 --> loss:0.06826704740524292
step 251/275, epoch 84/301 --> loss:0.08243567347526551
step 261/275, epoch 84/301 --> loss:0.08117611408233642
step 271/275, epoch 84/301 --> loss:0.08192220330238342
 28%|██▊       | 85/301 [8:08:31<20:09:41, 336.02s/it]step 11/275, epoch 85/301 --> loss:0.07841458320617675
step 21/275, epoch 85/301 --> loss:0.06871556639671325
step 31/275, epoch 85/301 --> loss:0.07371748089790345
step 41/275, epoch 85/301 --> loss:0.07358847260475158
step 51/275, epoch 85/301 --> loss:0.07838718891143799
step 61/275, epoch 85/301 --> loss:0.067085862159729
step 71/275, epoch 85/301 --> loss:0.06668012142181397
step 81/275, epoch 85/301 --> loss:0.0659641981124878
step 91/275, epoch 85/301 --> loss:0.06583552360534668
step 101/275, epoch 85/301 --> loss:0.07287302613258362
step 111/275, epoch 85/301 --> loss:0.0691758155822754
step 121/275, epoch 85/301 --> loss:0.08096585273742676
step 131/275, epoch 85/301 --> loss:0.057161033153533936
step 141/275, epoch 85/301 --> loss:0.07329899072647095
step 151/275, epoch 85/301 --> loss:0.06958997249603271
step 161/275, epoch 85/301 --> loss:0.08301050662994384
step 171/275, epoch 85/301 --> loss:0.07130289077758789
step 181/275, epoch 85/301 --> loss:0.06987444758415222
step 191/275, epoch 85/301 --> loss:0.07296845316886902
step 201/275, epoch 85/301 --> loss:0.07639861702919007
step 211/275, epoch 85/301 --> loss:0.07382673025131226
step 221/275, epoch 85/301 --> loss:0.08012144565582276
step 231/275, epoch 85/301 --> loss:0.06150047779083252
step 241/275, epoch 85/301 --> loss:0.05851572155952454
step 251/275, epoch 85/301 --> loss:0.06829158067703248
step 261/275, epoch 85/301 --> loss:0.07277229428291321
step 271/275, epoch 85/301 --> loss:0.0798462986946106
 29%|██▊       | 86/301 [8:13:52<19:47:11, 331.31s/it]step 11/275, epoch 86/301 --> loss:0.0622886598110199
step 21/275, epoch 86/301 --> loss:0.08581736087799072
step 31/275, epoch 86/301 --> loss:0.07415001988410949
step 41/275, epoch 86/301 --> loss:0.07609740495681763
step 51/275, epoch 86/301 --> loss:0.07729342579841614
step 61/275, epoch 86/301 --> loss:0.06763439178466797
step 71/275, epoch 86/301 --> loss:0.06867414116859435
step 81/275, epoch 86/301 --> loss:0.07572889924049378
step 91/275, epoch 86/301 --> loss:0.06444326043128967
step 101/275, epoch 86/301 --> loss:0.06931109428405761
step 111/275, epoch 86/301 --> loss:0.07325160503387451
step 121/275, epoch 86/301 --> loss:0.0771576464176178
step 131/275, epoch 86/301 --> loss:0.06835753917694092
step 141/275, epoch 86/301 --> loss:0.054084545373916625
step 151/275, epoch 86/301 --> loss:0.07054861187934876
step 161/275, epoch 86/301 --> loss:0.0746628224849701
step 171/275, epoch 86/301 --> loss:0.07183692455291749
step 181/275, epoch 86/301 --> loss:0.06553816199302673
step 191/275, epoch 86/301 --> loss:0.06153934597969055
step 201/275, epoch 86/301 --> loss:0.07681532502174378
step 211/275, epoch 86/301 --> loss:0.08419533371925354
step 221/275, epoch 86/301 --> loss:0.08644230961799622
step 231/275, epoch 86/301 --> loss:0.06692619323730468
step 241/275, epoch 86/301 --> loss:0.08754202127456664
step 251/275, epoch 86/301 --> loss:0.06989616751670838
step 261/275, epoch 86/301 --> loss:0.0669610321521759
step 271/275, epoch 86/301 --> loss:0.07889514565467834
 29%|██▉       | 87/301 [8:19:13<19:30:52, 328.28s/it]step 11/275, epoch 87/301 --> loss:0.08383074998855591
step 21/275, epoch 87/301 --> loss:0.07672527432441711
step 31/275, epoch 87/301 --> loss:0.07371892929077148
step 41/275, epoch 87/301 --> loss:0.07382596731185913
step 51/275, epoch 87/301 --> loss:0.06096070408821106
step 61/275, epoch 87/301 --> loss:0.06941577792167664
step 71/275, epoch 87/301 --> loss:0.09023631811141967
step 81/275, epoch 87/301 --> loss:0.07835279703140259
step 91/275, epoch 87/301 --> loss:0.06981832981109619
step 101/275, epoch 87/301 --> loss:0.07837930917739869
step 111/275, epoch 87/301 --> loss:0.06703398227691651
step 121/275, epoch 87/301 --> loss:0.07319644093513489
step 131/275, epoch 87/301 --> loss:0.06849985122680664
step 141/275, epoch 87/301 --> loss:0.06048272848129273
step 151/275, epoch 87/301 --> loss:0.06754639148712158
step 161/275, epoch 87/301 --> loss:0.07369550466537475
step 171/275, epoch 87/301 --> loss:0.07231932878494263
step 181/275, epoch 87/301 --> loss:0.07567032575607299
step 191/275, epoch 87/301 --> loss:0.0567659854888916
step 201/275, epoch 87/301 --> loss:0.056949108839035034
step 211/275, epoch 87/301 --> loss:0.0693727195262909
step 221/275, epoch 87/301 --> loss:0.06107763648033142
step 231/275, epoch 87/301 --> loss:0.08256370425224305
step 241/275, epoch 87/301 --> loss:0.07101200819015503
step 251/275, epoch 87/301 --> loss:0.07166601419448852
step 261/275, epoch 87/301 --> loss:0.06667174100875854
step 271/275, epoch 87/301 --> loss:0.05282686352729797
 29%|██▉       | 88/301 [8:24:33<19:17:05, 325.94s/it]step 11/275, epoch 88/301 --> loss:0.06553686261177064
step 21/275, epoch 88/301 --> loss:0.07598631381988526
step 31/275, epoch 88/301 --> loss:0.062379980087280275
step 41/275, epoch 88/301 --> loss:0.07429863810539246
step 51/275, epoch 88/301 --> loss:0.07648442387580871
step 61/275, epoch 88/301 --> loss:0.06339017152786255
step 71/275, epoch 88/301 --> loss:0.06603770852088928
step 81/275, epoch 88/301 --> loss:0.07305439710617065
step 91/275, epoch 88/301 --> loss:0.05846858024597168
step 101/275, epoch 88/301 --> loss:0.06160224080085754
step 111/275, epoch 88/301 --> loss:0.06589669585227967
step 121/275, epoch 88/301 --> loss:0.07667888998985291
step 131/275, epoch 88/301 --> loss:0.06861356496810914
step 141/275, epoch 88/301 --> loss:0.07489404082298279
step 151/275, epoch 88/301 --> loss:0.06842710971832275
step 161/275, epoch 88/301 --> loss:0.07584413886070251
step 171/275, epoch 88/301 --> loss:0.06735100746154785
step 181/275, epoch 88/301 --> loss:0.06242225170135498
step 191/275, epoch 88/301 --> loss:0.07055664658546448
step 201/275, epoch 88/301 --> loss:0.06897118091583251
step 211/275, epoch 88/301 --> loss:0.07355024814605712
step 221/275, epoch 88/301 --> loss:0.07033278346061707
step 231/275, epoch 88/301 --> loss:0.06864206194877624
step 241/275, epoch 88/301 --> loss:0.06364304423332215
step 251/275, epoch 88/301 --> loss:0.07151406407356262
step 261/275, epoch 88/301 --> loss:0.06927552819252014
step 271/275, epoch 88/301 --> loss:0.06063005328178406
 30%|██▉       | 89/301 [8:29:54<19:05:53, 324.31s/it]step 11/275, epoch 89/301 --> loss:0.06634389162063599
step 21/275, epoch 89/301 --> loss:0.06666606068611144
step 31/275, epoch 89/301 --> loss:0.08536450266838073
step 41/275, epoch 89/301 --> loss:0.0655684232711792
step 51/275, epoch 89/301 --> loss:0.07092225551605225
step 61/275, epoch 89/301 --> loss:0.06709847450256348
step 71/275, epoch 89/301 --> loss:0.07035640478134156
step 81/275, epoch 89/301 --> loss:0.07282321453094483
step 91/275, epoch 89/301 --> loss:0.07928441166877746
step 101/275, epoch 89/301 --> loss:0.06650575995445251
step 111/275, epoch 89/301 --> loss:0.06502598524093628
step 121/275, epoch 89/301 --> loss:0.07797359228134156
step 131/275, epoch 89/301 --> loss:0.06726910471916199
step 141/275, epoch 89/301 --> loss:0.07079890966415406
step 151/275, epoch 89/301 --> loss:0.06847441792488099
step 161/275, epoch 89/301 --> loss:0.0641915738582611
step 171/275, epoch 89/301 --> loss:0.0780531644821167
step 181/275, epoch 89/301 --> loss:0.06921932101249695
step 191/275, epoch 89/301 --> loss:0.07212772965431213
step 201/275, epoch 89/301 --> loss:0.06894991993904113
step 211/275, epoch 89/301 --> loss:0.07162762880325317
step 221/275, epoch 89/301 --> loss:0.07327948808670044
step 231/275, epoch 89/301 --> loss:0.07452933788299561
step 241/275, epoch 89/301 --> loss:0.06131473183631897
step 251/275, epoch 89/301 --> loss:0.0698962688446045
step 261/275, epoch 89/301 --> loss:0.07414568662643432
step 271/275, epoch 89/301 --> loss:0.07405109405517578
 30%|██▉       | 90/301 [8:35:15<18:56:37, 323.21s/it]step 11/275, epoch 90/301 --> loss:0.06854467391967774
step 21/275, epoch 90/301 --> loss:0.060571706295013426
step 31/275, epoch 90/301 --> loss:0.06981664299964904
step 41/275, epoch 90/301 --> loss:0.0736128032207489
step 51/275, epoch 90/301 --> loss:0.07234891653060913
step 61/275, epoch 90/301 --> loss:0.05875447392463684
step 71/275, epoch 90/301 --> loss:0.06272909045219421
step 81/275, epoch 90/301 --> loss:0.07693229913711548
step 91/275, epoch 90/301 --> loss:0.07287794351577759
step 101/275, epoch 90/301 --> loss:0.08567926287651062
step 111/275, epoch 90/301 --> loss:0.06980071663856506
step 121/275, epoch 90/301 --> loss:0.06590327620506287
step 131/275, epoch 90/301 --> loss:0.06773400902748108
step 141/275, epoch 90/301 --> loss:0.07283318638801575
step 151/275, epoch 90/301 --> loss:0.06899396181106568
step 161/275, epoch 90/301 --> loss:0.06362878680229186
step 171/275, epoch 90/301 --> loss:0.05722452402114868
step 181/275, epoch 90/301 --> loss:0.06904478073120117
step 191/275, epoch 90/301 --> loss:0.07196598052978516
step 201/275, epoch 90/301 --> loss:0.060820019245147704
step 211/275, epoch 90/301 --> loss:0.069716078042984
step 221/275, epoch 90/301 --> loss:0.055982071161270144
step 231/275, epoch 90/301 --> loss:0.06638154983520508
step 241/275, epoch 90/301 --> loss:0.06554622650146484
step 251/275, epoch 90/301 --> loss:0.09763435125350953
step 261/275, epoch 90/301 --> loss:0.07420777082443238
step 271/275, epoch 90/301 --> loss:0.06428334712982178
step 11/275, epoch 91/301 --> loss:0.06724187731742859
step 21/275, epoch 91/301 --> loss:0.07993667721748351
step 31/275, epoch 91/301 --> loss:0.0714140236377716
step 41/275, epoch 91/301 --> loss:0.06286773681640626
step 51/275, epoch 91/301 --> loss:0.0723842978477478
step 61/275, epoch 91/301 --> loss:0.05881727337837219
step 71/275, epoch 91/301 --> loss:0.0720447838306427
step 81/275, epoch 91/301 --> loss:0.09025049209594727
step 91/275, epoch 91/301 --> loss:0.06175147294998169
step 101/275, epoch 91/301 --> loss:0.06458033323287964
step 111/275, epoch 91/301 --> loss:0.07547814249992371
step 121/275, epoch 91/301 --> loss:0.06886181831359864
step 131/275, epoch 91/301 --> loss:0.06587360501289367
step 141/275, epoch 91/301 --> loss:0.07957571148872375
step 151/275, epoch 91/301 --> loss:0.056067931652069095
step 161/275, epoch 91/301 --> loss:0.07390702366828919
step 171/275, epoch 91/301 --> loss:0.05980984568595886
step 181/275, epoch 91/301 --> loss:0.07654252052307128
step 191/275, epoch 91/301 --> loss:0.07592192888259888
step 201/275, epoch 91/301 --> loss:0.07354984283447266
step 211/275, epoch 91/301 --> loss:0.06442067623138428
step 221/275, epoch 91/301 --> loss:0.07799837589263917
step 231/275, epoch 91/301 --> loss:0.067477947473526
step 241/275, epoch 91/301 --> loss:0.06312577128410339
step 251/275, epoch 91/301 --> loss:0.06970757842063904
step 261/275, epoch 91/301 --> loss:0.06930322647094726
step 271/275, epoch 91/301 --> loss:0.06528624892234802
########## train dataset ##########
PLout index:  2
acc -->  [93.90109437354855]
F1 -->  {'F1': [0.9280908752156626], 'precision': [0.905217885223462], 'recall': [0.9521602548020276]}
########## eval dataset ##########
 30%|███       | 91/301 [8:44:33<22:58:00, 393.72s/it]PLout index:  2
acc -->  [92.16215068205307]
F1 -->  {'F1': [0.9094511401246408], 'precision': [0.8880394373679623], 'recall': [0.9319313715058933]}
 31%|███       | 92/301 [8:49:53<21:34:29, 371.62s/it]step 11/275, epoch 92/301 --> loss:0.07496342062950134
step 21/275, epoch 92/301 --> loss:0.07110703587532044
step 31/275, epoch 92/301 --> loss:0.06283006668090821
step 41/275, epoch 92/301 --> loss:0.06569744944572449
step 51/275, epoch 92/301 --> loss:0.06626083850860595
step 61/275, epoch 92/301 --> loss:0.054923468828201295
step 71/275, epoch 92/301 --> loss:0.0753184974193573
step 81/275, epoch 92/301 --> loss:0.057529288530349734
step 91/275, epoch 92/301 --> loss:0.09251810312271118
step 101/275, epoch 92/301 --> loss:0.06856011152267456
step 111/275, epoch 92/301 --> loss:0.07734597325325013
step 121/275, epoch 92/301 --> loss:0.07764056324958801
step 131/275, epoch 92/301 --> loss:0.08594563603401184
step 141/275, epoch 92/301 --> loss:0.058310550451278684
step 151/275, epoch 92/301 --> loss:0.07255218029022217
step 161/275, epoch 92/301 --> loss:0.06300885677337646
step 171/275, epoch 92/301 --> loss:0.06865957975387574
step 181/275, epoch 92/301 --> loss:0.07584632635116577
step 191/275, epoch 92/301 --> loss:0.061403053998947146
step 201/275, epoch 92/301 --> loss:0.06817166805267334
step 211/275, epoch 92/301 --> loss:0.06752610206604004
step 221/275, epoch 92/301 --> loss:0.07313583493232727
step 231/275, epoch 92/301 --> loss:0.06264916062355042
step 241/275, epoch 92/301 --> loss:0.060577183961868286
step 251/275, epoch 92/301 --> loss:0.06473472714424133
step 261/275, epoch 92/301 --> loss:0.07804673910140991
step 271/275, epoch 92/301 --> loss:0.05666947364807129
 31%|███       | 93/301 [8:55:10<20:31:32, 355.25s/it]step 11/275, epoch 93/301 --> loss:0.06966838836669922
step 21/275, epoch 93/301 --> loss:0.07029998898506165
step 31/275, epoch 93/301 --> loss:0.06704961657524108
step 41/275, epoch 93/301 --> loss:0.08173415064811707
step 51/275, epoch 93/301 --> loss:0.07575138807296752
step 61/275, epoch 93/301 --> loss:0.059474581480026247
step 71/275, epoch 93/301 --> loss:0.07306343913078309
step 81/275, epoch 93/301 --> loss:0.05544413328170776
step 91/275, epoch 93/301 --> loss:0.07867116928100586
step 101/275, epoch 93/301 --> loss:0.061265182495117185
step 111/275, epoch 93/301 --> loss:0.06841704249382019
step 121/275, epoch 93/301 --> loss:0.06454148888587952
step 131/275, epoch 93/301 --> loss:0.06727410554885864
step 141/275, epoch 93/301 --> loss:0.07384476065635681
step 151/275, epoch 93/301 --> loss:0.07866287231445312
step 161/275, epoch 93/301 --> loss:0.07811033129692077
step 171/275, epoch 93/301 --> loss:0.07503149509429932
step 181/275, epoch 93/301 --> loss:0.06663976907730103
step 191/275, epoch 93/301 --> loss:0.057812005281448364
step 201/275, epoch 93/301 --> loss:0.06591763496398925
step 211/275, epoch 93/301 --> loss:0.07085351347923279
step 221/275, epoch 93/301 --> loss:0.06464903950691223
step 231/275, epoch 93/301 --> loss:0.0678468644618988
step 241/275, epoch 93/301 --> loss:0.08279322981834411
step 251/275, epoch 93/301 --> loss:0.07930763959884643
step 261/275, epoch 93/301 --> loss:0.06161408424377442
step 271/275, epoch 93/301 --> loss:0.07423779368400574
 31%|███       | 94/301 [9:00:28<19:46:47, 344.00s/it]step 11/275, epoch 94/301 --> loss:0.07434548735618592
step 21/275, epoch 94/301 --> loss:0.06267928481101989
step 31/275, epoch 94/301 --> loss:0.07861340641975403
step 41/275, epoch 94/301 --> loss:0.07252762317657471
step 51/275, epoch 94/301 --> loss:0.06659005284309387
step 61/275, epoch 94/301 --> loss:0.06428205370903015
step 71/275, epoch 94/301 --> loss:0.06584683060646057
step 81/275, epoch 94/301 --> loss:0.0754985272884369
step 91/275, epoch 94/301 --> loss:0.06704210042953491
step 101/275, epoch 94/301 --> loss:0.07017674446105956
step 111/275, epoch 94/301 --> loss:0.0561332643032074
step 121/275, epoch 94/301 --> loss:0.06930047869682313
step 131/275, epoch 94/301 --> loss:0.06871994733810424
step 141/275, epoch 94/301 --> loss:0.06728333234786987
step 151/275, epoch 94/301 --> loss:0.06486944556236267
step 161/275, epoch 94/301 --> loss:0.07029986381530762
step 171/275, epoch 94/301 --> loss:0.0735526442527771
step 181/275, epoch 94/301 --> loss:0.06264495253562927
step 191/275, epoch 94/301 --> loss:0.07537080645561219
step 201/275, epoch 94/301 --> loss:0.07949845194816589
step 211/275, epoch 94/301 --> loss:0.056010866165161134
step 221/275, epoch 94/301 --> loss:0.05935815572738647
step 231/275, epoch 94/301 --> loss:0.06963502764701843
step 241/275, epoch 94/301 --> loss:0.055948537588119504
step 251/275, epoch 94/301 --> loss:0.05883354544639587
step 261/275, epoch 94/301 --> loss:0.05629609823226929
step 271/275, epoch 94/301 --> loss:0.05920717716217041
 32%|███▏      | 95/301 [9:05:48<19:16:57, 336.98s/it]step 11/275, epoch 95/301 --> loss:0.06571020483970642
step 21/275, epoch 95/301 --> loss:0.06952199339866638
step 31/275, epoch 95/301 --> loss:0.05909466147422791
step 41/275, epoch 95/301 --> loss:0.06500893235206603
step 51/275, epoch 95/301 --> loss:0.06251805424690246
step 61/275, epoch 95/301 --> loss:0.07539933323860168
step 71/275, epoch 95/301 --> loss:0.06573799252510071
step 81/275, epoch 95/301 --> loss:0.06958907842636108
step 91/275, epoch 95/301 --> loss:0.07112868428230286
step 101/275, epoch 95/301 --> loss:0.06794174909591674
step 111/275, epoch 95/301 --> loss:0.07606033086776734
step 121/275, epoch 95/301 --> loss:0.057299095392227176
step 131/275, epoch 95/301 --> loss:0.07073492407798768
step 141/275, epoch 95/301 --> loss:0.06317371129989624
step 151/275, epoch 95/301 --> loss:0.07113075852394105
step 161/275, epoch 95/301 --> loss:0.06915587186813354
step 171/275, epoch 95/301 --> loss:0.06320810914039612
step 181/275, epoch 95/301 --> loss:0.07394710183143616
step 191/275, epoch 95/301 --> loss:0.06550408601760864
step 201/275, epoch 95/301 --> loss:0.058233129978179934
step 211/275, epoch 95/301 --> loss:0.05844417214393616
step 221/275, epoch 95/301 --> loss:0.06158357858657837
step 231/275, epoch 95/301 --> loss:0.06976013779640197
step 241/275, epoch 95/301 --> loss:0.08140562772750855
step 251/275, epoch 95/301 --> loss:0.07027609348297119
step 261/275, epoch 95/301 --> loss:0.07285493612289429
step 271/275, epoch 95/301 --> loss:0.06958732008934021
 32%|███▏      | 96/301 [9:11:10<18:55:41, 332.40s/it]step 11/275, epoch 96/301 --> loss:0.06372878551483155
step 21/275, epoch 96/301 --> loss:0.07592955827713013
step 31/275, epoch 96/301 --> loss:0.062398219108581544
step 41/275, epoch 96/301 --> loss:0.0770127534866333
step 51/275, epoch 96/301 --> loss:0.05333741903305054
step 61/275, epoch 96/301 --> loss:0.07647699713706971
step 71/275, epoch 96/301 --> loss:0.06077317595481872
step 81/275, epoch 96/301 --> loss:0.06784284114837646
step 91/275, epoch 96/301 --> loss:0.0705522894859314
step 101/275, epoch 96/301 --> loss:0.06809527277946473
step 111/275, epoch 96/301 --> loss:0.07186954617500305
step 121/275, epoch 96/301 --> loss:0.07480070590972901
step 131/275, epoch 96/301 --> loss:0.07611873149871826
step 141/275, epoch 96/301 --> loss:0.06766881346702576
step 151/275, epoch 96/301 --> loss:0.07439426183700562
step 161/275, epoch 96/301 --> loss:0.060537701845169066
step 171/275, epoch 96/301 --> loss:0.06598615646362305
step 181/275, epoch 96/301 --> loss:0.06406711339950562
step 191/275, epoch 96/301 --> loss:0.07142866253852845
step 201/275, epoch 96/301 --> loss:0.07691524624824524
step 211/275, epoch 96/301 --> loss:0.06769315004348755
step 221/275, epoch 96/301 --> loss:0.06494346261024475
step 231/275, epoch 96/301 --> loss:0.06505169272422791
step 241/275, epoch 96/301 --> loss:0.06567506790161133
step 251/275, epoch 96/301 --> loss:0.062183231115341187
step 261/275, epoch 96/301 --> loss:0.07732840776443481
step 271/275, epoch 96/301 --> loss:0.06539884209632874
 32%|███▏      | 97/301 [9:16:33<18:40:19, 329.51s/it]step 11/275, epoch 97/301 --> loss:0.07873796820640563
step 21/275, epoch 97/301 --> loss:0.06395263075828553
step 31/275, epoch 97/301 --> loss:0.05697757005691528
step 41/275, epoch 97/301 --> loss:0.08115531206130981
step 51/275, epoch 97/301 --> loss:0.05870141983032227
step 61/275, epoch 97/301 --> loss:0.07208133339881898
step 71/275, epoch 97/301 --> loss:0.06390881538391113
step 81/275, epoch 97/301 --> loss:0.06487870216369629
step 91/275, epoch 97/301 --> loss:0.07744264602661133
step 101/275, epoch 97/301 --> loss:0.05003543496131897
step 111/275, epoch 97/301 --> loss:0.06835250854492188
step 121/275, epoch 97/301 --> loss:0.057502460479736325
step 131/275, epoch 97/301 --> loss:0.057008779048919676
step 141/275, epoch 97/301 --> loss:0.06041631102561951
step 151/275, epoch 97/301 --> loss:0.07730512619018555
step 161/275, epoch 97/301 --> loss:0.07004691362380981
step 171/275, epoch 97/301 --> loss:0.06224874258041382
step 181/275, epoch 97/301 --> loss:0.06728028059005738
step 191/275, epoch 97/301 --> loss:0.06781021952629089
step 201/275, epoch 97/301 --> loss:0.0653858721256256
step 211/275, epoch 97/301 --> loss:0.0725721299648285
step 221/275, epoch 97/301 --> loss:0.07913870811462402
step 231/275, epoch 97/301 --> loss:0.06958553791046143
step 241/275, epoch 97/301 --> loss:0.06794928908348083
step 251/275, epoch 97/301 --> loss:0.06773735880851746
step 261/275, epoch 97/301 --> loss:0.08301102519035339
step 271/275, epoch 97/301 --> loss:0.05827279686927796
 33%|███▎      | 98/301 [9:21:55<18:27:24, 327.31s/it]step 11/275, epoch 98/301 --> loss:0.09074546694755554
step 21/275, epoch 98/301 --> loss:0.06828805208206176
step 31/275, epoch 98/301 --> loss:0.048391371965408325
step 41/275, epoch 98/301 --> loss:0.07241109609603882
step 51/275, epoch 98/301 --> loss:0.0580468475818634
step 61/275, epoch 98/301 --> loss:0.07920919060707092
step 71/275, epoch 98/301 --> loss:0.07142793536186218
step 81/275, epoch 98/301 --> loss:0.06899206042289734
step 91/275, epoch 98/301 --> loss:0.05886744260787964
step 101/275, epoch 98/301 --> loss:0.06267608404159546
step 111/275, epoch 98/301 --> loss:0.06644229888916016
step 121/275, epoch 98/301 --> loss:0.06883684396743775
step 131/275, epoch 98/301 --> loss:0.053732603788375854
step 141/275, epoch 98/301 --> loss:0.06766866445541382
step 151/275, epoch 98/301 --> loss:0.05162697434425354
step 161/275, epoch 98/301 --> loss:0.07817659378051758
step 171/275, epoch 98/301 --> loss:0.05544478893280029
step 181/275, epoch 98/301 --> loss:0.06772335171699524
step 191/275, epoch 98/301 --> loss:0.05964361429214478
step 201/275, epoch 98/301 --> loss:0.06898416876792908
step 211/275, epoch 98/301 --> loss:0.06700608730316163
step 221/275, epoch 98/301 --> loss:0.06605026125907898
step 231/275, epoch 98/301 --> loss:0.06145214438438416
step 241/275, epoch 98/301 --> loss:0.06150164604187012
step 251/275, epoch 98/301 --> loss:0.0674032986164093
step 261/275, epoch 98/301 --> loss:0.07110264897346497
step 271/275, epoch 98/301 --> loss:0.05576072335243225
 33%|███▎      | 99/301 [9:27:13<18:13:01, 324.66s/it]step 11/275, epoch 99/301 --> loss:0.06572530269622803
step 21/275, epoch 99/301 --> loss:0.08319916129112244
step 31/275, epoch 99/301 --> loss:0.0682198703289032
step 41/275, epoch 99/301 --> loss:0.07111535668373108
step 51/275, epoch 99/301 --> loss:0.06258093118667603
step 61/275, epoch 99/301 --> loss:0.06294458508491516
step 71/275, epoch 99/301 --> loss:0.0698674499988556
step 81/275, epoch 99/301 --> loss:0.06021914482116699
step 91/275, epoch 99/301 --> loss:0.06294918060302734
step 101/275, epoch 99/301 --> loss:0.06291550397872925
step 111/275, epoch 99/301 --> loss:0.0708216369152069
step 121/275, epoch 99/301 --> loss:0.06396883130073547
step 131/275, epoch 99/301 --> loss:0.06605230569839478
step 141/275, epoch 99/301 --> loss:0.07127459049224853
step 151/275, epoch 99/301 --> loss:0.05477311611175537
step 161/275, epoch 99/301 --> loss:0.06451602578163147
step 171/275, epoch 99/301 --> loss:0.06693503856658936
step 181/275, epoch 99/301 --> loss:0.0703673779964447
step 191/275, epoch 99/301 --> loss:0.054920119047164914
step 201/275, epoch 99/301 --> loss:0.08765254616737365
step 211/275, epoch 99/301 --> loss:0.06703534126281738
step 221/275, epoch 99/301 --> loss:0.08388500213623047
step 231/275, epoch 99/301 --> loss:0.06588817834854126
step 241/275, epoch 99/301 --> loss:0.07180824875831604
step 251/275, epoch 99/301 --> loss:0.060528653860092166
step 261/275, epoch 99/301 --> loss:0.06159112453460693
step 271/275, epoch 99/301 --> loss:0.07119998335838318
 33%|███▎      | 100/301 [9:32:30<17:59:46, 322.32s/it]step 11/275, epoch 100/301 --> loss:0.06324760913848877
step 21/275, epoch 100/301 --> loss:0.0648973286151886
step 31/275, epoch 100/301 --> loss:0.05818414092063904
step 41/275, epoch 100/301 --> loss:0.07061423063278198
step 51/275, epoch 100/301 --> loss:0.06869497895240784
step 61/275, epoch 100/301 --> loss:0.06989155411720276
step 71/275, epoch 100/301 --> loss:0.06871684193611145
step 81/275, epoch 100/301 --> loss:0.057050269842147824
step 91/275, epoch 100/301 --> loss:0.06900025606155395
step 101/275, epoch 100/301 --> loss:0.0713016927242279
step 111/275, epoch 100/301 --> loss:0.05928464531898499
step 121/275, epoch 100/301 --> loss:0.06605263948440551
step 131/275, epoch 100/301 --> loss:0.06894955635070801
step 141/275, epoch 100/301 --> loss:0.07383805513381958
step 151/275, epoch 100/301 --> loss:0.05797168016433716
step 161/275, epoch 100/301 --> loss:0.05594084858894348
step 171/275, epoch 100/301 --> loss:0.06577370762825012
step 181/275, epoch 100/301 --> loss:0.07021058201789857
step 191/275, epoch 100/301 --> loss:0.06575788855552674
step 201/275, epoch 100/301 --> loss:0.06383668184280396
step 211/275, epoch 100/301 --> loss:0.06901606917381287
step 221/275, epoch 100/301 --> loss:0.06833263635635375
step 231/275, epoch 100/301 --> loss:0.05823928713798523
step 241/275, epoch 100/301 --> loss:0.054803240299224856
step 251/275, epoch 100/301 --> loss:0.06942999362945557
step 261/275, epoch 100/301 --> loss:0.06991308927536011
step 271/275, epoch 100/301 --> loss:0.061222130060195924
step 11/275, epoch 101/301 --> loss:0.0631970763206482
step 21/275, epoch 101/301 --> loss:0.05910741686820984
step 31/275, epoch 101/301 --> loss:0.07141860723495483
step 41/275, epoch 101/301 --> loss:0.05251816511154175
step 51/275, epoch 101/301 --> loss:0.05747277736663818
step 61/275, epoch 101/301 --> loss:0.07320500612258911
step 71/275, epoch 101/301 --> loss:0.0683963119983673
step 81/275, epoch 101/301 --> loss:0.06062910556793213
step 91/275, epoch 101/301 --> loss:0.07216353416442871
step 101/275, epoch 101/301 --> loss:0.07434730529785157
step 111/275, epoch 101/301 --> loss:0.06169359683990479
step 121/275, epoch 101/301 --> loss:0.058702534437179564
step 131/275, epoch 101/301 --> loss:0.0696216106414795
step 141/275, epoch 101/301 --> loss:0.07608113288879395
step 151/275, epoch 101/301 --> loss:0.062451452016830444
step 161/275, epoch 101/301 --> loss:0.055885297060012815
step 171/275, epoch 101/301 --> loss:0.06250715851783753
step 181/275, epoch 101/301 --> loss:0.06823864579200745
step 191/275, epoch 101/301 --> loss:0.053448766469955444
step 201/275, epoch 101/301 --> loss:0.06667056083679199
step 211/275, epoch 101/301 --> loss:0.06173081994056702
step 221/275, epoch 101/301 --> loss:0.06104615330696106
step 231/275, epoch 101/301 --> loss:0.05503150820732117
step 241/275, epoch 101/301 --> loss:0.06661562323570251
step 251/275, epoch 101/301 --> loss:0.06487603783607483
step 261/275, epoch 101/301 --> loss:0.06104910969734192
step 271/275, epoch 101/301 --> loss:0.0690747320652008
########## train dataset ##########
PLout index:  2
acc -->  [94.33843736635059]
F1 -->  {'F1': [0.9327968716659873], 'precision': [0.9156785859959622], 'recall': [0.9505777721622652]}
########## eval dataset ##########
 34%|███▎      | 101/301 [9:41:41<21:42:31, 390.76s/it]PLout index:  2
acc -->  [92.33156829852342]
F1 -->  {'F1': [0.9108939496292079], 'precision': [0.8943964613365711], 'recall': [0.9280218557676575]}
 34%|███▍      | 102/301 [9:46:58<20:23:23, 368.86s/it]step 11/275, epoch 102/301 --> loss:0.058323371410369876
step 21/275, epoch 102/301 --> loss:0.0663565993309021
step 31/275, epoch 102/301 --> loss:0.06292290091514588
step 41/275, epoch 102/301 --> loss:0.05449165105819702
step 51/275, epoch 102/301 --> loss:0.0678662657737732
step 61/275, epoch 102/301 --> loss:0.05279951095581055
step 71/275, epoch 102/301 --> loss:0.06557425260543823
step 81/275, epoch 102/301 --> loss:0.06438701748847961
step 91/275, epoch 102/301 --> loss:0.0601848304271698
step 101/275, epoch 102/301 --> loss:0.058041197061538694
step 111/275, epoch 102/301 --> loss:0.05618526935577393
step 121/275, epoch 102/301 --> loss:0.05645898580551147
step 131/275, epoch 102/301 --> loss:0.06702886819839478
step 141/275, epoch 102/301 --> loss:0.05161446928977966
step 151/275, epoch 102/301 --> loss:0.05017777681350708
step 161/275, epoch 102/301 --> loss:0.05973936915397644
step 171/275, epoch 102/301 --> loss:0.08105072975158692
step 181/275, epoch 102/301 --> loss:0.07925344705581665
step 191/275, epoch 102/301 --> loss:0.07539554238319397
step 201/275, epoch 102/301 --> loss:0.08244533538818359
step 211/275, epoch 102/301 --> loss:0.06213083267211914
step 221/275, epoch 102/301 --> loss:0.060135883092880246
step 231/275, epoch 102/301 --> loss:0.05712444186210632
step 241/275, epoch 102/301 --> loss:0.06231907606124878
step 251/275, epoch 102/301 --> loss:0.07015782594680786
step 261/275, epoch 102/301 --> loss:0.06101455092430115
step 271/275, epoch 102/301 --> loss:0.05770936608314514
 34%|███▍      | 103/301 [9:52:18<19:28:25, 354.07s/it]step 11/275, epoch 103/301 --> loss:0.06259470582008361
step 21/275, epoch 103/301 --> loss:0.08284066915512085
step 31/275, epoch 103/301 --> loss:0.07938200235366821
step 41/275, epoch 103/301 --> loss:0.06030514240264893
step 51/275, epoch 103/301 --> loss:0.0752989411354065
step 61/275, epoch 103/301 --> loss:0.06075791120529175
step 71/275, epoch 103/301 --> loss:0.055951088666915894
step 81/275, epoch 103/301 --> loss:0.058953166007995605
step 91/275, epoch 103/301 --> loss:0.06615504026412963
step 101/275, epoch 103/301 --> loss:0.07085288166999817
step 111/275, epoch 103/301 --> loss:0.06150541305541992
step 121/275, epoch 103/301 --> loss:0.07017984390258789
step 131/275, epoch 103/301 --> loss:0.06720950603485107
step 141/275, epoch 103/301 --> loss:0.058545899391174314
step 151/275, epoch 103/301 --> loss:0.0699469804763794
step 161/275, epoch 103/301 --> loss:0.06045820713043213
step 171/275, epoch 103/301 --> loss:0.061954820156097413
step 181/275, epoch 103/301 --> loss:0.06403959989547729
step 191/275, epoch 103/301 --> loss:0.05487779974937439
step 201/275, epoch 103/301 --> loss:0.05645586252212524
step 211/275, epoch 103/301 --> loss:0.0625445306301117
step 221/275, epoch 103/301 --> loss:0.06758970022201538
step 231/275, epoch 103/301 --> loss:0.07566337585449219
step 241/275, epoch 103/301 --> loss:0.0603233814239502
step 251/275, epoch 103/301 --> loss:0.06452028751373291
step 261/275, epoch 103/301 --> loss:0.06976101994514465
step 271/275, epoch 103/301 --> loss:0.0694923996925354
 35%|███▍      | 104/301 [9:57:38<18:48:42, 343.77s/it]step 11/275, epoch 104/301 --> loss:0.06048980951309204
step 21/275, epoch 104/301 --> loss:0.06516284346580506
step 31/275, epoch 104/301 --> loss:0.05842657089233398
step 41/275, epoch 104/301 --> loss:0.06334176063537597
step 51/275, epoch 104/301 --> loss:0.06469839811325073
step 61/275, epoch 104/301 --> loss:0.06509837508201599
step 71/275, epoch 104/301 --> loss:0.055145013332366946
step 81/275, epoch 104/301 --> loss:0.06127859354019165
step 91/275, epoch 104/301 --> loss:0.06052039265632629
step 101/275, epoch 104/301 --> loss:0.059476226568222046
step 111/275, epoch 104/301 --> loss:0.07813886404037476
step 121/275, epoch 104/301 --> loss:0.06445478796958923
step 131/275, epoch 104/301 --> loss:0.06151173114776611
step 141/275, epoch 104/301 --> loss:0.05009811520576477
step 151/275, epoch 104/301 --> loss:0.04864968061447143
step 161/275, epoch 104/301 --> loss:0.057043266296386716
step 171/275, epoch 104/301 --> loss:0.061524152755737305
step 181/275, epoch 104/301 --> loss:0.05313931703567505
step 191/275, epoch 104/301 --> loss:0.059788095951080325
step 201/275, epoch 104/301 --> loss:0.06305752992630005
step 211/275, epoch 104/301 --> loss:0.06263906955718994
step 221/275, epoch 104/301 --> loss:0.06717274785041809
step 231/275, epoch 104/301 --> loss:0.05867413282394409
step 241/275, epoch 104/301 --> loss:0.07425467371940613
step 251/275, epoch 104/301 --> loss:0.08463165163993835
step 261/275, epoch 104/301 --> loss:0.07197346687316894
step 271/275, epoch 104/301 --> loss:0.07593848705291747
 35%|███▍      | 105/301 [10:02:57<18:19:19, 336.53s/it]step 11/275, epoch 105/301 --> loss:0.07991553544998169
step 21/275, epoch 105/301 --> loss:0.07513000369071961
step 31/275, epoch 105/301 --> loss:0.08496247529983521
step 41/275, epoch 105/301 --> loss:0.059877818822860716
step 51/275, epoch 105/301 --> loss:0.07638824582099915
step 61/275, epoch 105/301 --> loss:0.05840060114860535
step 71/275, epoch 105/301 --> loss:0.06795699000358582
step 81/275, epoch 105/301 --> loss:0.055872654914855956
step 91/275, epoch 105/301 --> loss:0.05406066179275513
step 101/275, epoch 105/301 --> loss:0.05594488978385925
step 111/275, epoch 105/301 --> loss:0.060590612888336184
step 121/275, epoch 105/301 --> loss:0.07460116147994995
step 131/275, epoch 105/301 --> loss:0.06069980263710022
step 141/275, epoch 105/301 --> loss:0.0667233943939209
step 151/275, epoch 105/301 --> loss:0.05862498879432678
step 161/275, epoch 105/301 --> loss:0.0672873616218567
step 171/275, epoch 105/301 --> loss:0.05574078559875488
step 181/275, epoch 105/301 --> loss:0.0724161446094513
step 191/275, epoch 105/301 --> loss:0.09202409982681274
step 201/275, epoch 105/301 --> loss:0.08011935949325562
step 211/275, epoch 105/301 --> loss:0.07381053566932679
step 221/275, epoch 105/301 --> loss:0.07586899399757385
step 231/275, epoch 105/301 --> loss:0.0698604166507721
step 241/275, epoch 105/301 --> loss:0.07397139668464661
step 251/275, epoch 105/301 --> loss:0.06659662127494811
step 261/275, epoch 105/301 --> loss:0.06940383911132812
step 271/275, epoch 105/301 --> loss:0.06489670276641846
 35%|███▌      | 106/301 [10:08:17<17:57:17, 331.48s/it]step 11/275, epoch 106/301 --> loss:0.07854624390602112
step 21/275, epoch 106/301 --> loss:0.06355961561203002
step 31/275, epoch 106/301 --> loss:0.07218884229660034
step 41/275, epoch 106/301 --> loss:0.07729558944702149
step 51/275, epoch 106/301 --> loss:0.05561538934707642
step 61/275, epoch 106/301 --> loss:0.06355110406875611
step 71/275, epoch 106/301 --> loss:0.06855071187019349
step 81/275, epoch 106/301 --> loss:0.07151052355766296
step 91/275, epoch 106/301 --> loss:0.062422895431518556
step 101/275, epoch 106/301 --> loss:0.0677153468132019
step 111/275, epoch 106/301 --> loss:0.0763741374015808
step 121/275, epoch 106/301 --> loss:0.05876285433769226
step 131/275, epoch 106/301 --> loss:0.07318405508995056
step 141/275, epoch 106/301 --> loss:0.055799686908721925
step 151/275, epoch 106/301 --> loss:0.06126963496208191
step 161/275, epoch 106/301 --> loss:0.06121754050254822
step 171/275, epoch 106/301 --> loss:0.05358529090881348
step 181/275, epoch 106/301 --> loss:0.0647973895072937
step 191/275, epoch 106/301 --> loss:0.06649985313415527
step 201/275, epoch 106/301 --> loss:0.06136950254440308
step 211/275, epoch 106/301 --> loss:0.05807866454124451
step 221/275, epoch 106/301 --> loss:0.07540008425712585
step 231/275, epoch 106/301 --> loss:0.06086740493774414
step 241/275, epoch 106/301 --> loss:0.06925089955329895
step 251/275, epoch 106/301 --> loss:0.0675001323223114
step 261/275, epoch 106/301 --> loss:0.06839956641197205
step 271/275, epoch 106/301 --> loss:0.07372020483016968
 36%|███▌      | 107/301 [10:13:37<17:40:38, 328.03s/it]step 11/275, epoch 107/301 --> loss:0.08064014911651611
step 21/275, epoch 107/301 --> loss:0.05873894691467285
step 31/275, epoch 107/301 --> loss:0.057085490226745604
step 41/275, epoch 107/301 --> loss:0.0668627679347992
step 51/275, epoch 107/301 --> loss:0.06725600361824036
step 61/275, epoch 107/301 --> loss:0.0586234450340271
step 71/275, epoch 107/301 --> loss:0.0646754801273346
step 81/275, epoch 107/301 --> loss:0.05645860433578491
step 91/275, epoch 107/301 --> loss:0.05805153250694275
step 101/275, epoch 107/301 --> loss:0.06766855120658874
step 111/275, epoch 107/301 --> loss:0.05506835579872131
step 121/275, epoch 107/301 --> loss:0.054482805728912356
step 131/275, epoch 107/301 --> loss:0.05836799144744873
step 141/275, epoch 107/301 --> loss:0.06180128455162048
step 151/275, epoch 107/301 --> loss:0.05788314342498779
step 161/275, epoch 107/301 --> loss:0.06384921073913574
step 171/275, epoch 107/301 --> loss:0.06051094532012939
step 181/275, epoch 107/301 --> loss:0.05896353125572205
step 191/275, epoch 107/301 --> loss:0.06871224641799926
step 201/275, epoch 107/301 --> loss:0.08217771053314209
step 211/275, epoch 107/301 --> loss:0.053510963916778564
step 221/275, epoch 107/301 --> loss:0.06639482975006103
step 231/275, epoch 107/301 --> loss:0.05560723543167114
step 241/275, epoch 107/301 --> loss:0.07226536870002746
step 251/275, epoch 107/301 --> loss:0.05886940956115723
step 261/275, epoch 107/301 --> loss:0.05630409121513367
step 271/275, epoch 107/301 --> loss:0.07091369032859803
 36%|███▌      | 108/301 [10:18:57<17:27:37, 325.69s/it]step 11/275, epoch 108/301 --> loss:0.06546037793159484
step 21/275, epoch 108/301 --> loss:0.08890496492385865
step 31/275, epoch 108/301 --> loss:0.0683058500289917
step 41/275, epoch 108/301 --> loss:0.06003078818321228
step 51/275, epoch 108/301 --> loss:0.05558642148971558
step 61/275, epoch 108/301 --> loss:0.049737352132797244
step 71/275, epoch 108/301 --> loss:0.0764552891254425
step 81/275, epoch 108/301 --> loss:0.06320192217826844
step 91/275, epoch 108/301 --> loss:0.07259860634803772
step 101/275, epoch 108/301 --> loss:0.0668675184249878
step 111/275, epoch 108/301 --> loss:0.0662036657333374
step 121/275, epoch 108/301 --> loss:0.06361377835273743
step 131/275, epoch 108/301 --> loss:0.06757012605667115
step 141/275, epoch 108/301 --> loss:0.06232062578201294
step 151/275, epoch 108/301 --> loss:0.06979252696037293
step 161/275, epoch 108/301 --> loss:0.059238648414611815
step 171/275, epoch 108/301 --> loss:0.062652325630188
step 181/275, epoch 108/301 --> loss:0.05692686438560486
step 191/275, epoch 108/301 --> loss:0.05342571139335632
step 201/275, epoch 108/301 --> loss:0.05537816882133484
step 211/275, epoch 108/301 --> loss:0.05937314033508301
step 221/275, epoch 108/301 --> loss:0.06228962540626526
step 231/275, epoch 108/301 --> loss:0.06487634181976318
step 241/275, epoch 108/301 --> loss:0.06848935484886169
step 251/275, epoch 108/301 --> loss:0.07578778862953187
step 261/275, epoch 108/301 --> loss:0.04078987240791321
step 271/275, epoch 108/301 --> loss:0.06119989156723023
 36%|███▌      | 109/301 [10:24:17<17:16:50, 324.01s/it]step 11/275, epoch 109/301 --> loss:0.06814692616462707
step 21/275, epoch 109/301 --> loss:0.06255735158920288
step 31/275, epoch 109/301 --> loss:0.07053113579750062
step 41/275, epoch 109/301 --> loss:0.06245927214622497
step 51/275, epoch 109/301 --> loss:0.0749927818775177
step 61/275, epoch 109/301 --> loss:0.06402164697647095
step 71/275, epoch 109/301 --> loss:0.05203346014022827
step 81/275, epoch 109/301 --> loss:0.06768770813941956
step 91/275, epoch 109/301 --> loss:0.060435205698013306
step 101/275, epoch 109/301 --> loss:0.058865970373153685
step 111/275, epoch 109/301 --> loss:0.06032156348228455
step 121/275, epoch 109/301 --> loss:0.05676654577255249
step 131/275, epoch 109/301 --> loss:0.06799277067184448
step 141/275, epoch 109/301 --> loss:0.0595092236995697
step 151/275, epoch 109/301 --> loss:0.06913734078407288
step 161/275, epoch 109/301 --> loss:0.06407335996627808
step 171/275, epoch 109/301 --> loss:0.06240385174751282
step 181/275, epoch 109/301 --> loss:0.07267875671386718
step 191/275, epoch 109/301 --> loss:0.07159695029258728
step 201/275, epoch 109/301 --> loss:0.05845334529876709
step 211/275, epoch 109/301 --> loss:0.06564754843711854
step 221/275, epoch 109/301 --> loss:0.052936744689941403
step 231/275, epoch 109/301 --> loss:0.05637274384498596
step 241/275, epoch 109/301 --> loss:0.05065077543258667
step 251/275, epoch 109/301 --> loss:0.07941704988479614
step 261/275, epoch 109/301 --> loss:0.07676747441291809
step 271/275, epoch 109/301 --> loss:0.04767856001853943
 37%|███▋      | 110/301 [10:29:38<17:07:50, 322.88s/it]step 11/275, epoch 110/301 --> loss:0.04740002751350403
step 21/275, epoch 110/301 --> loss:0.06912161707878113
step 31/275, epoch 110/301 --> loss:0.05346872210502625
step 41/275, epoch 110/301 --> loss:0.05164403915405273
step 51/275, epoch 110/301 --> loss:0.06951560378074646
step 61/275, epoch 110/301 --> loss:0.057386988401412965
step 71/275, epoch 110/301 --> loss:0.06500110626220704
step 81/275, epoch 110/301 --> loss:0.05535935163497925
step 91/275, epoch 110/301 --> loss:0.06664901971817017
step 101/275, epoch 110/301 --> loss:0.06322206854820252
step 111/275, epoch 110/301 --> loss:0.05539653897285461
step 121/275, epoch 110/301 --> loss:0.05808785557746887
step 131/275, epoch 110/301 --> loss:0.06258819103240967
step 141/275, epoch 110/301 --> loss:0.05043491721153259
step 151/275, epoch 110/301 --> loss:0.07263419032096863
step 161/275, epoch 110/301 --> loss:0.07898342013359069
step 171/275, epoch 110/301 --> loss:0.07010090947151185
step 181/275, epoch 110/301 --> loss:0.06459755897521972
step 191/275, epoch 110/301 --> loss:0.060571664571762086
step 201/275, epoch 110/301 --> loss:0.056283342838287356
step 211/275, epoch 110/301 --> loss:0.06411864757537841
step 221/275, epoch 110/301 --> loss:0.057911652326583865
step 231/275, epoch 110/301 --> loss:0.05393646359443664
step 241/275, epoch 110/301 --> loss:0.05924385190010071
step 251/275, epoch 110/301 --> loss:0.06568719148635864
step 261/275, epoch 110/301 --> loss:0.07384113669395446
step 271/275, epoch 110/301 --> loss:0.06500279307365417
step 11/275, epoch 111/301 --> loss:0.06705954074859619
step 21/275, epoch 111/301 --> loss:0.06775459051132202
step 31/275, epoch 111/301 --> loss:0.061953401565551756
step 41/275, epoch 111/301 --> loss:0.06123839020729065
step 51/275, epoch 111/301 --> loss:0.06759155988693237
step 61/275, epoch 111/301 --> loss:0.047602617740631105
step 71/275, epoch 111/301 --> loss:0.06576828360557556
step 81/275, epoch 111/301 --> loss:0.05593452453613281
step 91/275, epoch 111/301 --> loss:0.06769787073135376
step 101/275, epoch 111/301 --> loss:0.05822120308876037
step 111/275, epoch 111/301 --> loss:0.056350862979888915
step 121/275, epoch 111/301 --> loss:0.05797700881958008
step 131/275, epoch 111/301 --> loss:0.05538972020149231
step 141/275, epoch 111/301 --> loss:0.0713905930519104
step 151/275, epoch 111/301 --> loss:0.05772812962532044
step 161/275, epoch 111/301 --> loss:0.06222847104072571
step 171/275, epoch 111/301 --> loss:0.07125340700149536
step 181/275, epoch 111/301 --> loss:0.0701436996459961
step 191/275, epoch 111/301 --> loss:0.0671002984046936
step 201/275, epoch 111/301 --> loss:0.06517496109008789
step 211/275, epoch 111/301 --> loss:0.060739606618881226
step 221/275, epoch 111/301 --> loss:0.0626606822013855
step 231/275, epoch 111/301 --> loss:0.06413460969924926
step 241/275, epoch 111/301 --> loss:0.060120999813079834
step 251/275, epoch 111/301 --> loss:0.0694836974143982
step 261/275, epoch 111/301 --> loss:0.055736637115478514
step 271/275, epoch 111/301 --> loss:0.0718260109424591
########## train dataset ##########
PLout index:  2
acc -->  [94.08643803001229]
F1 -->  {'F1': [0.9274857309934958], 'precision': [0.9404090493742058], 'recall': [0.9149225170053986]}
########## eval dataset ##########
 37%|███▋      | 111/301 [10:38:50<20:40:27, 391.73s/it]PLout index:  2
acc -->  [92.10408691010578]
F1 -->  {'F1': [0.9048789096445397], 'precision': [0.9211177199718624], 'recall': [0.8892123967232197]}
 37%|███▋      | 112/301 [10:44:10<19:25:52, 370.12s/it]step 11/275, epoch 112/301 --> loss:0.07266119122505188
step 21/275, epoch 112/301 --> loss:0.06100625395774841
step 31/275, epoch 112/301 --> loss:0.06286168694496155
step 41/275, epoch 112/301 --> loss:0.07196484208106994
step 51/275, epoch 112/301 --> loss:0.05647607445716858
step 61/275, epoch 112/301 --> loss:0.06980939507484436
step 71/275, epoch 112/301 --> loss:0.061254972219467164
step 81/275, epoch 112/301 --> loss:0.05820648074150085
step 91/275, epoch 112/301 --> loss:0.06356039643287659
step 101/275, epoch 112/301 --> loss:0.06688804030418397
step 111/275, epoch 112/301 --> loss:0.052916723489761355
step 121/275, epoch 112/301 --> loss:0.05786653757095337
step 131/275, epoch 112/301 --> loss:0.0650134563446045
step 141/275, epoch 112/301 --> loss:0.06739747524261475
step 151/275, epoch 112/301 --> loss:0.06413451433181763
step 161/275, epoch 112/301 --> loss:0.05159540176391601
step 171/275, epoch 112/301 --> loss:0.05155794620513916
step 181/275, epoch 112/301 --> loss:0.06857906579971314
step 191/275, epoch 112/301 --> loss:0.05569828152656555
step 201/275, epoch 112/301 --> loss:0.06986476182937622
step 211/275, epoch 112/301 --> loss:0.04711663126945496
step 221/275, epoch 112/301 --> loss:0.05967670679092407
step 231/275, epoch 112/301 --> loss:0.06628904342651368
step 241/275, epoch 112/301 --> loss:0.06699066162109375
step 251/275, epoch 112/301 --> loss:0.06694399714469909
step 261/275, epoch 112/301 --> loss:0.06189439296722412
step 271/275, epoch 112/301 --> loss:0.06392549276351929
 38%|███▊      | 113/301 [10:49:31<18:33:30, 355.37s/it]step 11/275, epoch 113/301 --> loss:0.056226491928100586
step 21/275, epoch 113/301 --> loss:0.057660818099975586
step 31/275, epoch 113/301 --> loss:0.05922619104385376
step 41/275, epoch 113/301 --> loss:0.060731816291809085
step 51/275, epoch 113/301 --> loss:0.0609499454498291
step 61/275, epoch 113/301 --> loss:0.061564838886260985
step 71/275, epoch 113/301 --> loss:0.060998964309692386
step 81/275, epoch 113/301 --> loss:0.055554169416427615
step 91/275, epoch 113/301 --> loss:0.08310081362724304
step 101/275, epoch 113/301 --> loss:0.058078056573867796
step 111/275, epoch 113/301 --> loss:0.05280157923698425
step 121/275, epoch 113/301 --> loss:0.0524614155292511
step 131/275, epoch 113/301 --> loss:0.05638887882232666
step 141/275, epoch 113/301 --> loss:0.05455607771873474
step 151/275, epoch 113/301 --> loss:0.056748378276824954
step 161/275, epoch 113/301 --> loss:0.05852953791618347
step 171/275, epoch 113/301 --> loss:0.06297892332077026
step 181/275, epoch 113/301 --> loss:0.05755521655082703
step 191/275, epoch 113/301 --> loss:0.0676230549812317
step 201/275, epoch 113/301 --> loss:0.05139824151992798
step 211/275, epoch 113/301 --> loss:0.06341727972030639
step 221/275, epoch 113/301 --> loss:0.05381336212158203
step 231/275, epoch 113/301 --> loss:0.06609832048416138
step 241/275, epoch 113/301 --> loss:0.05508203506469726
step 251/275, epoch 113/301 --> loss:0.07503820061683655
step 261/275, epoch 113/301 --> loss:0.06681460738182068
step 271/275, epoch 113/301 --> loss:0.06817677021026611
 38%|███▊      | 114/301 [10:54:51<17:55:06, 344.96s/it]step 11/275, epoch 114/301 --> loss:0.06248212456703186
step 21/275, epoch 114/301 --> loss:0.05735908150672912
step 31/275, epoch 114/301 --> loss:0.06689097881317138
step 41/275, epoch 114/301 --> loss:0.0681615948677063
step 51/275, epoch 114/301 --> loss:0.05677273273468018
step 61/275, epoch 114/301 --> loss:0.059077107906341554
step 71/275, epoch 114/301 --> loss:0.05929688811302185
step 81/275, epoch 114/301 --> loss:0.05288321375846863
step 91/275, epoch 114/301 --> loss:0.047170788049697876
step 101/275, epoch 114/301 --> loss:0.07743998765945434
step 111/275, epoch 114/301 --> loss:0.05462678670883179
step 121/275, epoch 114/301 --> loss:0.0554389238357544
step 131/275, epoch 114/301 --> loss:0.05229845643043518
step 141/275, epoch 114/301 --> loss:0.060579323768615724
step 151/275, epoch 114/301 --> loss:0.05192884206771851
step 161/275, epoch 114/301 --> loss:0.05241661071777344
step 171/275, epoch 114/301 --> loss:0.04937713742256165
step 181/275, epoch 114/301 --> loss:0.06337429881095887
step 191/275, epoch 114/301 --> loss:0.06431003808975219
step 201/275, epoch 114/301 --> loss:0.060599607229232785
step 211/275, epoch 114/301 --> loss:0.055931556224823
step 221/275, epoch 114/301 --> loss:0.061606138944625854
step 231/275, epoch 114/301 --> loss:0.06004675626754761
step 241/275, epoch 114/301 --> loss:0.06890038847923279
step 251/275, epoch 114/301 --> loss:0.05483542680740357
step 261/275, epoch 114/301 --> loss:0.06384941339492797
step 271/275, epoch 114/301 --> loss:0.05485023260116577
 38%|███▊      | 115/301 [11:00:11<17:25:37, 337.30s/it]step 11/275, epoch 115/301 --> loss:0.06269035339355469
step 21/275, epoch 115/301 --> loss:0.05636268258094788
step 31/275, epoch 115/301 --> loss:0.05927920341491699
step 41/275, epoch 115/301 --> loss:0.06549612283706666
step 51/275, epoch 115/301 --> loss:0.05140520334243774
step 61/275, epoch 115/301 --> loss:0.05682321786880493
step 71/275, epoch 115/301 --> loss:0.04060491919517517
step 81/275, epoch 115/301 --> loss:0.05889608263969422
step 91/275, epoch 115/301 --> loss:0.054136306047439575
step 101/275, epoch 115/301 --> loss:0.061371070146560666
step 111/275, epoch 115/301 --> loss:0.0513174295425415
step 121/275, epoch 115/301 --> loss:0.056515705585479734
step 131/275, epoch 115/301 --> loss:0.0562541663646698
step 141/275, epoch 115/301 --> loss:0.05837600827217102
step 151/275, epoch 115/301 --> loss:0.06941837072372437
step 161/275, epoch 115/301 --> loss:0.048880201578140256
step 171/275, epoch 115/301 --> loss:0.05672857165336609
step 181/275, epoch 115/301 --> loss:0.05998727083206177
step 191/275, epoch 115/301 --> loss:0.05926430821418762
step 201/275, epoch 115/301 --> loss:0.05706577301025391
step 211/275, epoch 115/301 --> loss:0.06808267831802368
step 221/275, epoch 115/301 --> loss:0.05773530602455139
step 231/275, epoch 115/301 --> loss:0.06308311820030213
step 241/275, epoch 115/301 --> loss:0.06557989120483398
step 251/275, epoch 115/301 --> loss:0.06293140649795533
step 261/275, epoch 115/301 --> loss:0.060283315181732175
step 271/275, epoch 115/301 --> loss:0.05872982144355774
 39%|███▊      | 116/301 [11:05:28<17:01:08, 331.18s/it]step 11/275, epoch 116/301 --> loss:0.057597923278808597
step 21/275, epoch 116/301 --> loss:0.06757502555847168
step 31/275, epoch 116/301 --> loss:0.05571444034576416
step 41/275, epoch 116/301 --> loss:0.05400189757347107
step 51/275, epoch 116/301 --> loss:0.05165773034095764
step 61/275, epoch 116/301 --> loss:0.06503669619560241
step 71/275, epoch 116/301 --> loss:0.047059875726699826
step 81/275, epoch 116/301 --> loss:0.05153408646583557
step 91/275, epoch 116/301 --> loss:0.061343997716903687
step 101/275, epoch 116/301 --> loss:0.06050601601600647
step 111/275, epoch 116/301 --> loss:0.061597412824630736
step 121/275, epoch 116/301 --> loss:0.05950614809989929
step 131/275, epoch 116/301 --> loss:0.06327121257781983
step 141/275, epoch 116/301 --> loss:0.07005029916763306
step 151/275, epoch 116/301 --> loss:0.051008212566375735
step 161/275, epoch 116/301 --> loss:0.07846907377243043
step 171/275, epoch 116/301 --> loss:0.05061897039413452
step 181/275, epoch 116/301 --> loss:0.060976731777191165
step 191/275, epoch 116/301 --> loss:0.05419328808784485
step 201/275, epoch 116/301 --> loss:0.06601126194000244
step 211/275, epoch 116/301 --> loss:0.0466389536857605
step 221/275, epoch 116/301 --> loss:0.05896888375282287
step 231/275, epoch 116/301 --> loss:0.05655341744422913
step 241/275, epoch 116/301 --> loss:0.0646284818649292
step 251/275, epoch 116/301 --> loss:0.05513561367988586
step 261/275, epoch 116/301 --> loss:0.05178736448287964
step 271/275, epoch 116/301 --> loss:0.05305460691452026
 39%|███▉      | 117/301 [11:10:43<16:41:27, 326.56s/it]step 11/275, epoch 117/301 --> loss:0.049054044485092166
step 21/275, epoch 117/301 --> loss:0.062389856576919554
step 31/275, epoch 117/301 --> loss:0.06627816557884217
step 41/275, epoch 117/301 --> loss:0.06206321120262146
step 51/275, epoch 117/301 --> loss:0.05974974632263184
step 61/275, epoch 117/301 --> loss:0.054847753047943114
step 71/275, epoch 117/301 --> loss:0.05189619660377502
step 81/275, epoch 117/301 --> loss:0.0642410933971405
step 91/275, epoch 117/301 --> loss:0.05693851113319397
step 101/275, epoch 117/301 --> loss:0.05139038562774658
step 111/275, epoch 117/301 --> loss:0.05068000555038452
step 121/275, epoch 117/301 --> loss:0.06383078694343566
step 131/275, epoch 117/301 --> loss:0.052105510234832765
step 141/275, epoch 117/301 --> loss:0.04677934646606445
step 151/275, epoch 117/301 --> loss:0.060276126861572264
step 161/275, epoch 117/301 --> loss:0.061288845539093015
step 171/275, epoch 117/301 --> loss:0.05790802240371704
step 181/275, epoch 117/301 --> loss:0.05272948741912842
step 191/275, epoch 117/301 --> loss:0.058049947023391724
step 201/275, epoch 117/301 --> loss:0.07078741192817688
step 211/275, epoch 117/301 --> loss:0.05023463368415833
step 221/275, epoch 117/301 --> loss:0.059816622734069826
step 231/275, epoch 117/301 --> loss:0.06848707199096679
step 241/275, epoch 117/301 --> loss:0.06242767572402954
step 251/275, epoch 117/301 --> loss:0.07626789808273315
step 261/275, epoch 117/301 --> loss:0.07206442952156067
step 271/275, epoch 117/301 --> loss:0.05829584002494812
 39%|███▉      | 118/301 [11:15:59<16:26:14, 323.36s/it]step 11/275, epoch 118/301 --> loss:0.06910680532455445
step 21/275, epoch 118/301 --> loss:0.05499752163887024
step 31/275, epoch 118/301 --> loss:0.06449982523918152
step 41/275, epoch 118/301 --> loss:0.06132527589797974
step 51/275, epoch 118/301 --> loss:0.047397720813751223
step 61/275, epoch 118/301 --> loss:0.06281810402870178
step 71/275, epoch 118/301 --> loss:0.054122132062911985
step 81/275, epoch 118/301 --> loss:0.05014688968658447
step 91/275, epoch 118/301 --> loss:0.062451452016830444
step 101/275, epoch 118/301 --> loss:0.04913390278816223
step 111/275, epoch 118/301 --> loss:0.055149024724960326
step 121/275, epoch 118/301 --> loss:0.058570104837417605
step 131/275, epoch 118/301 --> loss:0.05593627691268921
step 141/275, epoch 118/301 --> loss:0.05477561354637146
step 151/275, epoch 118/301 --> loss:0.05340065360069275
step 161/275, epoch 118/301 --> loss:0.07186970114707947
step 171/275, epoch 118/301 --> loss:0.06632421612739563
step 181/275, epoch 118/301 --> loss:0.05208545923233032
step 191/275, epoch 118/301 --> loss:0.060016459226608275
step 201/275, epoch 118/301 --> loss:0.05456633567810058
step 211/275, epoch 118/301 --> loss:0.0613420307636261
step 221/275, epoch 118/301 --> loss:0.06318351626396179
step 231/275, epoch 118/301 --> loss:0.05903828740119934
step 241/275, epoch 118/301 --> loss:0.052594953775405885
step 251/275, epoch 118/301 --> loss:0.05658749938011169
step 261/275, epoch 118/301 --> loss:0.05985528230667114
step 271/275, epoch 118/301 --> loss:0.059387826919555665
 40%|███▉      | 119/301 [11:21:17<16:15:26, 321.57s/it]step 11/275, epoch 119/301 --> loss:0.04492467045783997
step 21/275, epoch 119/301 --> loss:0.058020204305648804
step 31/275, epoch 119/301 --> loss:0.06203558444976807
step 41/275, epoch 119/301 --> loss:0.05622678995132446
step 51/275, epoch 119/301 --> loss:0.051970040798187254
step 61/275, epoch 119/301 --> loss:0.04842868447303772
step 71/275, epoch 119/301 --> loss:0.068595552444458
step 81/275, epoch 119/301 --> loss:0.05364755392074585
step 91/275, epoch 119/301 --> loss:0.0626402199268341
step 101/275, epoch 119/301 --> loss:0.04763563871383667
step 111/275, epoch 119/301 --> loss:0.05679488778114319
step 121/275, epoch 119/301 --> loss:0.05788023471832275
step 131/275, epoch 119/301 --> loss:0.06895575523376465
step 141/275, epoch 119/301 --> loss:0.06414199471473694
step 151/275, epoch 119/301 --> loss:0.054946088790893556
step 161/275, epoch 119/301 --> loss:0.05917346477508545
step 171/275, epoch 119/301 --> loss:0.06976370811462403
step 181/275, epoch 119/301 --> loss:0.049212795495986936
step 191/275, epoch 119/301 --> loss:0.05824712514877319
step 201/275, epoch 119/301 --> loss:0.06507786512374877
step 211/275, epoch 119/301 --> loss:0.05843311548233032
step 221/275, epoch 119/301 --> loss:0.06093765497207641
step 231/275, epoch 119/301 --> loss:0.05693005919456482
step 241/275, epoch 119/301 --> loss:0.08933970928192139
step 251/275, epoch 119/301 --> loss:0.08107933402061462
step 261/275, epoch 119/301 --> loss:0.0725740373134613
step 271/275, epoch 119/301 --> loss:0.05964533686637878
 40%|███▉      | 120/301 [11:26:36<16:07:59, 320.88s/it]step 11/275, epoch 120/301 --> loss:0.057198363542556765
step 21/275, epoch 120/301 --> loss:0.0476515531539917
step 31/275, epoch 120/301 --> loss:0.06537095308303834
step 41/275, epoch 120/301 --> loss:0.05536762475967407
step 51/275, epoch 120/301 --> loss:0.04989308714866638
step 61/275, epoch 120/301 --> loss:0.055567038059234616
step 71/275, epoch 120/301 --> loss:0.056686848402023315
step 81/275, epoch 120/301 --> loss:0.06685436964035034
step 91/275, epoch 120/301 --> loss:0.06002198457717896
step 101/275, epoch 120/301 --> loss:0.05872063040733337
step 111/275, epoch 120/301 --> loss:0.06563439965248108
step 121/275, epoch 120/301 --> loss:0.06384904384613037
step 131/275, epoch 120/301 --> loss:0.06153830885887146
step 141/275, epoch 120/301 --> loss:0.06257312893867492
step 151/275, epoch 120/301 --> loss:0.05851913094520569
step 161/275, epoch 120/301 --> loss:0.05857352018356323
step 171/275, epoch 120/301 --> loss:0.06100993156433106
step 181/275, epoch 120/301 --> loss:0.06381998658180237
step 191/275, epoch 120/301 --> loss:0.07515403032302856
step 201/275, epoch 120/301 --> loss:0.06711338758468628
step 211/275, epoch 120/301 --> loss:0.05654740333557129
step 221/275, epoch 120/301 --> loss:0.057393991947174074
step 231/275, epoch 120/301 --> loss:0.056319248676300046
step 241/275, epoch 120/301 --> loss:0.05642727017402649
step 251/275, epoch 120/301 --> loss:0.05725155472755432
step 261/275, epoch 120/301 --> loss:0.04842371940612793
step 271/275, epoch 120/301 --> loss:0.05683239698410034
step 11/275, epoch 121/301 --> loss:0.05484657883644104
step 21/275, epoch 121/301 --> loss:0.047976553440093994
step 31/275, epoch 121/301 --> loss:0.06507229804992676
step 41/275, epoch 121/301 --> loss:0.06293833255767822
step 51/275, epoch 121/301 --> loss:0.05169790983200073
step 61/275, epoch 121/301 --> loss:0.06141728162765503
step 71/275, epoch 121/301 --> loss:0.05215196013450622
step 81/275, epoch 121/301 --> loss:0.068250173330307
step 91/275, epoch 121/301 --> loss:0.05802635550498962
step 101/275, epoch 121/301 --> loss:0.06727207303047181
step 111/275, epoch 121/301 --> loss:0.05692604184150696
step 121/275, epoch 121/301 --> loss:0.059498769044876096
step 131/275, epoch 121/301 --> loss:0.05192114114761352
step 141/275, epoch 121/301 --> loss:0.06010967493057251
step 151/275, epoch 121/301 --> loss:0.04739735126495361
step 161/275, epoch 121/301 --> loss:0.06923751831054688
step 171/275, epoch 121/301 --> loss:0.049205219745635985
step 181/275, epoch 121/301 --> loss:0.05485868453979492
step 191/275, epoch 121/301 --> loss:0.05386943221092224
step 201/275, epoch 121/301 --> loss:0.050974476337432864
step 211/275, epoch 121/301 --> loss:0.0859486222267151
step 221/275, epoch 121/301 --> loss:0.05655982494354248
step 231/275, epoch 121/301 --> loss:0.05446137189865112
step 241/275, epoch 121/301 --> loss:0.06763420701026916
step 251/275, epoch 121/301 --> loss:0.05772068500518799
step 261/275, epoch 121/301 --> loss:0.06083235144615173
step 271/275, epoch 121/301 --> loss:0.05603593587875366
########## train dataset ##########
PLout index:  2
acc -->  [95.39405466074882]
F1 -->  {'F1': [0.9440206091701405], 'precision': [0.948516719881086], 'recall': [0.9395768274809471]}
########## eval dataset ##########
 40%|████      | 121/301 [11:35:52<19:34:35, 391.53s/it]PLout index:  2
acc -->  [92.84399082820187]
F1 -->  {'F1': [0.9147811254042335], 'precision': [0.9202589976314824], 'recall': [0.9093779633692455]}
save model!
 41%|████      | 122/301 [11:41:12<18:23:52, 370.02s/it]step 11/275, epoch 122/301 --> loss:0.05735817551612854
step 21/275, epoch 122/301 --> loss:0.06041243076324463
step 31/275, epoch 122/301 --> loss:0.0613919198513031
step 41/275, epoch 122/301 --> loss:0.06178067326545715
step 51/275, epoch 122/301 --> loss:0.058938443660736084
step 61/275, epoch 122/301 --> loss:0.06772263050079345
step 71/275, epoch 122/301 --> loss:0.050676369667053224
step 81/275, epoch 122/301 --> loss:0.053527849912643435
step 91/275, epoch 122/301 --> loss:0.05242927670478821
step 101/275, epoch 122/301 --> loss:0.05330878496170044
step 111/275, epoch 122/301 --> loss:0.04378166198730469
step 121/275, epoch 122/301 --> loss:0.0540006697177887
step 131/275, epoch 122/301 --> loss:0.04788121581077576
step 141/275, epoch 122/301 --> loss:0.057651710510253903
step 151/275, epoch 122/301 --> loss:0.06727949380874634
step 161/275, epoch 122/301 --> loss:0.06326442956924438
step 171/275, epoch 122/301 --> loss:0.061969637870788574
step 181/275, epoch 122/301 --> loss:0.05054289102554321
step 191/275, epoch 122/301 --> loss:0.06177076697349548
step 201/275, epoch 122/301 --> loss:0.0576407253742218
step 211/275, epoch 122/301 --> loss:0.06459325551986694
step 221/275, epoch 122/301 --> loss:0.056407636404037474
step 231/275, epoch 122/301 --> loss:0.051572281122207644
step 241/275, epoch 122/301 --> loss:0.046400195360183714
step 251/275, epoch 122/301 --> loss:0.06980037689208984
step 261/275, epoch 122/301 --> loss:0.045042669773101805
step 271/275, epoch 122/301 --> loss:0.06601818203926087
 41%|████      | 123/301 [11:46:32<17:33:14, 355.02s/it]step 11/275, epoch 123/301 --> loss:0.06449908018112183
step 21/275, epoch 123/301 --> loss:0.05929121375083923
step 31/275, epoch 123/301 --> loss:0.058664119243621825
step 41/275, epoch 123/301 --> loss:0.0665930986404419
step 51/275, epoch 123/301 --> loss:0.05318986177444458
step 61/275, epoch 123/301 --> loss:0.06901245713233947
step 71/275, epoch 123/301 --> loss:0.05791766047477722
step 81/275, epoch 123/301 --> loss:0.054642599821090695
step 91/275, epoch 123/301 --> loss:0.06518142819404601
step 101/275, epoch 123/301 --> loss:0.062264937162399295
step 111/275, epoch 123/301 --> loss:0.05626063346862793
step 121/275, epoch 123/301 --> loss:0.05356412529945374
step 131/275, epoch 123/301 --> loss:0.05637769103050232
step 141/275, epoch 123/301 --> loss:0.057293015718460086
step 151/275, epoch 123/301 --> loss:0.05258396863937378
step 161/275, epoch 123/301 --> loss:0.05982293486595154
step 171/275, epoch 123/301 --> loss:0.05584004521369934
step 181/275, epoch 123/301 --> loss:0.06257942318916321
step 191/275, epoch 123/301 --> loss:0.06408492326736451
step 201/275, epoch 123/301 --> loss:0.0527839183807373
step 211/275, epoch 123/301 --> loss:0.046974468231201175
step 221/275, epoch 123/301 --> loss:0.05461206436157227
step 231/275, epoch 123/301 --> loss:0.058283942937850955
step 241/275, epoch 123/301 --> loss:0.050988197326660156
step 251/275, epoch 123/301 --> loss:0.06655671000480652
step 261/275, epoch 123/301 --> loss:0.05879324674606323
step 271/275, epoch 123/301 --> loss:0.05947734117507934
 41%|████      | 124/301 [11:51:52<16:56:21, 344.53s/it]step 11/275, epoch 124/301 --> loss:0.07073342800140381
step 21/275, epoch 124/301 --> loss:0.06561267375946045
step 31/275, epoch 124/301 --> loss:0.059275376796722415
step 41/275, epoch 124/301 --> loss:0.05948432683944702
step 51/275, epoch 124/301 --> loss:0.04533869028091431
step 61/275, epoch 124/301 --> loss:0.06229549050331116
step 71/275, epoch 124/301 --> loss:0.0630499243736267
step 81/275, epoch 124/301 --> loss:0.0741734266281128
step 91/275, epoch 124/301 --> loss:0.06626437306404113
step 101/275, epoch 124/301 --> loss:0.04739336967468262
step 111/275, epoch 124/301 --> loss:0.060784393548965455
step 121/275, epoch 124/301 --> loss:0.04975625276565552
step 131/275, epoch 124/301 --> loss:0.04712823033332825
step 141/275, epoch 124/301 --> loss:0.05698263645172119
step 151/275, epoch 124/301 --> loss:0.05879027247428894
step 161/275, epoch 124/301 --> loss:0.05529118180274963
step 171/275, epoch 124/301 --> loss:0.05095483660697937
step 181/275, epoch 124/301 --> loss:0.06209632754325867
step 191/275, epoch 124/301 --> loss:0.0512482762336731
step 201/275, epoch 124/301 --> loss:0.057264047861099246
step 211/275, epoch 124/301 --> loss:0.05725482702255249
step 221/275, epoch 124/301 --> loss:0.05615373253822327
step 231/275, epoch 124/301 --> loss:0.06072503924369812
step 241/275, epoch 124/301 --> loss:0.05688350796699524
step 251/275, epoch 124/301 --> loss:0.056845438480377194
step 261/275, epoch 124/301 --> loss:0.06067013740539551
step 271/275, epoch 124/301 --> loss:0.05651828646659851
 42%|████▏     | 125/301 [11:57:12<16:29:09, 337.21s/it]step 11/275, epoch 125/301 --> loss:0.06638196706771851
step 21/275, epoch 125/301 --> loss:0.0542276680469513
step 31/275, epoch 125/301 --> loss:0.05110166072845459
step 41/275, epoch 125/301 --> loss:0.05600845813751221
step 51/275, epoch 125/301 --> loss:0.06128731369972229
step 61/275, epoch 125/301 --> loss:0.05359436869621277
step 71/275, epoch 125/301 --> loss:0.052569460868835446
step 81/275, epoch 125/301 --> loss:0.062095290422439574
step 91/275, epoch 125/301 --> loss:0.05243613123893738
step 101/275, epoch 125/301 --> loss:0.05676610469818115
step 111/275, epoch 125/301 --> loss:0.05713896751403809
step 121/275, epoch 125/301 --> loss:0.066571444272995
step 131/275, epoch 125/301 --> loss:0.06138668060302734
step 141/275, epoch 125/301 --> loss:0.05061563849449158
step 151/275, epoch 125/301 --> loss:0.05733690857887268
step 161/275, epoch 125/301 --> loss:0.04557347297668457
step 171/275, epoch 125/301 --> loss:0.05898171067237854
step 181/275, epoch 125/301 --> loss:0.07211632132530213
step 191/275, epoch 125/301 --> loss:0.0664221465587616
step 201/275, epoch 125/301 --> loss:0.05769607424736023
step 211/275, epoch 125/301 --> loss:0.046982818841934205
step 221/275, epoch 125/301 --> loss:0.06682918667793274
step 231/275, epoch 125/301 --> loss:0.050333303213119504
step 241/275, epoch 125/301 --> loss:0.05455922484397888
step 251/275, epoch 125/301 --> loss:0.06557970643043518
step 261/275, epoch 125/301 --> loss:0.05611821413040161
step 271/275, epoch 125/301 --> loss:0.06264581084251404
 42%|████▏     | 126/301 [12:02:33<16:08:55, 332.20s/it]step 11/275, epoch 126/301 --> loss:0.05023912787437439
step 21/275, epoch 126/301 --> loss:0.047734349966049194
step 31/275, epoch 126/301 --> loss:0.050330895185470584
step 41/275, epoch 126/301 --> loss:0.05760592222213745
step 51/275, epoch 126/301 --> loss:0.05990082025527954
step 61/275, epoch 126/301 --> loss:0.05378707051277161
step 71/275, epoch 126/301 --> loss:0.053160065412521364
step 81/275, epoch 126/301 --> loss:0.05789375305175781
step 91/275, epoch 126/301 --> loss:0.06733141541481018
step 101/275, epoch 126/301 --> loss:0.05426297783851623
step 111/275, epoch 126/301 --> loss:0.07063332200050354
step 121/275, epoch 126/301 --> loss:0.05621957778930664
step 131/275, epoch 126/301 --> loss:0.05178000926971436
step 141/275, epoch 126/301 --> loss:0.06236093640327454
step 151/275, epoch 126/301 --> loss:0.055306142568588255
step 161/275, epoch 126/301 --> loss:0.06531856656074524
step 171/275, epoch 126/301 --> loss:0.06159952878952026
step 181/275, epoch 126/301 --> loss:0.05809804201126099
step 191/275, epoch 126/301 --> loss:0.05836801528930664
step 201/275, epoch 126/301 --> loss:0.054841816425323486
step 211/275, epoch 126/301 --> loss:0.044306600093841554
step 221/275, epoch 126/301 --> loss:0.054657232761383054
step 231/275, epoch 126/301 --> loss:0.05669738650321961
step 241/275, epoch 126/301 --> loss:0.04458751678466797
step 251/275, epoch 126/301 --> loss:0.0482904851436615
step 261/275, epoch 126/301 --> loss:0.06468368768692016
step 271/275, epoch 126/301 --> loss:0.05692851543426514
 42%|████▏     | 127/301 [12:07:52<15:51:55, 328.25s/it]step 11/275, epoch 127/301 --> loss:0.04784497022628784
step 21/275, epoch 127/301 --> loss:0.058063215017318724
step 31/275, epoch 127/301 --> loss:0.05023313760757446
step 41/275, epoch 127/301 --> loss:0.057811015844345094
step 51/275, epoch 127/301 --> loss:0.06607995629310608
step 61/275, epoch 127/301 --> loss:0.0644576370716095
step 71/275, epoch 127/301 --> loss:0.05387108325958252
step 81/275, epoch 127/301 --> loss:0.048739182949066165
step 91/275, epoch 127/301 --> loss:0.0627963125705719
step 101/275, epoch 127/301 --> loss:0.0607113242149353
step 111/275, epoch 127/301 --> loss:0.05133037567138672
step 121/275, epoch 127/301 --> loss:0.06081162691116333
step 131/275, epoch 127/301 --> loss:0.048394954204559325
step 141/275, epoch 127/301 --> loss:0.04463862180709839
step 151/275, epoch 127/301 --> loss:0.05552494525909424
step 161/275, epoch 127/301 --> loss:0.040643823146820066
step 171/275, epoch 127/301 --> loss:0.05467482209205628
step 181/275, epoch 127/301 --> loss:0.05513303279876709
step 191/275, epoch 127/301 --> loss:0.04773789644241333
step 201/275, epoch 127/301 --> loss:0.05105276107788086
step 211/275, epoch 127/301 --> loss:0.062028586864471436
step 221/275, epoch 127/301 --> loss:0.05632931590080261
step 231/275, epoch 127/301 --> loss:0.05949286818504333
step 241/275, epoch 127/301 --> loss:0.056320637464523315
step 251/275, epoch 127/301 --> loss:0.05502634048461914
step 261/275, epoch 127/301 --> loss:0.05973824262619019
step 271/275, epoch 127/301 --> loss:0.0635882556438446
 43%|████▎     | 128/301 [12:13:09<15:36:48, 324.90s/it]step 11/275, epoch 128/301 --> loss:0.05898504257202149
step 21/275, epoch 128/301 --> loss:0.0520995557308197
step 31/275, epoch 128/301 --> loss:0.05484464764595032
step 41/275, epoch 128/301 --> loss:0.05725507736206055
step 51/275, epoch 128/301 --> loss:0.05486174821853638
step 61/275, epoch 128/301 --> loss:0.05086208581924438
step 71/275, epoch 128/301 --> loss:0.05331662893295288
step 81/275, epoch 128/301 --> loss:0.05458586812019348
step 91/275, epoch 128/301 --> loss:0.04291512966156006
step 101/275, epoch 128/301 --> loss:0.05577377080917358
step 111/275, epoch 128/301 --> loss:0.04899553060531616
step 121/275, epoch 128/301 --> loss:0.05362971425056458
step 131/275, epoch 128/301 --> loss:0.05363643765449524
step 141/275, epoch 128/301 --> loss:0.05274828672409058
step 151/275, epoch 128/301 --> loss:0.05323270559310913
step 161/275, epoch 128/301 --> loss:0.05684850215911865
step 171/275, epoch 128/301 --> loss:0.048293155431747434
step 181/275, epoch 128/301 --> loss:0.05761184096336365
step 191/275, epoch 128/301 --> loss:0.051521456241607665
step 201/275, epoch 128/301 --> loss:0.05553543567657471
step 211/275, epoch 128/301 --> loss:0.04338493347167969
step 221/275, epoch 128/301 --> loss:0.06602323055267334
step 231/275, epoch 128/301 --> loss:0.05643705129623413
step 241/275, epoch 128/301 --> loss:0.05355879068374634
step 251/275, epoch 128/301 --> loss:0.06404575109481811
step 261/275, epoch 128/301 --> loss:0.05601475834846496
step 271/275, epoch 128/301 --> loss:0.06541749238967895
 43%|████▎     | 129/301 [12:18:29<15:26:46, 323.29s/it]step 11/275, epoch 129/301 --> loss:0.048127108812332155
step 21/275, epoch 129/301 --> loss:0.06489617228507996
step 31/275, epoch 129/301 --> loss:0.06255278587341309
step 41/275, epoch 129/301 --> loss:0.06601583957672119
step 51/275, epoch 129/301 --> loss:0.061771684885025026
step 61/275, epoch 129/301 --> loss:0.05604878067970276
step 71/275, epoch 129/301 --> loss:0.0643236517906189
step 81/275, epoch 129/301 --> loss:0.06895045042037964
step 91/275, epoch 129/301 --> loss:0.06882252097129822
step 101/275, epoch 129/301 --> loss:0.04919055104255676
step 111/275, epoch 129/301 --> loss:0.04617980122566223
step 121/275, epoch 129/301 --> loss:0.062205612659454346
step 131/275, epoch 129/301 --> loss:0.054150325059890744
step 141/275, epoch 129/301 --> loss:0.060110777616500854
step 151/275, epoch 129/301 --> loss:0.057261472940444945
step 161/275, epoch 129/301 --> loss:0.06660081148147583
step 171/275, epoch 129/301 --> loss:0.05098976492881775
step 181/275, epoch 129/301 --> loss:0.05386006236076355
step 191/275, epoch 129/301 --> loss:0.052296501398086545
step 201/275, epoch 129/301 --> loss:0.040704721212387086
step 211/275, epoch 129/301 --> loss:0.04856076240539551
step 221/275, epoch 129/301 --> loss:0.04839025735855103
step 231/275, epoch 129/301 --> loss:0.04735709428787231
step 241/275, epoch 129/301 --> loss:0.052240890264511106
step 251/275, epoch 129/301 --> loss:0.05364754796028137
step 261/275, epoch 129/301 --> loss:0.056162130832672116
step 271/275, epoch 129/301 --> loss:0.05378024578094483
 43%|████▎     | 130/301 [12:23:50<15:19:25, 322.61s/it]step 11/275, epoch 130/301 --> loss:0.055441439151763916
step 21/275, epoch 130/301 --> loss:0.06996609568595887
step 31/275, epoch 130/301 --> loss:0.05650413632392883
step 41/275, epoch 130/301 --> loss:0.049974995851516726
step 51/275, epoch 130/301 --> loss:0.055979025363922116
step 61/275, epoch 130/301 --> loss:0.050529688596725464
step 71/275, epoch 130/301 --> loss:0.06314457654953003
step 81/275, epoch 130/301 --> loss:0.06764695048332214
step 91/275, epoch 130/301 --> loss:0.0483036994934082
step 101/275, epoch 130/301 --> loss:0.06935583353042603
step 111/275, epoch 130/301 --> loss:0.05463194251060486
step 121/275, epoch 130/301 --> loss:0.06382124423980713
step 131/275, epoch 130/301 --> loss:0.05239830613136291
step 141/275, epoch 130/301 --> loss:0.06501536965370178
step 151/275, epoch 130/301 --> loss:0.06862447261810303
step 161/275, epoch 130/301 --> loss:0.05757755637168884
step 171/275, epoch 130/301 --> loss:0.06051313281059265
step 181/275, epoch 130/301 --> loss:0.053520983457565306
step 191/275, epoch 130/301 --> loss:0.05345464944839477
step 201/275, epoch 130/301 --> loss:0.05169429183006287
step 211/275, epoch 130/301 --> loss:0.05615385174751282
step 221/275, epoch 130/301 --> loss:0.0586318850517273
step 231/275, epoch 130/301 --> loss:0.05069453120231628
step 241/275, epoch 130/301 --> loss:0.0578787624835968
step 251/275, epoch 130/301 --> loss:0.04099082350730896
step 261/275, epoch 130/301 --> loss:0.06383338570594788
step 271/275, epoch 130/301 --> loss:0.04901052713394165
step 11/275, epoch 131/301 --> loss:0.055620217323303224
step 21/275, epoch 131/301 --> loss:0.0513420581817627
step 31/275, epoch 131/301 --> loss:0.05550534129142761
step 41/275, epoch 131/301 --> loss:0.05079950094223022
step 51/275, epoch 131/301 --> loss:0.055158191919326784
step 61/275, epoch 131/301 --> loss:0.0527030348777771
step 71/275, epoch 131/301 --> loss:0.04863365888595581
step 81/275, epoch 131/301 --> loss:0.04583717584609985
step 91/275, epoch 131/301 --> loss:0.056520086526870725
step 101/275, epoch 131/301 --> loss:0.058479171991348264
step 111/275, epoch 131/301 --> loss:0.05725677609443665
step 121/275, epoch 131/301 --> loss:0.04866521954536438
step 131/275, epoch 131/301 --> loss:0.05611915588378906
step 141/275, epoch 131/301 --> loss:0.050898957252502444
step 151/275, epoch 131/301 --> loss:0.05626073479652405
step 161/275, epoch 131/301 --> loss:0.06487959027290344
step 171/275, epoch 131/301 --> loss:0.05064237117767334
step 181/275, epoch 131/301 --> loss:0.061032426357269284
step 191/275, epoch 131/301 --> loss:0.057964617013931276
step 201/275, epoch 131/301 --> loss:0.054793745279312134
step 211/275, epoch 131/301 --> loss:0.055338305234909055
step 221/275, epoch 131/301 --> loss:0.05002901554107666
step 231/275, epoch 131/301 --> loss:0.052051329612731935
step 241/275, epoch 131/301 --> loss:0.061185640096664426
step 251/275, epoch 131/301 --> loss:0.04148882031440735
step 261/275, epoch 131/301 --> loss:0.04744275808334351
step 271/275, epoch 131/301 --> loss:0.07219545841217041
########## train dataset ##########
PLout index:  2
acc -->  [96.01990650831135]
F1 -->  {'F1': [0.9514003847657803], 'precision': [0.9604615359903944], 'recall': [0.9425184175140318]}
########## eval dataset ##########
 44%|████▎     | 131/301 [12:33:07<18:33:53, 393.14s/it]PLout index:  2
acc -->  [93.21544958759574]
F1 -->  {'F1': [0.9186634090353464], 'precision': [0.9304704253766561], 'recall': [0.9071620329344877]}
save model!
 44%|████▍     | 132/301 [12:38:25<17:23:16, 370.39s/it]step 11/275, epoch 132/301 --> loss:0.05183481574058533
step 21/275, epoch 132/301 --> loss:0.05097371935844421
step 31/275, epoch 132/301 --> loss:0.05324414372444153
step 41/275, epoch 132/301 --> loss:0.059428977966308597
step 51/275, epoch 132/301 --> loss:0.049798989295959474
step 61/275, epoch 132/301 --> loss:0.06410089731216431
step 71/275, epoch 132/301 --> loss:0.05271672010421753
step 81/275, epoch 132/301 --> loss:0.056316417455673215
step 91/275, epoch 132/301 --> loss:0.061616694927215575
step 101/275, epoch 132/301 --> loss:0.05541312098503113
step 111/275, epoch 132/301 --> loss:0.05813987255096435
step 121/275, epoch 132/301 --> loss:0.04783340692520142
step 131/275, epoch 132/301 --> loss:0.05137099027633667
step 141/275, epoch 132/301 --> loss:0.052883440256118776
step 151/275, epoch 132/301 --> loss:0.055184674263000486
step 161/275, epoch 132/301 --> loss:0.05575630664825439
step 171/275, epoch 132/301 --> loss:0.055984729528427125
step 181/275, epoch 132/301 --> loss:0.05635862946510315
step 191/275, epoch 132/301 --> loss:0.04686726331710815
step 201/275, epoch 132/301 --> loss:0.060847097635269166
step 211/275, epoch 132/301 --> loss:0.04755880236625672
step 221/275, epoch 132/301 --> loss:0.0448575496673584
step 231/275, epoch 132/301 --> loss:0.0460024893283844
step 241/275, epoch 132/301 --> loss:0.0473747968673706
step 251/275, epoch 132/301 --> loss:0.05395410656929016
step 261/275, epoch 132/301 --> loss:0.060254746675491334
step 271/275, epoch 132/301 --> loss:0.05814424753189087
 44%|████▍     | 133/301 [12:43:41<16:31:25, 354.08s/it]step 11/275, epoch 133/301 --> loss:0.0682095468044281
step 21/275, epoch 133/301 --> loss:0.053775453567504884
step 31/275, epoch 133/301 --> loss:0.06414023637771607
step 41/275, epoch 133/301 --> loss:0.04793064594268799
step 51/275, epoch 133/301 --> loss:0.058649367094039916
step 61/275, epoch 133/301 --> loss:0.05715060234069824
step 71/275, epoch 133/301 --> loss:0.05939281582832336
step 81/275, epoch 133/301 --> loss:0.05794495940208435
step 91/275, epoch 133/301 --> loss:0.05538095235824585
step 101/275, epoch 133/301 --> loss:0.051497858762741086
step 111/275, epoch 133/301 --> loss:0.05032755732536316
step 121/275, epoch 133/301 --> loss:0.04815978407859802
step 131/275, epoch 133/301 --> loss:0.04844018816947937
step 141/275, epoch 133/301 --> loss:0.04759811162948609
step 151/275, epoch 133/301 --> loss:0.05850790143013
step 161/275, epoch 133/301 --> loss:0.04421064257621765
step 171/275, epoch 133/301 --> loss:0.06091921329498291
step 181/275, epoch 133/301 --> loss:0.04862509965896607
step 191/275, epoch 133/301 --> loss:0.0457358717918396
step 201/275, epoch 133/301 --> loss:0.05247880220413208
step 211/275, epoch 133/301 --> loss:0.05330636501312256
step 221/275, epoch 133/301 --> loss:0.061995744705200195
step 231/275, epoch 133/301 --> loss:0.05048330426216126
step 241/275, epoch 133/301 --> loss:0.05584468245506287
step 251/275, epoch 133/301 --> loss:0.06553460359573364
step 261/275, epoch 133/301 --> loss:0.05036039352416992
step 271/275, epoch 133/301 --> loss:0.044022482633590695
 45%|████▍     | 134/301 [12:48:56<15:53:20, 342.52s/it]step 11/275, epoch 134/301 --> loss:0.049798494577407836
step 21/275, epoch 134/301 --> loss:0.05552910566329956
step 31/275, epoch 134/301 --> loss:0.05226885676383972
step 41/275, epoch 134/301 --> loss:0.048112344741821286
step 51/275, epoch 134/301 --> loss:0.05101524591445923
step 61/275, epoch 134/301 --> loss:0.05438403487205505
step 71/275, epoch 134/301 --> loss:0.04588610529899597
step 81/275, epoch 134/301 --> loss:0.05126394629478455
step 91/275, epoch 134/301 --> loss:0.05600766539573669
step 101/275, epoch 134/301 --> loss:0.049249082803726196
step 111/275, epoch 134/301 --> loss:0.05649566650390625
step 121/275, epoch 134/301 --> loss:0.04815419912338257
step 131/275, epoch 134/301 --> loss:0.05415371060371399
step 141/275, epoch 134/301 --> loss:0.051867049932479856
step 151/275, epoch 134/301 --> loss:0.06207643151283264
step 161/275, epoch 134/301 --> loss:0.056146031618118285
step 171/275, epoch 134/301 --> loss:0.05934249758720398
step 181/275, epoch 134/301 --> loss:0.06439366936683655
step 191/275, epoch 134/301 --> loss:0.05323695540428162
step 201/275, epoch 134/301 --> loss:0.06146699786186218
step 211/275, epoch 134/301 --> loss:0.055494886636734006
step 221/275, epoch 134/301 --> loss:0.051528894901275636
step 231/275, epoch 134/301 --> loss:0.0442809522151947
step 241/275, epoch 134/301 --> loss:0.05089632272720337
step 251/275, epoch 134/301 --> loss:0.055026912689208986
step 261/275, epoch 134/301 --> loss:0.05846140384674072
step 271/275, epoch 134/301 --> loss:0.054117655754089354
 45%|████▍     | 135/301 [12:54:13<15:26:25, 334.85s/it]step 11/275, epoch 135/301 --> loss:0.05200760364532471
step 21/275, epoch 135/301 --> loss:0.06336905360221863
step 31/275, epoch 135/301 --> loss:0.05201994776725769
step 41/275, epoch 135/301 --> loss:0.04809833168983459
step 51/275, epoch 135/301 --> loss:0.051908177137374875
step 61/275, epoch 135/301 --> loss:0.060175496339797976
step 71/275, epoch 135/301 --> loss:0.05548595190048218
step 81/275, epoch 135/301 --> loss:0.059349173307418825
step 91/275, epoch 135/301 --> loss:0.055744463205337526
step 101/275, epoch 135/301 --> loss:0.05032219886779785
step 111/275, epoch 135/301 --> loss:0.060386908054351804
step 121/275, epoch 135/301 --> loss:0.057779508829116824
step 131/275, epoch 135/301 --> loss:0.05474730134010315
step 141/275, epoch 135/301 --> loss:0.053107964992523196
step 151/275, epoch 135/301 --> loss:0.0446051836013794
step 161/275, epoch 135/301 --> loss:0.04743911623954773
step 171/275, epoch 135/301 --> loss:0.046521836519241334
step 181/275, epoch 135/301 --> loss:0.04622406959533691
step 191/275, epoch 135/301 --> loss:0.05490021705627442
step 201/275, epoch 135/301 --> loss:0.05698400139808655
step 211/275, epoch 135/301 --> loss:0.06504217386245728
step 221/275, epoch 135/301 --> loss:0.047950857877731325
step 231/275, epoch 135/301 --> loss:0.045255225896835324
step 241/275, epoch 135/301 --> loss:0.052460873126983644
step 251/275, epoch 135/301 --> loss:0.062227219343185425
step 261/275, epoch 135/301 --> loss:0.05246372818946839
step 271/275, epoch 135/301 --> loss:0.052046799659729005
 45%|████▌     | 136/301 [12:59:32<15:07:39, 330.06s/it]step 11/275, epoch 136/301 --> loss:0.05615912079811096
step 21/275, epoch 136/301 --> loss:0.049106931686401366
step 31/275, epoch 136/301 --> loss:0.05958656072616577
step 41/275, epoch 136/301 --> loss:0.05485607385635376
step 51/275, epoch 136/301 --> loss:0.05730031132698059
step 61/275, epoch 136/301 --> loss:0.06471112370491028
step 71/275, epoch 136/301 --> loss:0.057077044248580934
step 81/275, epoch 136/301 --> loss:0.052706938982009885
step 91/275, epoch 136/301 --> loss:0.05137215852737427
step 101/275, epoch 136/301 --> loss:0.051090145111083986
step 111/275, epoch 136/301 --> loss:0.05616482496261597
step 121/275, epoch 136/301 --> loss:0.055392777919769286
step 131/275, epoch 136/301 --> loss:0.04812091588973999
step 141/275, epoch 136/301 --> loss:0.05397183299064636
step 151/275, epoch 136/301 --> loss:0.06757323145866394
step 161/275, epoch 136/301 --> loss:0.05546379089355469
step 171/275, epoch 136/301 --> loss:0.06912888288497925
step 181/275, epoch 136/301 --> loss:0.03794493079185486
step 191/275, epoch 136/301 --> loss:0.044987207651138304
step 201/275, epoch 136/301 --> loss:0.05265301465988159
step 211/275, epoch 136/301 --> loss:0.05266256928443909
step 221/275, epoch 136/301 --> loss:0.04597828388214111
step 231/275, epoch 136/301 --> loss:0.05007432103157043
step 241/275, epoch 136/301 --> loss:0.04856545329093933
step 251/275, epoch 136/301 --> loss:0.054118359088897706
step 261/275, epoch 136/301 --> loss:0.059642899036407473
step 271/275, epoch 136/301 --> loss:0.046151894330978396
 46%|████▌     | 137/301 [13:04:52<14:53:45, 326.98s/it]step 11/275, epoch 137/301 --> loss:0.06330726742744446
step 21/275, epoch 137/301 --> loss:0.0503142774105072
step 31/275, epoch 137/301 --> loss:0.05100084543228149
step 41/275, epoch 137/301 --> loss:0.05478096008300781
step 51/275, epoch 137/301 --> loss:0.04896827340126038
step 61/275, epoch 137/301 --> loss:0.04954964518547058
step 71/275, epoch 137/301 --> loss:0.049950522184371945
step 81/275, epoch 137/301 --> loss:0.05531801581382752
step 91/275, epoch 137/301 --> loss:0.04369284510612488
step 101/275, epoch 137/301 --> loss:0.05166907906532288
step 111/275, epoch 137/301 --> loss:0.05140330791473389
step 121/275, epoch 137/301 --> loss:0.06252619624137878
step 131/275, epoch 137/301 --> loss:0.05203368067741394
step 141/275, epoch 137/301 --> loss:0.04782410264015198
step 151/275, epoch 137/301 --> loss:0.05532190203666687
step 161/275, epoch 137/301 --> loss:0.049879425764083864
step 171/275, epoch 137/301 --> loss:0.05840192437171936
step 181/275, epoch 137/301 --> loss:0.04522351026535034
step 191/275, epoch 137/301 --> loss:0.05619495511054993
step 201/275, epoch 137/301 --> loss:0.04959518313407898
step 211/275, epoch 137/301 --> loss:0.04924955368041992
step 221/275, epoch 137/301 --> loss:0.05093283653259277
step 231/275, epoch 137/301 --> loss:0.04971953630447388
step 241/275, epoch 137/301 --> loss:0.049963909387588504
step 251/275, epoch 137/301 --> loss:0.05269486904144287
step 261/275, epoch 137/301 --> loss:0.05356965065002441
step 271/275, epoch 137/301 --> loss:0.036791884899139406
 46%|████▌     | 138/301 [13:10:11<14:42:17, 324.77s/it]step 11/275, epoch 138/301 --> loss:0.046930831670761106
step 21/275, epoch 138/301 --> loss:0.04846380352973938
step 31/275, epoch 138/301 --> loss:0.048535221815109254
step 41/275, epoch 138/301 --> loss:0.059357482194900515
step 51/275, epoch 138/301 --> loss:0.046685463190078734
step 61/275, epoch 138/301 --> loss:0.043991255760192874
step 71/275, epoch 138/301 --> loss:0.0495987057685852
step 81/275, epoch 138/301 --> loss:0.04473049640655517
step 91/275, epoch 138/301 --> loss:0.05176079273223877
step 101/275, epoch 138/301 --> loss:0.04768047332763672
step 111/275, epoch 138/301 --> loss:0.04644116163253784
step 121/275, epoch 138/301 --> loss:0.05495480895042419
step 131/275, epoch 138/301 --> loss:0.059253746271133424
step 141/275, epoch 138/301 --> loss:0.06769668459892272
step 151/275, epoch 138/301 --> loss:0.05307415723800659
step 161/275, epoch 138/301 --> loss:0.062117469310760495
step 171/275, epoch 138/301 --> loss:0.05425470471382141
step 181/275, epoch 138/301 --> loss:0.04982483983039856
step 191/275, epoch 138/301 --> loss:0.058860105276107785
step 201/275, epoch 138/301 --> loss:0.0604577898979187
step 211/275, epoch 138/301 --> loss:0.058900654315948486
step 221/275, epoch 138/301 --> loss:0.05509825944900513
step 231/275, epoch 138/301 --> loss:0.04220839738845825
step 241/275, epoch 138/301 --> loss:0.05963746905326843
step 251/275, epoch 138/301 --> loss:0.061799037456512454
step 261/275, epoch 138/301 --> loss:0.0613531231880188
step 271/275, epoch 138/301 --> loss:0.05673196315765381
 46%|████▌     | 139/301 [13:15:31<14:32:36, 323.19s/it]step 11/275, epoch 139/301 --> loss:0.042212283611297606
step 21/275, epoch 139/301 --> loss:0.04631307125091553
step 31/275, epoch 139/301 --> loss:0.04981289505958557
step 41/275, epoch 139/301 --> loss:0.05693444013595581
step 51/275, epoch 139/301 --> loss:0.05148555040359497
step 61/275, epoch 139/301 --> loss:0.05309308171272278
step 71/275, epoch 139/301 --> loss:0.04400688409805298
step 81/275, epoch 139/301 --> loss:0.04937431812286377
step 91/275, epoch 139/301 --> loss:0.051774853467941286
step 101/275, epoch 139/301 --> loss:0.04379883408546448
step 111/275, epoch 139/301 --> loss:0.05371800661087036
step 121/275, epoch 139/301 --> loss:0.05292008519172668
step 131/275, epoch 139/301 --> loss:0.061072146892547606
step 141/275, epoch 139/301 --> loss:0.05607522130012512
step 151/275, epoch 139/301 --> loss:0.051052254438400266
step 161/275, epoch 139/301 --> loss:0.056630653142929074
step 171/275, epoch 139/301 --> loss:0.06124101877212525
step 181/275, epoch 139/301 --> loss:0.06021168828010559
step 191/275, epoch 139/301 --> loss:0.050650930404663085
step 201/275, epoch 139/301 --> loss:0.054234659671783446
step 211/275, epoch 139/301 --> loss:0.06302910447120666
step 221/275, epoch 139/301 --> loss:0.05534021258354187
step 231/275, epoch 139/301 --> loss:0.06401444077491761
step 241/275, epoch 139/301 --> loss:0.06530488729476928
step 251/275, epoch 139/301 --> loss:0.06530683636665344
step 261/275, epoch 139/301 --> loss:0.05235835313796997
step 271/275, epoch 139/301 --> loss:0.04779740571975708
 47%|████▋     | 140/301 [13:20:51<14:24:21, 322.12s/it]step 11/275, epoch 140/301 --> loss:0.04415460824966431
step 21/275, epoch 140/301 --> loss:0.047396785020828246
step 31/275, epoch 140/301 --> loss:0.058730071783065795
step 41/275, epoch 140/301 --> loss:0.06207682490348816
step 51/275, epoch 140/301 --> loss:0.05839828252792358
step 61/275, epoch 140/301 --> loss:0.0536917507648468
step 71/275, epoch 140/301 --> loss:0.04966591596603394
step 81/275, epoch 140/301 --> loss:0.048314636945724486
step 91/275, epoch 140/301 --> loss:0.045546501874923706
step 101/275, epoch 140/301 --> loss:0.04843405485153198
step 111/275, epoch 140/301 --> loss:0.056947356462478636
step 121/275, epoch 140/301 --> loss:0.06393258571624756
step 131/275, epoch 140/301 --> loss:0.05109137296676636
step 141/275, epoch 140/301 --> loss:0.049778974056243895
step 151/275, epoch 140/301 --> loss:0.056617385149002074
step 161/275, epoch 140/301 --> loss:0.04940738677978516
step 171/275, epoch 140/301 --> loss:0.045043843984603885
step 181/275, epoch 140/301 --> loss:0.05596833229064942
step 191/275, epoch 140/301 --> loss:0.055641943216323854
step 201/275, epoch 140/301 --> loss:0.05110874176025391
step 211/275, epoch 140/301 --> loss:0.039573115110397336
step 221/275, epoch 140/301 --> loss:0.060806053876876834
step 231/275, epoch 140/301 --> loss:0.05457771420478821
step 241/275, epoch 140/301 --> loss:0.050857162475585936
step 251/275, epoch 140/301 --> loss:0.04826418161392212
step 261/275, epoch 140/301 --> loss:0.05018186569213867
step 271/275, epoch 140/301 --> loss:0.05353835821151733
step 11/275, epoch 141/301 --> loss:0.0654936671257019
step 21/275, epoch 141/301 --> loss:0.061694175004959106
step 31/275, epoch 141/301 --> loss:0.0533671498298645
step 41/275, epoch 141/301 --> loss:0.056553053855896
step 51/275, epoch 141/301 --> loss:0.053745603561401366
step 61/275, epoch 141/301 --> loss:0.0487744152545929
step 71/275, epoch 141/301 --> loss:0.05708974599838257
step 81/275, epoch 141/301 --> loss:0.0491369366645813
step 91/275, epoch 141/301 --> loss:0.0508081316947937
step 101/275, epoch 141/301 --> loss:0.05170654058456421
step 111/275, epoch 141/301 --> loss:0.03986418843269348
step 121/275, epoch 141/301 --> loss:0.04880996346473694
step 131/275, epoch 141/301 --> loss:0.04453996419906616
step 141/275, epoch 141/301 --> loss:0.06898279190063476
step 151/275, epoch 141/301 --> loss:0.04746353030204773
step 161/275, epoch 141/301 --> loss:0.04747587442398071
step 171/275, epoch 141/301 --> loss:0.05883312225341797
step 181/275, epoch 141/301 --> loss:0.056587255001068114
step 191/275, epoch 141/301 --> loss:0.049966460466384886
step 201/275, epoch 141/301 --> loss:0.05011304616928101
step 211/275, epoch 141/301 --> loss:0.043923217058181765
step 221/275, epoch 141/301 --> loss:0.0502915620803833
step 231/275, epoch 141/301 --> loss:0.05920494794845581
step 241/275, epoch 141/301 --> loss:0.056636446714401247
step 251/275, epoch 141/301 --> loss:0.05633001327514649
step 261/275, epoch 141/301 --> loss:0.05161431431770325
step 271/275, epoch 141/301 --> loss:0.05449815392494202
########## train dataset ##########
PLout index:  2
acc -->  [96.23266518045355]
F1 -->  {'F1': [0.9545016074772982], 'precision': [0.9529608692018139], 'recall': [0.9560573683116682]}
########## eval dataset ##########
 47%|████▋     | 141/301 [13:30:08<17:27:01, 392.63s/it]PLout index:  2
acc -->  [93.20086869631815]
F1 -->  {'F1': [0.9195240087416232], 'precision': [0.9193631440674126], 'recall': [0.9196949332200591]}
save model!
 47%|████▋     | 142/301 [13:35:28<16:22:54, 370.91s/it]step 11/275, epoch 142/301 --> loss:0.05273601412773132
step 21/275, epoch 142/301 --> loss:0.06031374335289001
step 31/275, epoch 142/301 --> loss:0.04727728962898255
step 41/275, epoch 142/301 --> loss:0.047182786464691165
step 51/275, epoch 142/301 --> loss:0.0554279625415802
step 61/275, epoch 142/301 --> loss:0.045052486658096316
step 71/275, epoch 142/301 --> loss:0.048923856019973753
step 81/275, epoch 142/301 --> loss:0.043144327402114865
step 91/275, epoch 142/301 --> loss:0.049532335996627805
step 101/275, epoch 142/301 --> loss:0.062037086486816405
step 111/275, epoch 142/301 --> loss:0.04977460503578186
step 121/275, epoch 142/301 --> loss:0.05342346429824829
step 131/275, epoch 142/301 --> loss:0.056859266757965085
step 141/275, epoch 142/301 --> loss:0.05682346820831299
step 151/275, epoch 142/301 --> loss:0.05210944414138794
step 161/275, epoch 142/301 --> loss:0.05405291318893433
step 171/275, epoch 142/301 --> loss:0.049909907579422
step 181/275, epoch 142/301 --> loss:0.06157234311103821
step 191/275, epoch 142/301 --> loss:0.059544104337692264
step 201/275, epoch 142/301 --> loss:0.055570590496063235
step 211/275, epoch 142/301 --> loss:0.052815449237823484
step 221/275, epoch 142/301 --> loss:0.05979245901107788
step 231/275, epoch 142/301 --> loss:0.057362353801727294
step 241/275, epoch 142/301 --> loss:0.04331852793693543
step 251/275, epoch 142/301 --> loss:0.048525106906890866
step 261/275, epoch 142/301 --> loss:0.05490622520446777
step 271/275, epoch 142/301 --> loss:0.05359717607498169
 48%|████▊     | 143/301 [13:40:48<15:36:32, 355.65s/it]step 11/275, epoch 143/301 --> loss:0.05294057130813599
step 21/275, epoch 143/301 --> loss:0.05134750008583069
step 31/275, epoch 143/301 --> loss:0.05093494653701782
step 41/275, epoch 143/301 --> loss:0.04831822514533997
step 51/275, epoch 143/301 --> loss:0.05208151936531067
step 61/275, epoch 143/301 --> loss:0.049681288003921506
step 71/275, epoch 143/301 --> loss:0.04516484141349793
step 81/275, epoch 143/301 --> loss:0.05416354537010193
step 91/275, epoch 143/301 --> loss:0.04746751189231872
step 101/275, epoch 143/301 --> loss:0.04458841681480408
step 111/275, epoch 143/301 --> loss:0.05318818688392639
step 121/275, epoch 143/301 --> loss:0.050670850276947024
step 131/275, epoch 143/301 --> loss:0.06229529976844787
step 141/275, epoch 143/301 --> loss:0.05981245040893555
step 151/275, epoch 143/301 --> loss:0.05410133004188537
step 161/275, epoch 143/301 --> loss:0.051160764694213864
step 171/275, epoch 143/301 --> loss:0.053152036666870114
step 181/275, epoch 143/301 --> loss:0.04191973805427551
step 191/275, epoch 143/301 --> loss:0.0512813925743103
step 201/275, epoch 143/301 --> loss:0.05036890506744385
step 211/275, epoch 143/301 --> loss:0.045508581399917605
step 221/275, epoch 143/301 --> loss:0.04605586528778076
step 231/275, epoch 143/301 --> loss:0.04894141554832458
step 241/275, epoch 143/301 --> loss:0.05683436989784241
step 251/275, epoch 143/301 --> loss:0.06277182698249817
step 261/275, epoch 143/301 --> loss:0.05971571207046509
step 271/275, epoch 143/301 --> loss:0.05130165219306946
 48%|████▊     | 144/301 [13:46:06<15:00:50, 344.27s/it]step 11/275, epoch 144/301 --> loss:0.05526843070983887
step 21/275, epoch 144/301 --> loss:0.048635995388031004
step 31/275, epoch 144/301 --> loss:0.05905529856681824
step 41/275, epoch 144/301 --> loss:0.04261864423751831
step 51/275, epoch 144/301 --> loss:0.05593942403793335
step 61/275, epoch 144/301 --> loss:0.046299368143081665
step 71/275, epoch 144/301 --> loss:0.059875094890594484
step 81/275, epoch 144/301 --> loss:0.04251295328140259
step 91/275, epoch 144/301 --> loss:0.06191944479942322
step 101/275, epoch 144/301 --> loss:0.05339572429656982
step 111/275, epoch 144/301 --> loss:0.05069040060043335
step 121/275, epoch 144/301 --> loss:0.048002499341964724
step 131/275, epoch 144/301 --> loss:0.05121470689773559
step 141/275, epoch 144/301 --> loss:0.04214771389961243
step 151/275, epoch 144/301 --> loss:0.050375509262084964
step 161/275, epoch 144/301 --> loss:0.05838214755058289
step 171/275, epoch 144/301 --> loss:0.045598548650741574
step 181/275, epoch 144/301 --> loss:0.06636422872543335
step 191/275, epoch 144/301 --> loss:0.049235802888870236
step 201/275, epoch 144/301 --> loss:0.050234878063201906
step 211/275, epoch 144/301 --> loss:0.03584689497947693
step 221/275, epoch 144/301 --> loss:0.05185673832893371
step 231/275, epoch 144/301 --> loss:0.05119301080703735
step 241/275, epoch 144/301 --> loss:0.04894247651100159
step 251/275, epoch 144/301 --> loss:0.04650363326072693
step 261/275, epoch 144/301 --> loss:0.0577808678150177
step 271/275, epoch 144/301 --> loss:0.044389408826828
 48%|████▊     | 145/301 [13:51:23<14:34:28, 336.33s/it]step 11/275, epoch 145/301 --> loss:0.05881067514419556
step 21/275, epoch 145/301 --> loss:0.06485811471939087
step 31/275, epoch 145/301 --> loss:0.055026513338088986
step 41/275, epoch 145/301 --> loss:0.05400403738021851
step 51/275, epoch 145/301 --> loss:0.056323295831680296
step 61/275, epoch 145/301 --> loss:0.04980725646018982
step 71/275, epoch 145/301 --> loss:0.06486772894859313
step 81/275, epoch 145/301 --> loss:0.04781801104545593
step 91/275, epoch 145/301 --> loss:0.04884601831436157
step 101/275, epoch 145/301 --> loss:0.04392138719558716
step 111/275, epoch 145/301 --> loss:0.04790805578231812
step 121/275, epoch 145/301 --> loss:0.04835105538368225
step 131/275, epoch 145/301 --> loss:0.04877957105636597
step 141/275, epoch 145/301 --> loss:0.04727432131767273
step 151/275, epoch 145/301 --> loss:0.049280977249145506
step 161/275, epoch 145/301 --> loss:0.037144696712493895
step 171/275, epoch 145/301 --> loss:0.04974740743637085
step 181/275, epoch 145/301 --> loss:0.0651547908782959
step 191/275, epoch 145/301 --> loss:0.05163072943687439
step 201/275, epoch 145/301 --> loss:0.04436900019645691
step 211/275, epoch 145/301 --> loss:0.052835899591445926
step 221/275, epoch 145/301 --> loss:0.06369944810867309
step 231/275, epoch 145/301 --> loss:0.05135194659233093
step 241/275, epoch 145/301 --> loss:0.05373870134353638
step 251/275, epoch 145/301 --> loss:0.04609858989715576
step 261/275, epoch 145/301 --> loss:0.04475889205932617
step 271/275, epoch 145/301 --> loss:0.044918912649154666
 49%|████▊     | 146/301 [13:56:44<14:16:36, 331.59s/it]step 11/275, epoch 146/301 --> loss:0.0514947772026062
step 21/275, epoch 146/301 --> loss:0.05934260487556457
step 31/275, epoch 146/301 --> loss:0.046009558439254764
step 41/275, epoch 146/301 --> loss:0.04708846211433411
step 51/275, epoch 146/301 --> loss:0.050625556707382204
step 61/275, epoch 146/301 --> loss:0.05121367573738098
step 71/275, epoch 146/301 --> loss:0.04435290098190307
step 81/275, epoch 146/301 --> loss:0.04379146695137024
step 91/275, epoch 146/301 --> loss:0.0582757830619812
step 101/275, epoch 146/301 --> loss:0.049130779504776
step 111/275, epoch 146/301 --> loss:0.046218520402908324
step 121/275, epoch 146/301 --> loss:0.05585950016975403
step 131/275, epoch 146/301 --> loss:0.050967222452163695
step 141/275, epoch 146/301 --> loss:0.05101056098937988
step 151/275, epoch 146/301 --> loss:0.06446895599365235
step 161/275, epoch 146/301 --> loss:0.047082924842834474
step 171/275, epoch 146/301 --> loss:0.04299370050430298
step 181/275, epoch 146/301 --> loss:0.04116210341453552
step 191/275, epoch 146/301 --> loss:0.059208840131759644
step 201/275, epoch 146/301 --> loss:0.049431270360946654
step 211/275, epoch 146/301 --> loss:0.050638478994369504
step 221/275, epoch 146/301 --> loss:0.05467360615730286
step 231/275, epoch 146/301 --> loss:0.04082629084587097
step 241/275, epoch 146/301 --> loss:0.05223374962806702
step 251/275, epoch 146/301 --> loss:0.05012519359588623
step 261/275, epoch 146/301 --> loss:0.04958081841468811
step 271/275, epoch 146/301 --> loss:0.05462614893913269
 49%|████▉     | 147/301 [14:02:05<14:02:39, 328.31s/it]step 11/275, epoch 147/301 --> loss:0.04785064458847046
step 21/275, epoch 147/301 --> loss:0.06306793689727783
step 31/275, epoch 147/301 --> loss:0.05382397174835205
step 41/275, epoch 147/301 --> loss:0.04595822095870972
step 51/275, epoch 147/301 --> loss:0.041572707891464236
step 61/275, epoch 147/301 --> loss:0.05334547758102417
step 71/275, epoch 147/301 --> loss:0.051186656951904295
step 81/275, epoch 147/301 --> loss:0.04125505089759827
step 91/275, epoch 147/301 --> loss:0.05134033560752869
step 101/275, epoch 147/301 --> loss:0.06366038918495179
step 111/275, epoch 147/301 --> loss:0.04800378680229187
step 121/275, epoch 147/301 --> loss:0.05307993292808533
step 131/275, epoch 147/301 --> loss:0.04738340973854065
step 141/275, epoch 147/301 --> loss:0.05593143701553345
step 151/275, epoch 147/301 --> loss:0.05584471225738526
step 161/275, epoch 147/301 --> loss:0.046663838624954226
step 171/275, epoch 147/301 --> loss:0.05415897369384766
step 181/275, epoch 147/301 --> loss:0.04366835355758667
step 191/275, epoch 147/301 --> loss:0.05231813788414001
step 201/275, epoch 147/301 --> loss:0.06376265287399292
step 211/275, epoch 147/301 --> loss:0.062492990493774415
step 221/275, epoch 147/301 --> loss:0.05442425608634949
step 231/275, epoch 147/301 --> loss:0.05222856402397156
step 241/275, epoch 147/301 --> loss:0.055505400896072386
step 251/275, epoch 147/301 --> loss:0.05692536830902099
step 261/275, epoch 147/301 --> loss:0.05231400728225708
step 271/275, epoch 147/301 --> loss:0.04886054992675781
 49%|████▉     | 148/301 [14:07:24<13:50:24, 325.65s/it]step 11/275, epoch 148/301 --> loss:0.05849343538284302
step 21/275, epoch 148/301 --> loss:0.054391896724700926
step 31/275, epoch 148/301 --> loss:0.047693169116973876
step 41/275, epoch 148/301 --> loss:0.05525478720664978
step 51/275, epoch 148/301 --> loss:0.046367430686950685
step 61/275, epoch 148/301 --> loss:0.050804704427719116
step 71/275, epoch 148/301 --> loss:0.05197228789329529
step 81/275, epoch 148/301 --> loss:0.056568878889083865
step 91/275, epoch 148/301 --> loss:0.056778454780578615
step 101/275, epoch 148/301 --> loss:0.0466995120048523
step 111/275, epoch 148/301 --> loss:0.04364533424377441
step 121/275, epoch 148/301 --> loss:0.0521357536315918
step 131/275, epoch 148/301 --> loss:0.05426449179649353
step 141/275, epoch 148/301 --> loss:0.04912962317466736
step 151/275, epoch 148/301 --> loss:0.05351945757865906
step 161/275, epoch 148/301 --> loss:0.03960020542144775
step 171/275, epoch 148/301 --> loss:0.05247893333435059
step 181/275, epoch 148/301 --> loss:0.051267576217651364
step 191/275, epoch 148/301 --> loss:0.050620973110198975
step 201/275, epoch 148/301 --> loss:0.05010795593261719
step 211/275, epoch 148/301 --> loss:0.055780059099197386
step 221/275, epoch 148/301 --> loss:0.05068885684013367
step 231/275, epoch 148/301 --> loss:0.050979483127594
step 241/275, epoch 148/301 --> loss:0.04527195692062378
step 251/275, epoch 148/301 --> loss:0.04048752188682556
step 261/275, epoch 148/301 --> loss:0.0508638858795166
step 271/275, epoch 148/301 --> loss:0.0492595911026001
 50%|████▉     | 149/301 [14:12:42<13:39:18, 323.41s/it]step 11/275, epoch 149/301 --> loss:0.043766355514526366
step 21/275, epoch 149/301 --> loss:0.05912138223648071
step 31/275, epoch 149/301 --> loss:0.0573908269405365
step 41/275, epoch 149/301 --> loss:0.04773595929145813
step 51/275, epoch 149/301 --> loss:0.05166916251182556
step 61/275, epoch 149/301 --> loss:0.04576572179794312
step 71/275, epoch 149/301 --> loss:0.04198117852210999
step 81/275, epoch 149/301 --> loss:0.045975005626678465
step 91/275, epoch 149/301 --> loss:0.05587615966796875
step 101/275, epoch 149/301 --> loss:0.04439742565155029
step 111/275, epoch 149/301 --> loss:0.05154461860656738
step 121/275, epoch 149/301 --> loss:0.04367479681968689
step 131/275, epoch 149/301 --> loss:0.05537405014038086
step 141/275, epoch 149/301 --> loss:0.06127780079841614
step 151/275, epoch 149/301 --> loss:0.05377026200294495
step 161/275, epoch 149/301 --> loss:0.061774414777755735
step 171/275, epoch 149/301 --> loss:0.057119184732437135
step 181/275, epoch 149/301 --> loss:0.04391421675682068
step 191/275, epoch 149/301 --> loss:0.0430202305316925
step 201/275, epoch 149/301 --> loss:0.043664997816085814
step 211/275, epoch 149/301 --> loss:0.056227964162826535
step 221/275, epoch 149/301 --> loss:0.04605414867401123
step 231/275, epoch 149/301 --> loss:0.046819287538528445
step 241/275, epoch 149/301 --> loss:0.050910931825637815
step 251/275, epoch 149/301 --> loss:0.04635024070739746
step 261/275, epoch 149/301 --> loss:0.04203483462333679
step 271/275, epoch 149/301 --> loss:0.05286630392074585
 50%|████▉     | 150/301 [14:17:58<13:28:18, 321.18s/it]step 11/275, epoch 150/301 --> loss:0.047045457363128665
step 21/275, epoch 150/301 --> loss:0.0664473295211792
step 31/275, epoch 150/301 --> loss:0.047052001953125
step 41/275, epoch 150/301 --> loss:0.04535266160964966
step 51/275, epoch 150/301 --> loss:0.04934933185577393
step 61/275, epoch 150/301 --> loss:0.05021966695785522
step 71/275, epoch 150/301 --> loss:0.042733341455459595
step 81/275, epoch 150/301 --> loss:0.053161853551864625
step 91/275, epoch 150/301 --> loss:0.055547916889190675
step 101/275, epoch 150/301 --> loss:0.05488930940628052
step 111/275, epoch 150/301 --> loss:0.04367278814315796
step 121/275, epoch 150/301 --> loss:0.03793535232543945
step 131/275, epoch 150/301 --> loss:0.052770334482192996
step 141/275, epoch 150/301 --> loss:0.05161586403846741
step 151/275, epoch 150/301 --> loss:0.04952332377433777
step 161/275, epoch 150/301 --> loss:0.04568553566932678
step 171/275, epoch 150/301 --> loss:0.05247390866279602
step 181/275, epoch 150/301 --> loss:0.049724352359771726
step 191/275, epoch 150/301 --> loss:0.06571879386901855
step 201/275, epoch 150/301 --> loss:0.045029217004776
step 211/275, epoch 150/301 --> loss:0.058693206310272215
step 221/275, epoch 150/301 --> loss:0.04496309757232666
step 231/275, epoch 150/301 --> loss:0.041037970781326295
step 241/275, epoch 150/301 --> loss:0.04465208649635315
step 251/275, epoch 150/301 --> loss:0.05037746429443359
step 261/275, epoch 150/301 --> loss:0.05171485543251038
step 271/275, epoch 150/301 --> loss:0.050700992345809937
step 11/275, epoch 151/301 --> loss:0.04147442579269409
step 21/275, epoch 151/301 --> loss:0.040080302953720094
step 31/275, epoch 151/301 --> loss:0.056033778190612796
step 41/275, epoch 151/301 --> loss:0.04654853940010071
step 51/275, epoch 151/301 --> loss:0.051807069778442384
step 61/275, epoch 151/301 --> loss:0.04676159024238587
step 71/275, epoch 151/301 --> loss:0.04109569787979126
step 81/275, epoch 151/301 --> loss:0.039403748512268064
step 91/275, epoch 151/301 --> loss:0.04039953947067261
step 101/275, epoch 151/301 --> loss:0.05175536274909973
step 111/275, epoch 151/301 --> loss:0.051304155588150026
step 121/275, epoch 151/301 --> loss:0.04613121747970581
step 131/275, epoch 151/301 --> loss:0.046344596147537234
step 141/275, epoch 151/301 --> loss:0.039145815372467044
step 151/275, epoch 151/301 --> loss:0.05850985646247864
step 161/275, epoch 151/301 --> loss:0.05313376784324646
step 171/275, epoch 151/301 --> loss:0.05248234868049621
step 181/275, epoch 151/301 --> loss:0.04742240309715271
step 191/275, epoch 151/301 --> loss:0.058853906393051145
step 201/275, epoch 151/301 --> loss:0.05461498498916626
step 211/275, epoch 151/301 --> loss:0.05277816653251648
step 221/275, epoch 151/301 --> loss:0.0505234956741333
step 231/275, epoch 151/301 --> loss:0.04254025816917419
step 241/275, epoch 151/301 --> loss:0.04326989054679871
step 251/275, epoch 151/301 --> loss:0.05634313225746155
step 261/275, epoch 151/301 --> loss:0.04417427778244019
step 271/275, epoch 151/301 --> loss:0.05221959948539734
########## train dataset ##########
PLout index:  2
acc -->  [96.40427905855356]
F1 -->  {'F1': [0.9560812203524122], 'precision': [0.965458731142453], 'recall': [0.9468939325161986]}
########## eval dataset ##########
 50%|█████     | 151/301 [14:27:08<16:14:33, 389.82s/it]PLout index:  2
acc -->  [93.3181003611558]
F1 -->  {'F1': [0.9199013394642399], 'precision': [0.9316362528518957], 'recall': [0.9084681264125831]}
save model!
 50%|█████     | 152/301 [14:32:26<15:14:26, 368.23s/it]step 11/275, epoch 152/301 --> loss:0.04425933361053467
step 21/275, epoch 152/301 --> loss:0.03693984746932984
step 31/275, epoch 152/301 --> loss:0.04706195592880249
step 41/275, epoch 152/301 --> loss:0.04338030815124512
step 51/275, epoch 152/301 --> loss:0.04423618912696838
step 61/275, epoch 152/301 --> loss:0.05802085995674133
step 71/275, epoch 152/301 --> loss:0.05218416452407837
step 81/275, epoch 152/301 --> loss:0.044822484254837036
step 91/275, epoch 152/301 --> loss:0.04548366069793701
step 101/275, epoch 152/301 --> loss:0.04971083998680115
step 111/275, epoch 152/301 --> loss:0.04267206788063049
step 121/275, epoch 152/301 --> loss:0.04793949723243714
step 131/275, epoch 152/301 --> loss:0.06007506847381592
step 141/275, epoch 152/301 --> loss:0.04925015568733215
step 151/275, epoch 152/301 --> loss:0.05723726749420166
step 161/275, epoch 152/301 --> loss:0.06740864515304565
step 171/275, epoch 152/301 --> loss:0.06003226637840271
step 181/275, epoch 152/301 --> loss:0.05052096843719482
step 191/275, epoch 152/301 --> loss:0.03884899616241455
step 201/275, epoch 152/301 --> loss:0.04565632343292236
step 211/275, epoch 152/301 --> loss:0.04867668747901917
step 221/275, epoch 152/301 --> loss:0.0468048095703125
step 231/275, epoch 152/301 --> loss:0.05786412954330444
step 241/275, epoch 152/301 --> loss:0.04366255402565002
step 251/275, epoch 152/301 --> loss:0.05682132840156555
step 261/275, epoch 152/301 --> loss:0.052781695127487184
step 271/275, epoch 152/301 --> loss:0.06101388335227966
 51%|█████     | 153/301 [14:37:46<14:32:13, 353.61s/it]step 11/275, epoch 153/301 --> loss:0.053081589937210086
step 21/275, epoch 153/301 --> loss:0.05606322288513184
step 31/275, epoch 153/301 --> loss:0.050007814168930055
step 41/275, epoch 153/301 --> loss:0.04559139609336853
step 51/275, epoch 153/301 --> loss:0.053358787298202516
step 61/275, epoch 153/301 --> loss:0.04780173301696777
step 71/275, epoch 153/301 --> loss:0.045253074169158934
step 81/275, epoch 153/301 --> loss:0.047544682025909425
step 91/275, epoch 153/301 --> loss:0.052100342512130735
step 101/275, epoch 153/301 --> loss:0.056571006774902344
step 111/275, epoch 153/301 --> loss:0.04737535119056702
step 121/275, epoch 153/301 --> loss:0.04782977104187012
step 131/275, epoch 153/301 --> loss:0.04390217661857605
step 141/275, epoch 153/301 --> loss:0.051023072004318236
step 151/275, epoch 153/301 --> loss:0.046003586053848265
step 161/275, epoch 153/301 --> loss:0.047179621458053586
step 171/275, epoch 153/301 --> loss:0.046928369998931886
step 181/275, epoch 153/301 --> loss:0.05466310977935791
step 191/275, epoch 153/301 --> loss:0.04190713167190552
step 201/275, epoch 153/301 --> loss:0.039574503898620605
step 211/275, epoch 153/301 --> loss:0.05463688969612122
step 221/275, epoch 153/301 --> loss:0.05058523416519165
step 231/275, epoch 153/301 --> loss:0.0498785138130188
step 241/275, epoch 153/301 --> loss:0.05890215039253235
step 251/275, epoch 153/301 --> loss:0.05305451154708862
step 261/275, epoch 153/301 --> loss:0.043949353694915774
step 271/275, epoch 153/301 --> loss:0.04362037777900696
 51%|█████     | 154/301 [14:43:05<14:01:03, 343.29s/it]step 11/275, epoch 154/301 --> loss:0.061844360828399655
step 21/275, epoch 154/301 --> loss:0.05195074677467346
step 31/275, epoch 154/301 --> loss:0.050140762329101564
step 41/275, epoch 154/301 --> loss:0.05403107404708862
step 51/275, epoch 154/301 --> loss:0.05258857011795044
step 61/275, epoch 154/301 --> loss:0.049355310201644895
step 71/275, epoch 154/301 --> loss:0.041620266437530515
step 81/275, epoch 154/301 --> loss:0.047133404016494754
step 91/275, epoch 154/301 --> loss:0.041382229328155516
step 101/275, epoch 154/301 --> loss:0.04503131508827209
step 111/275, epoch 154/301 --> loss:0.05146970748901367
step 121/275, epoch 154/301 --> loss:0.0526238203048706
step 131/275, epoch 154/301 --> loss:0.047801780700683597
step 141/275, epoch 154/301 --> loss:0.050454729795455934
step 151/275, epoch 154/301 --> loss:0.041945791244506835
step 161/275, epoch 154/301 --> loss:0.04198681116104126
step 171/275, epoch 154/301 --> loss:0.04894946217536926
step 181/275, epoch 154/301 --> loss:0.046686196327209474
step 191/275, epoch 154/301 --> loss:0.0594499945640564
step 201/275, epoch 154/301 --> loss:0.041984552145004274
step 211/275, epoch 154/301 --> loss:0.04485970735549927
step 221/275, epoch 154/301 --> loss:0.04376270174980164
step 231/275, epoch 154/301 --> loss:0.04460814595222473
step 241/275, epoch 154/301 --> loss:0.04110645055770874
step 251/275, epoch 154/301 --> loss:0.050931143760681155
step 261/275, epoch 154/301 --> loss:0.05029820203781128
step 271/275, epoch 154/301 --> loss:0.049052256345748904
 51%|█████▏    | 155/301 [14:48:24<13:37:49, 336.10s/it]step 11/275, epoch 155/301 --> loss:0.0450306236743927
step 21/275, epoch 155/301 --> loss:0.08825319409370422
step 31/275, epoch 155/301 --> loss:0.05764206051826477
step 41/275, epoch 155/301 --> loss:0.05490629673004151
step 51/275, epoch 155/301 --> loss:0.05043565630912781
step 61/275, epoch 155/301 --> loss:0.05104809403419495
step 71/275, epoch 155/301 --> loss:0.0521693229675293
step 81/275, epoch 155/301 --> loss:0.04204649925231933
step 91/275, epoch 155/301 --> loss:0.0528728187084198
step 101/275, epoch 155/301 --> loss:0.04430781006813049
step 111/275, epoch 155/301 --> loss:0.049078619480133055
step 121/275, epoch 155/301 --> loss:0.04564145803451538
step 131/275, epoch 155/301 --> loss:0.05203309655189514
step 141/275, epoch 155/301 --> loss:0.0467934787273407
step 151/275, epoch 155/301 --> loss:0.05181456208229065
step 161/275, epoch 155/301 --> loss:0.04148264527320862
step 171/275, epoch 155/301 --> loss:0.040892720222473145
step 181/275, epoch 155/301 --> loss:0.05166278481483459
step 191/275, epoch 155/301 --> loss:0.05068436861038208
step 201/275, epoch 155/301 --> loss:0.04854118227958679
step 211/275, epoch 155/301 --> loss:0.052633154392242434
step 221/275, epoch 155/301 --> loss:0.04291402101516724
step 231/275, epoch 155/301 --> loss:0.04609220623970032
step 241/275, epoch 155/301 --> loss:0.046654945611953734
step 251/275, epoch 155/301 --> loss:0.047398579120635984
step 261/275, epoch 155/301 --> loss:0.05412831902503967
step 271/275, epoch 155/301 --> loss:0.04519686698913574
 52%|█████▏    | 156/301 [14:53:44<13:20:21, 331.18s/it]step 11/275, epoch 156/301 --> loss:0.04471173882484436
step 21/275, epoch 156/301 --> loss:0.04373067021369934
step 31/275, epoch 156/301 --> loss:0.04479590058326721
step 41/275, epoch 156/301 --> loss:0.06092386841773987
step 51/275, epoch 156/301 --> loss:0.05121514797210693
step 61/275, epoch 156/301 --> loss:0.05005528330802918
step 71/275, epoch 156/301 --> loss:0.051596051454544066
step 81/275, epoch 156/301 --> loss:0.04967365264892578
step 91/275, epoch 156/301 --> loss:0.05838832855224609
step 101/275, epoch 156/301 --> loss:0.04492808580398559
step 111/275, epoch 156/301 --> loss:0.052584922313690184
step 121/275, epoch 156/301 --> loss:0.04736543297767639
step 131/275, epoch 156/301 --> loss:0.042773890495300296
step 141/275, epoch 156/301 --> loss:0.047059285640716556
step 151/275, epoch 156/301 --> loss:0.04756053686141968
step 161/275, epoch 156/301 --> loss:0.046318864822387694
step 171/275, epoch 156/301 --> loss:0.044700294733047485
step 181/275, epoch 156/301 --> loss:0.04352002739906311
step 191/275, epoch 156/301 --> loss:0.05661830902099609
step 201/275, epoch 156/301 --> loss:0.050743472576141355
step 211/275, epoch 156/301 --> loss:0.0467242181301117
step 221/275, epoch 156/301 --> loss:0.05514184236526489
step 231/275, epoch 156/301 --> loss:0.04314724206924438
step 241/275, epoch 156/301 --> loss:0.05202984213829041
step 251/275, epoch 156/301 --> loss:0.04500705599784851
step 261/275, epoch 156/301 --> loss:0.05111763477325439
step 271/275, epoch 156/301 --> loss:0.04145374298095703
 52%|█████▏    | 157/301 [14:59:03<13:06:26, 327.68s/it]step 11/275, epoch 157/301 --> loss:0.051435232162475586
step 21/275, epoch 157/301 --> loss:0.0514754056930542
step 31/275, epoch 157/301 --> loss:0.05497245192527771
step 41/275, epoch 157/301 --> loss:0.04620107412338257
step 51/275, epoch 157/301 --> loss:0.04903849959373474
step 61/275, epoch 157/301 --> loss:0.0465448796749115
step 71/275, epoch 157/301 --> loss:0.03820664286613464
step 81/275, epoch 157/301 --> loss:0.047147136926651
step 91/275, epoch 157/301 --> loss:0.03975222110748291
step 101/275, epoch 157/301 --> loss:0.04558447003364563
step 111/275, epoch 157/301 --> loss:0.03825764656066895
step 121/275, epoch 157/301 --> loss:0.04236853718757629
step 131/275, epoch 157/301 --> loss:0.04295342564582825
step 141/275, epoch 157/301 --> loss:0.03863139152526855
step 151/275, epoch 157/301 --> loss:0.05290229916572571
step 161/275, epoch 157/301 --> loss:0.04200149774551391
step 171/275, epoch 157/301 --> loss:0.041962385177612305
step 181/275, epoch 157/301 --> loss:0.04834601879119873
step 191/275, epoch 157/301 --> loss:0.04727473258972168
step 201/275, epoch 157/301 --> loss:0.04773927330970764
step 211/275, epoch 157/301 --> loss:0.059300696849823
step 221/275, epoch 157/301 --> loss:0.042842262983322145
step 231/275, epoch 157/301 --> loss:0.046976286172866824
step 241/275, epoch 157/301 --> loss:0.0479036808013916
step 251/275, epoch 157/301 --> loss:0.054389989376068114
step 261/275, epoch 157/301 --> loss:0.05390973091125488
step 271/275, epoch 157/301 --> loss:0.05585786700248718
 52%|█████▏    | 158/301 [15:04:23<12:55:22, 325.33s/it]step 11/275, epoch 158/301 --> loss:0.06288977861404418
step 21/275, epoch 158/301 --> loss:0.05644664168357849
step 31/275, epoch 158/301 --> loss:0.0457073450088501
step 41/275, epoch 158/301 --> loss:0.047836631536483765
step 51/275, epoch 158/301 --> loss:0.05066177248954773
step 61/275, epoch 158/301 --> loss:0.05161214470863342
step 71/275, epoch 158/301 --> loss:0.05215516686439514
step 81/275, epoch 158/301 --> loss:0.05238356590270996
step 91/275, epoch 158/301 --> loss:0.04673665761947632
step 101/275, epoch 158/301 --> loss:0.03917418122291565
step 111/275, epoch 158/301 --> loss:0.04816311001777649
step 121/275, epoch 158/301 --> loss:0.037151336669921875
step 131/275, epoch 158/301 --> loss:0.05027701854705811
step 141/275, epoch 158/301 --> loss:0.05864794254302978
step 151/275, epoch 158/301 --> loss:0.041343575716018675
step 161/275, epoch 158/301 --> loss:0.043483561277389525
step 171/275, epoch 158/301 --> loss:0.03959906697273254
step 181/275, epoch 158/301 --> loss:0.04106485843658447
step 191/275, epoch 158/301 --> loss:0.04816777110099792
step 201/275, epoch 158/301 --> loss:0.04721960425376892
step 211/275, epoch 158/301 --> loss:0.03848007321357727
step 221/275, epoch 158/301 --> loss:0.042367595434188846
step 231/275, epoch 158/301 --> loss:0.04470735192298889
step 241/275, epoch 158/301 --> loss:0.04779667854309082
step 251/275, epoch 158/301 --> loss:0.05347938537597656
step 261/275, epoch 158/301 --> loss:0.05191590189933777
step 271/275, epoch 158/301 --> loss:0.050243300199508664
 53%|█████▎    | 159/301 [15:09:43<12:46:14, 323.77s/it]step 11/275, epoch 159/301 --> loss:0.042367756366729736
step 21/275, epoch 159/301 --> loss:0.04699831008911133
step 31/275, epoch 159/301 --> loss:0.04541530013084412
step 41/275, epoch 159/301 --> loss:0.03795519471168518
step 51/275, epoch 159/301 --> loss:0.04548879861831665
step 61/275, epoch 159/301 --> loss:0.040720421075820926
step 71/275, epoch 159/301 --> loss:0.053217756748199466
step 81/275, epoch 159/301 --> loss:0.0418984055519104
step 91/275, epoch 159/301 --> loss:0.038686889410018924
step 101/275, epoch 159/301 --> loss:0.0528705894947052
step 111/275, epoch 159/301 --> loss:0.04047870635986328
step 121/275, epoch 159/301 --> loss:0.05124009847640991
step 131/275, epoch 159/301 --> loss:0.04857282638549805
step 141/275, epoch 159/301 --> loss:0.05526929497718811
step 151/275, epoch 159/301 --> loss:0.04933516383171081
step 161/275, epoch 159/301 --> loss:0.043105751276016235
step 171/275, epoch 159/301 --> loss:0.04687482714653015
step 181/275, epoch 159/301 --> loss:0.05271689891815186
step 191/275, epoch 159/301 --> loss:0.049702250957489015
step 201/275, epoch 159/301 --> loss:0.045908427238464354
step 211/275, epoch 159/301 --> loss:0.04339817762374878
step 221/275, epoch 159/301 --> loss:0.0412995457649231
step 231/275, epoch 159/301 --> loss:0.04423519968986511
step 241/275, epoch 159/301 --> loss:0.051544153690338136
step 251/275, epoch 159/301 --> loss:0.04535096287727356
step 261/275, epoch 159/301 --> loss:0.05296511650085449
step 271/275, epoch 159/301 --> loss:0.043346983194351194
 53%|█████▎    | 160/301 [15:15:03<12:38:18, 322.68s/it]step 11/275, epoch 160/301 --> loss:0.049388939142227174
step 21/275, epoch 160/301 --> loss:0.049312472343444824
step 31/275, epoch 160/301 --> loss:0.04293113350868225
step 41/275, epoch 160/301 --> loss:0.04531927108764648
step 51/275, epoch 160/301 --> loss:0.041558146476745605
step 61/275, epoch 160/301 --> loss:0.04658344984054565
step 71/275, epoch 160/301 --> loss:0.049215441942214964
step 81/275, epoch 160/301 --> loss:0.046481764316558837
step 91/275, epoch 160/301 --> loss:0.043698519468307495
step 101/275, epoch 160/301 --> loss:0.05776829123497009
step 111/275, epoch 160/301 --> loss:0.04436442255973816
step 121/275, epoch 160/301 --> loss:0.04430866837501526
step 131/275, epoch 160/301 --> loss:0.05486551523208618
step 141/275, epoch 160/301 --> loss:0.043706828355789186
step 151/275, epoch 160/301 --> loss:0.04122043251991272
step 161/275, epoch 160/301 --> loss:0.042405086755752566
step 171/275, epoch 160/301 --> loss:0.05306645035743714
step 181/275, epoch 160/301 --> loss:0.05462527275085449
step 191/275, epoch 160/301 --> loss:0.04805907607078552
step 201/275, epoch 160/301 --> loss:0.05173905491828919
step 211/275, epoch 160/301 --> loss:0.05210197567939758
step 221/275, epoch 160/301 --> loss:0.04428229928016662
step 231/275, epoch 160/301 --> loss:0.044590145349502563
step 241/275, epoch 160/301 --> loss:0.04781448245048523
step 251/275, epoch 160/301 --> loss:0.03440456986427307
step 261/275, epoch 160/301 --> loss:0.048322224617004396
step 271/275, epoch 160/301 --> loss:0.047850924730300906
step 11/275, epoch 161/301 --> loss:0.05603875517845154
step 21/275, epoch 161/301 --> loss:0.04689173698425293
step 31/275, epoch 161/301 --> loss:0.04626206755638122
step 41/275, epoch 161/301 --> loss:0.042455488443374635
step 51/275, epoch 161/301 --> loss:0.04947817325592041
step 61/275, epoch 161/301 --> loss:0.05579456090927124
step 71/275, epoch 161/301 --> loss:0.050557959079742434
step 81/275, epoch 161/301 --> loss:0.04028801321983337
step 91/275, epoch 161/301 --> loss:0.03675885200500488
step 101/275, epoch 161/301 --> loss:0.04057961702346802
step 111/275, epoch 161/301 --> loss:0.047197699546813965
step 121/275, epoch 161/301 --> loss:0.042550861835479736
step 131/275, epoch 161/301 --> loss:0.04535524845123291
step 141/275, epoch 161/301 --> loss:0.04491541981697082
step 151/275, epoch 161/301 --> loss:0.044794869422912595
step 161/275, epoch 161/301 --> loss:0.03378592729568482
step 171/275, epoch 161/301 --> loss:0.039993679523468016
step 181/275, epoch 161/301 --> loss:0.047332513332366946
step 191/275, epoch 161/301 --> loss:0.0385341227054596
step 201/275, epoch 161/301 --> loss:0.049854332208633424
step 211/275, epoch 161/301 --> loss:0.05186644196510315
step 221/275, epoch 161/301 --> loss:0.054495060443878175
step 231/275, epoch 161/301 --> loss:0.05793570876121521
step 241/275, epoch 161/301 --> loss:0.04738978147506714
step 251/275, epoch 161/301 --> loss:0.054908263683319095
step 261/275, epoch 161/301 --> loss:0.05248522758483887
step 271/275, epoch 161/301 --> loss:0.04092018604278565
########## train dataset ##########
PLout index:  2
acc -->  [96.7252112358981]
F1 -->  {'F1': [0.9600466073925786], 'precision': [0.9683296324109846], 'recall': [0.951913915745206]}
########## eval dataset ##########
 53%|█████▎    | 161/301 [15:24:20<15:16:34, 392.82s/it]PLout index:  2
acc -->  [93.38988770694253]
F1 -->  {'F1': [0.9207404260478083], 'precision': [0.9327444354165286], 'recall': [0.9090512093498256]}
save model!
 54%|█████▍    | 162/301 [15:29:37<14:17:30, 370.15s/it]step 11/275, epoch 162/301 --> loss:0.04602643847465515
step 21/275, epoch 162/301 --> loss:0.051859110593795776
step 31/275, epoch 162/301 --> loss:0.040162861347198486
step 41/275, epoch 162/301 --> loss:0.046141552925109866
step 51/275, epoch 162/301 --> loss:0.04897629022598267
step 61/275, epoch 162/301 --> loss:0.04065613746643067
step 71/275, epoch 162/301 --> loss:0.057076603174209595
step 81/275, epoch 162/301 --> loss:0.04803934693336487
step 91/275, epoch 162/301 --> loss:0.045273596048355104
step 101/275, epoch 162/301 --> loss:0.038092541694641116
step 111/275, epoch 162/301 --> loss:0.05822792649269104
step 121/275, epoch 162/301 --> loss:0.04252302050590515
step 131/275, epoch 162/301 --> loss:0.037253671884536745
step 141/275, epoch 162/301 --> loss:0.03749226927757263
step 151/275, epoch 162/301 --> loss:0.046752190589904784
step 161/275, epoch 162/301 --> loss:0.04712573289871216
step 171/275, epoch 162/301 --> loss:0.04348436594009399
step 181/275, epoch 162/301 --> loss:0.04452608227729797
step 191/275, epoch 162/301 --> loss:0.05057646632194519
step 201/275, epoch 162/301 --> loss:0.04958644509315491
step 211/275, epoch 162/301 --> loss:0.055699360370635984
step 221/275, epoch 162/301 --> loss:0.06723815202713013
step 231/275, epoch 162/301 --> loss:0.05022807121276855
step 241/275, epoch 162/301 --> loss:0.04483464956283569
step 251/275, epoch 162/301 --> loss:0.05617321133613586
step 261/275, epoch 162/301 --> loss:0.045644712448120114
step 271/275, epoch 162/301 --> loss:0.055654847621917726
 54%|█████▍    | 163/301 [15:34:54<13:34:34, 354.16s/it]step 11/275, epoch 163/301 --> loss:0.05680014491081238
step 21/275, epoch 163/301 --> loss:0.04815586805343628
step 31/275, epoch 163/301 --> loss:0.0584105134010315
step 41/275, epoch 163/301 --> loss:0.05487490892410278
step 51/275, epoch 163/301 --> loss:0.042964011430740356
step 61/275, epoch 163/301 --> loss:0.04870451688766479
step 71/275, epoch 163/301 --> loss:0.05223073959350586
step 81/275, epoch 163/301 --> loss:0.03829842209815979
step 91/275, epoch 163/301 --> loss:0.04164324402809143
step 101/275, epoch 163/301 --> loss:0.04513310194015503
step 111/275, epoch 163/301 --> loss:0.04934634566307068
step 121/275, epoch 163/301 --> loss:0.04282420873641968
step 131/275, epoch 163/301 --> loss:0.05062543153762818
step 141/275, epoch 163/301 --> loss:0.050169438123703
step 151/275, epoch 163/301 --> loss:0.04136759042739868
step 161/275, epoch 163/301 --> loss:0.053102236986160276
step 171/275, epoch 163/301 --> loss:0.051103216409683225
step 181/275, epoch 163/301 --> loss:0.04549994468688965
step 191/275, epoch 163/301 --> loss:0.04324095845222473
step 201/275, epoch 163/301 --> loss:0.044548964500427245
step 211/275, epoch 163/301 --> loss:0.047434943914413455
step 221/275, epoch 163/301 --> loss:0.034411394596099855
step 231/275, epoch 163/301 --> loss:0.04276612401008606
step 241/275, epoch 163/301 --> loss:0.04433930516242981
step 251/275, epoch 163/301 --> loss:0.04493241310119629
step 261/275, epoch 163/301 --> loss:0.04426700472831726
step 271/275, epoch 163/301 --> loss:0.05090362429618835
 54%|█████▍    | 164/301 [15:40:12<13:03:46, 343.26s/it]step 11/275, epoch 164/301 --> loss:0.046100187301635745
step 21/275, epoch 164/301 --> loss:0.0507455050945282
step 31/275, epoch 164/301 --> loss:0.041582679748535155
step 41/275, epoch 164/301 --> loss:0.050826925039291385
step 51/275, epoch 164/301 --> loss:0.03564870357513428
step 61/275, epoch 164/301 --> loss:0.04169780611991882
step 71/275, epoch 164/301 --> loss:0.04828370213508606
step 81/275, epoch 164/301 --> loss:0.03697739839553833
step 91/275, epoch 164/301 --> loss:0.047749674320220946
step 101/275, epoch 164/301 --> loss:0.039880412817001346
step 111/275, epoch 164/301 --> loss:0.03817792534828186
step 121/275, epoch 164/301 --> loss:0.047556787729263306
step 131/275, epoch 164/301 --> loss:0.06283115148544312
step 141/275, epoch 164/301 --> loss:0.05645219087600708
step 151/275, epoch 164/301 --> loss:0.05131399631500244
step 161/275, epoch 164/301 --> loss:0.05792128443717957
step 171/275, epoch 164/301 --> loss:0.04309759736061096
step 181/275, epoch 164/301 --> loss:0.05893195867538452
step 191/275, epoch 164/301 --> loss:0.052095049619674684
step 201/275, epoch 164/301 --> loss:0.054848724603652955
step 211/275, epoch 164/301 --> loss:0.04652354121208191
step 221/275, epoch 164/301 --> loss:0.05262625217437744
step 231/275, epoch 164/301 --> loss:0.050652050971984865
step 241/275, epoch 164/301 --> loss:0.04580432176589966
step 251/275, epoch 164/301 --> loss:0.03738163709640503
step 261/275, epoch 164/301 --> loss:0.0418376088142395
step 271/275, epoch 164/301 --> loss:0.044806760549545285
 55%|█████▍    | 165/301 [15:45:32<12:42:19, 336.32s/it]step 11/275, epoch 165/301 --> loss:0.05862530469894409
step 21/275, epoch 165/301 --> loss:0.04925363063812256
step 31/275, epoch 165/301 --> loss:0.048443323373794554
step 41/275, epoch 165/301 --> loss:0.047496354579925536
step 51/275, epoch 165/301 --> loss:0.038782501220703126
step 61/275, epoch 165/301 --> loss:0.05181789994239807
step 71/275, epoch 165/301 --> loss:0.04553489685058594
step 81/275, epoch 165/301 --> loss:0.04754531979560852
step 91/275, epoch 165/301 --> loss:0.04589630961418152
step 101/275, epoch 165/301 --> loss:0.04256076216697693
step 111/275, epoch 165/301 --> loss:0.0537497341632843
step 121/275, epoch 165/301 --> loss:0.04633541107177734
step 131/275, epoch 165/301 --> loss:0.04027045369148254
step 141/275, epoch 165/301 --> loss:0.040815716981887816
step 151/275, epoch 165/301 --> loss:0.04307183623313904
step 161/275, epoch 165/301 --> loss:0.04539352059364319
step 171/275, epoch 165/301 --> loss:0.04522671699523926
step 181/275, epoch 165/301 --> loss:0.04056480526924133
step 191/275, epoch 165/301 --> loss:0.04241474270820618
step 201/275, epoch 165/301 --> loss:0.03975390195846558
step 211/275, epoch 165/301 --> loss:0.05529845356941223
step 221/275, epoch 165/301 --> loss:0.04840531945228577
step 231/275, epoch 165/301 --> loss:0.04543185234069824
step 241/275, epoch 165/301 --> loss:0.04728622436523437
step 251/275, epoch 165/301 --> loss:0.0501843512058258
step 261/275, epoch 165/301 --> loss:0.039299362897872926
step 271/275, epoch 165/301 --> loss:0.05020543336868286
 55%|█████▌    | 166/301 [15:50:53<12:26:23, 331.73s/it]step 11/275, epoch 166/301 --> loss:0.07255147695541382
step 21/275, epoch 166/301 --> loss:0.048418056964874265
step 31/275, epoch 166/301 --> loss:0.04243495464324951
step 41/275, epoch 166/301 --> loss:0.04964820146560669
step 51/275, epoch 166/301 --> loss:0.04122495651245117
step 61/275, epoch 166/301 --> loss:0.05648590922355652
step 71/275, epoch 166/301 --> loss:0.045466774702072145
step 81/275, epoch 166/301 --> loss:0.04226908087730408
step 91/275, epoch 166/301 --> loss:0.048310762643814086
step 101/275, epoch 166/301 --> loss:0.04340993165969849
step 111/275, epoch 166/301 --> loss:0.04001008272171021
step 121/275, epoch 166/301 --> loss:0.03921287059783936
step 131/275, epoch 166/301 --> loss:0.05433051586151123
step 141/275, epoch 166/301 --> loss:0.04827763438224793
step 151/275, epoch 166/301 --> loss:0.05245680809020996
step 161/275, epoch 166/301 --> loss:0.04638957381248474
step 171/275, epoch 166/301 --> loss:0.05583399534225464
step 181/275, epoch 166/301 --> loss:0.040334635972976686
step 191/275, epoch 166/301 --> loss:0.04361492395401001
step 201/275, epoch 166/301 --> loss:0.03828516006469727
step 211/275, epoch 166/301 --> loss:0.033584040403366086
step 221/275, epoch 166/301 --> loss:0.0359213650226593
step 231/275, epoch 166/301 --> loss:0.04950445890426636
step 241/275, epoch 166/301 --> loss:0.046632629632949826
step 251/275, epoch 166/301 --> loss:0.04586696028709412
step 261/275, epoch 166/301 --> loss:0.042436283826828
step 271/275, epoch 166/301 --> loss:0.04614662528038025
 55%|█████▌    | 167/301 [15:56:13<12:13:06, 328.25s/it]step 11/275, epoch 167/301 --> loss:0.043416726589202884
step 21/275, epoch 167/301 --> loss:0.05790420174598694
step 31/275, epoch 167/301 --> loss:0.04381178021430969
step 41/275, epoch 167/301 --> loss:0.05080316066741943
step 51/275, epoch 167/301 --> loss:0.04947662353515625
step 61/275, epoch 167/301 --> loss:0.0551224410533905
step 71/275, epoch 167/301 --> loss:0.048665589094161986
step 81/275, epoch 167/301 --> loss:0.05198782682418823
step 91/275, epoch 167/301 --> loss:0.04372443556785584
step 101/275, epoch 167/301 --> loss:0.04331095814704895
step 111/275, epoch 167/301 --> loss:0.03593740463256836
step 121/275, epoch 167/301 --> loss:0.0433501124382019
step 131/275, epoch 167/301 --> loss:0.047403228282928464
step 141/275, epoch 167/301 --> loss:0.043608516454696655
step 151/275, epoch 167/301 --> loss:0.05002126097679138
step 161/275, epoch 167/301 --> loss:0.0446417510509491
step 171/275, epoch 167/301 --> loss:0.038434505462646484
step 181/275, epoch 167/301 --> loss:0.049272215366363524
step 191/275, epoch 167/301 --> loss:0.03999703526496887
step 201/275, epoch 167/301 --> loss:0.03753036856651306
step 211/275, epoch 167/301 --> loss:0.04341648817062378
step 221/275, epoch 167/301 --> loss:0.04048076868057251
step 231/275, epoch 167/301 --> loss:0.0333315372467041
step 241/275, epoch 167/301 --> loss:0.0388145923614502
step 251/275, epoch 167/301 --> loss:0.036941391229629514
step 261/275, epoch 167/301 --> loss:0.04883002042770386
step 271/275, epoch 167/301 --> loss:0.04589734673500061
 56%|█████▌    | 168/301 [16:01:32<12:01:26, 325.47s/it]step 11/275, epoch 168/301 --> loss:0.042445415258407594
step 21/275, epoch 168/301 --> loss:0.04476438164710998
step 31/275, epoch 168/301 --> loss:0.038161826133728025
step 41/275, epoch 168/301 --> loss:0.043469089269638064
step 51/275, epoch 168/301 --> loss:0.03816693425178528
step 61/275, epoch 168/301 --> loss:0.040454357862472534
step 71/275, epoch 168/301 --> loss:0.047633910179138185
step 81/275, epoch 168/301 --> loss:0.04224455952644348
step 91/275, epoch 168/301 --> loss:0.04933454990386963
step 101/275, epoch 168/301 --> loss:0.0383148193359375
step 111/275, epoch 168/301 --> loss:0.047359895706176755
step 121/275, epoch 168/301 --> loss:0.04957734346389771
step 131/275, epoch 168/301 --> loss:0.0437050998210907
step 141/275, epoch 168/301 --> loss:0.05175540447235107
step 151/275, epoch 168/301 --> loss:0.04242099523544311
step 161/275, epoch 168/301 --> loss:0.04491969347000122
step 171/275, epoch 168/301 --> loss:0.03855993747711182
step 181/275, epoch 168/301 --> loss:0.036165112257003786
step 191/275, epoch 168/301 --> loss:0.035695725679397584
step 201/275, epoch 168/301 --> loss:0.04924099445343018
step 211/275, epoch 168/301 --> loss:0.041945672035217284
step 221/275, epoch 168/301 --> loss:0.05182330012321472
step 231/275, epoch 168/301 --> loss:0.05023649334907532
step 241/275, epoch 168/301 --> loss:0.04612019658088684
step 251/275, epoch 168/301 --> loss:0.042225658893585205
step 261/275, epoch 168/301 --> loss:0.04852445721626282
step 271/275, epoch 168/301 --> loss:0.050196492671966554
 56%|█████▌    | 169/301 [16:06:50<11:50:50, 323.11s/it]step 11/275, epoch 169/301 --> loss:0.03972073793411255
step 21/275, epoch 169/301 --> loss:0.04189037680625916
step 31/275, epoch 169/301 --> loss:0.04770272970199585
step 41/275, epoch 169/301 --> loss:0.04190839529037475
step 51/275, epoch 169/301 --> loss:0.04195145964622497
step 61/275, epoch 169/301 --> loss:0.042978376150131226
step 71/275, epoch 169/301 --> loss:0.036585825681686404
step 81/275, epoch 169/301 --> loss:0.03764951229095459
step 91/275, epoch 169/301 --> loss:0.0455583393573761
step 101/275, epoch 169/301 --> loss:0.04539923667907715
step 111/275, epoch 169/301 --> loss:0.044689083099365236
step 121/275, epoch 169/301 --> loss:0.04496915340423584
step 131/275, epoch 169/301 --> loss:0.04223666787147522
step 141/275, epoch 169/301 --> loss:0.04062607288360596
step 151/275, epoch 169/301 --> loss:0.04337313771247864
step 161/275, epoch 169/301 --> loss:0.03303593397140503
step 171/275, epoch 169/301 --> loss:0.04646674394607544
step 181/275, epoch 169/301 --> loss:0.0484731912612915
step 191/275, epoch 169/301 --> loss:0.04585201740264892
step 201/275, epoch 169/301 --> loss:0.06469592452049255
step 211/275, epoch 169/301 --> loss:0.04672893285751343
step 221/275, epoch 169/301 --> loss:0.04838911890983581
step 231/275, epoch 169/301 --> loss:0.060845869779586795
step 241/275, epoch 169/301 --> loss:0.0457607626914978
step 251/275, epoch 169/301 --> loss:0.043301510810852054
step 261/275, epoch 169/301 --> loss:0.048909008502960205
step 271/275, epoch 169/301 --> loss:0.051778316497802734
 56%|█████▋    | 170/301 [16:12:06<11:40:47, 320.97s/it]step 11/275, epoch 170/301 --> loss:0.05079067349433899
step 21/275, epoch 170/301 --> loss:0.04991573095321655
step 31/275, epoch 170/301 --> loss:0.04698250293731689
step 41/275, epoch 170/301 --> loss:0.04440687894821167
step 51/275, epoch 170/301 --> loss:0.04404867887496948
step 61/275, epoch 170/301 --> loss:0.04841676354408264
step 71/275, epoch 170/301 --> loss:0.044122624397277835
step 81/275, epoch 170/301 --> loss:0.04752959012985229
step 91/275, epoch 170/301 --> loss:0.03599163293838501
step 101/275, epoch 170/301 --> loss:0.043739646673202515
step 111/275, epoch 170/301 --> loss:0.03562228679656983
step 121/275, epoch 170/301 --> loss:0.033381718397140506
step 131/275, epoch 170/301 --> loss:0.04628950357437134
step 141/275, epoch 170/301 --> loss:0.05202662944793701
step 151/275, epoch 170/301 --> loss:0.046481043100357056
step 161/275, epoch 170/301 --> loss:0.04244123101234436
step 171/275, epoch 170/301 --> loss:0.0482597291469574
step 181/275, epoch 170/301 --> loss:0.04065929055213928
step 191/275, epoch 170/301 --> loss:0.045572680234909055
step 201/275, epoch 170/301 --> loss:0.03671607971191406
step 211/275, epoch 170/301 --> loss:0.04381498694419861
step 221/275, epoch 170/301 --> loss:0.05510537624359131
step 231/275, epoch 170/301 --> loss:0.045877450704574586
step 241/275, epoch 170/301 --> loss:0.037246912717819214
step 251/275, epoch 170/301 --> loss:0.04530892968177795
step 261/275, epoch 170/301 --> loss:0.04343835711479187
step 271/275, epoch 170/301 --> loss:0.03779374361038208
step 11/275, epoch 171/301 --> loss:0.04557991027832031
step 21/275, epoch 171/301 --> loss:0.04919174909591675
step 31/275, epoch 171/301 --> loss:0.040023183822631835
step 41/275, epoch 171/301 --> loss:0.04819677472114563
step 51/275, epoch 171/301 --> loss:0.04479938745498657
step 61/275, epoch 171/301 --> loss:0.046833425760269165
step 71/275, epoch 171/301 --> loss:0.04709221720695496
step 81/275, epoch 171/301 --> loss:0.03392522931098938
step 91/275, epoch 171/301 --> loss:0.03800155520439148
step 101/275, epoch 171/301 --> loss:0.04890300035476684
step 111/275, epoch 171/301 --> loss:0.039183080196380615
step 121/275, epoch 171/301 --> loss:0.0438958466053009
step 131/275, epoch 171/301 --> loss:0.04281401038169861
step 141/275, epoch 171/301 --> loss:0.043614113330841066
step 151/275, epoch 171/301 --> loss:0.03935664296150208
step 161/275, epoch 171/301 --> loss:0.039963376522064206
step 171/275, epoch 171/301 --> loss:0.05090445280075073
step 181/275, epoch 171/301 --> loss:0.05210986137390137
step 191/275, epoch 171/301 --> loss:0.05067291259765625
step 201/275, epoch 171/301 --> loss:0.04494097232818604
step 211/275, epoch 171/301 --> loss:0.04644070863723755
step 221/275, epoch 171/301 --> loss:0.05144902467727661
step 231/275, epoch 171/301 --> loss:0.04131501913070679
step 241/275, epoch 171/301 --> loss:0.040427780151367186
step 251/275, epoch 171/301 --> loss:0.04965748190879822
step 261/275, epoch 171/301 --> loss:0.03976759314537048
step 271/275, epoch 171/301 --> loss:0.03952347040176392
########## train dataset ##########
PLout index:  2
acc -->  [95.54325047210853]
F1 -->  {'F1': [0.9451727379913648], 'precision': [0.9615205774355633], 'recall': [0.9293811650416935]}
########## eval dataset ##########
 57%|█████▋    | 171/301 [16:21:16<14:04:25, 389.74s/it]PLout index:  2
acc -->  [92.49400397373614]
F1 -->  {'F1': [0.9088866037019924], 'precision': [0.932562148186724], 'recall': [0.8863929323937686]}
 57%|█████▋    | 172/301 [16:26:34<13:11:56, 368.34s/it]step 11/275, epoch 172/301 --> loss:0.045234674215316774
step 21/275, epoch 172/301 --> loss:0.04960795044898987
step 31/275, epoch 172/301 --> loss:0.04545981287956238
step 41/275, epoch 172/301 --> loss:0.04705965518951416
step 51/275, epoch 172/301 --> loss:0.04251160025596619
step 61/275, epoch 172/301 --> loss:0.04262121915817261
step 71/275, epoch 172/301 --> loss:0.04380325675010681
step 81/275, epoch 172/301 --> loss:0.03909150958061218
step 91/275, epoch 172/301 --> loss:0.046998584270477296
step 101/275, epoch 172/301 --> loss:0.04841429591178894
step 111/275, epoch 172/301 --> loss:0.050769883394241336
step 121/275, epoch 172/301 --> loss:0.03793748021125794
step 131/275, epoch 172/301 --> loss:0.04394481778144836
step 141/275, epoch 172/301 --> loss:0.03907309770584107
step 151/275, epoch 172/301 --> loss:0.04914767742156982
step 161/275, epoch 172/301 --> loss:0.037518495321273805
step 171/275, epoch 172/301 --> loss:0.051633024215698244
step 181/275, epoch 172/301 --> loss:0.04277450442314148
step 191/275, epoch 172/301 --> loss:0.04447788596153259
step 201/275, epoch 172/301 --> loss:0.04648720622062683
step 211/275, epoch 172/301 --> loss:0.05241005420684815
step 221/275, epoch 172/301 --> loss:0.04642366170883179
step 231/275, epoch 172/301 --> loss:0.04379677772521973
step 241/275, epoch 172/301 --> loss:0.04934873580932617
step 251/275, epoch 172/301 --> loss:0.04518858790397644
step 261/275, epoch 172/301 --> loss:0.047164684534072875
step 271/275, epoch 172/301 --> loss:0.041640174388885495
 57%|█████▋    | 173/301 [16:31:54<12:34:39, 353.74s/it]step 11/275, epoch 173/301 --> loss:0.034932959079742434
step 21/275, epoch 173/301 --> loss:0.04733393788337707
step 31/275, epoch 173/301 --> loss:0.0453487753868103
step 41/275, epoch 173/301 --> loss:0.05919551253318787
step 51/275, epoch 173/301 --> loss:0.04122220873832703
step 61/275, epoch 173/301 --> loss:0.05705548524856567
step 71/275, epoch 173/301 --> loss:0.047425580024719236
step 81/275, epoch 173/301 --> loss:0.04607792496681214
step 91/275, epoch 173/301 --> loss:0.04622922539710998
step 101/275, epoch 173/301 --> loss:0.04883235692977905
step 111/275, epoch 173/301 --> loss:0.043699133396148684
step 121/275, epoch 173/301 --> loss:0.04864233732223511
step 131/275, epoch 173/301 --> loss:0.043902242183685304
step 141/275, epoch 173/301 --> loss:0.040840554237365725
step 151/275, epoch 173/301 --> loss:0.04065101742744446
step 161/275, epoch 173/301 --> loss:0.04440903663635254
step 171/275, epoch 173/301 --> loss:0.03560004234313965
step 181/275, epoch 173/301 --> loss:0.04060513377189636
step 191/275, epoch 173/301 --> loss:0.040373986959457396
step 201/275, epoch 173/301 --> loss:0.04780253767967224
step 211/275, epoch 173/301 --> loss:0.055339854955673215
step 221/275, epoch 173/301 --> loss:0.04449222683906555
step 231/275, epoch 173/301 --> loss:0.03847179412841797
step 241/275, epoch 173/301 --> loss:0.045530080795288086
step 251/275, epoch 173/301 --> loss:0.041802364587783816
step 261/275, epoch 173/301 --> loss:0.046674078702926634
step 271/275, epoch 173/301 --> loss:0.051880836486816406
 58%|█████▊    | 174/301 [16:37:13<12:06:57, 343.44s/it]step 11/275, epoch 174/301 --> loss:0.04406513571739197
step 21/275, epoch 174/301 --> loss:0.04065066576004028
step 31/275, epoch 174/301 --> loss:0.04205216765403748
step 41/275, epoch 174/301 --> loss:0.04795754551887512
step 51/275, epoch 174/301 --> loss:0.04373035430908203
step 61/275, epoch 174/301 --> loss:0.055048626661300656
step 71/275, epoch 174/301 --> loss:0.03982784152030945
step 81/275, epoch 174/301 --> loss:0.03557791113853455
step 91/275, epoch 174/301 --> loss:0.05261895656585693
step 101/275, epoch 174/301 --> loss:0.05312446355819702
step 111/275, epoch 174/301 --> loss:0.04545162916183472
step 121/275, epoch 174/301 --> loss:0.04641190767288208
step 131/275, epoch 174/301 --> loss:0.04567705392837525
step 141/275, epoch 174/301 --> loss:0.042513716220855716
step 151/275, epoch 174/301 --> loss:0.03892342448234558
step 161/275, epoch 174/301 --> loss:0.04612669348716736
step 171/275, epoch 174/301 --> loss:0.049338752031326295
step 181/275, epoch 174/301 --> loss:0.043974220752716064
step 191/275, epoch 174/301 --> loss:0.04457972645759582
step 201/275, epoch 174/301 --> loss:0.04361492395401001
step 211/275, epoch 174/301 --> loss:0.03433834314346314
step 221/275, epoch 174/301 --> loss:0.04480879902839661
step 231/275, epoch 174/301 --> loss:0.048028874397277835
step 241/275, epoch 174/301 --> loss:0.04528971314430237
step 251/275, epoch 174/301 --> loss:0.03872943520545959
step 261/275, epoch 174/301 --> loss:0.043045490980148315
step 271/275, epoch 174/301 --> loss:0.04087615609169006
 58%|█████▊    | 175/301 [16:42:33<11:46:15, 336.32s/it]step 11/275, epoch 175/301 --> loss:0.05065483450889587
step 21/275, epoch 175/301 --> loss:0.04336637258529663
step 31/275, epoch 175/301 --> loss:0.04687222242355347
step 41/275, epoch 175/301 --> loss:0.046284013986587526
step 51/275, epoch 175/301 --> loss:0.04097992777824402
step 61/275, epoch 175/301 --> loss:0.0415580153465271
step 71/275, epoch 175/301 --> loss:0.038797122240066526
step 81/275, epoch 175/301 --> loss:0.043143844604492186
step 91/275, epoch 175/301 --> loss:0.03670785427093506
step 101/275, epoch 175/301 --> loss:0.0566450297832489
step 111/275, epoch 175/301 --> loss:0.05921500325202942
step 121/275, epoch 175/301 --> loss:0.04422277808189392
step 131/275, epoch 175/301 --> loss:0.05242394208908081
step 141/275, epoch 175/301 --> loss:0.041258329153060914
step 151/275, epoch 175/301 --> loss:0.04149956107139587
step 161/275, epoch 175/301 --> loss:0.044347739219665526
step 171/275, epoch 175/301 --> loss:0.053577786684036253
step 181/275, epoch 175/301 --> loss:0.03811978101730347
step 191/275, epoch 175/301 --> loss:0.041743510961532594
step 201/275, epoch 175/301 --> loss:0.042730867862701416
step 211/275, epoch 175/301 --> loss:0.04934991598129272
step 221/275, epoch 175/301 --> loss:0.03859121203422546
step 231/275, epoch 175/301 --> loss:0.046901154518127444
step 241/275, epoch 175/301 --> loss:0.041075634956359866
step 251/275, epoch 175/301 --> loss:0.036550271511077884
step 261/275, epoch 175/301 --> loss:0.047950220108032224
step 271/275, epoch 175/301 --> loss:0.03691644072532654
 58%|█████▊    | 176/301 [16:47:53<11:30:15, 331.32s/it]step 11/275, epoch 176/301 --> loss:0.03630868792533874
step 21/275, epoch 176/301 --> loss:0.04248520135879517
step 31/275, epoch 176/301 --> loss:0.04019455909729004
step 41/275, epoch 176/301 --> loss:0.051389175653457644
step 51/275, epoch 176/301 --> loss:0.036429214477539065
step 61/275, epoch 176/301 --> loss:0.03747795224189758
step 71/275, epoch 176/301 --> loss:0.04140883684158325
step 81/275, epoch 176/301 --> loss:0.039353561401367185
step 91/275, epoch 176/301 --> loss:0.041127336025238034
step 101/275, epoch 176/301 --> loss:0.034877443313598634
step 111/275, epoch 176/301 --> loss:0.04144049882888794
step 121/275, epoch 176/301 --> loss:0.04627112746238708
step 131/275, epoch 176/301 --> loss:0.04450798034667969
step 141/275, epoch 176/301 --> loss:0.04421277642250061
step 151/275, epoch 176/301 --> loss:0.038739758729934695
step 161/275, epoch 176/301 --> loss:0.04286419153213501
step 171/275, epoch 176/301 --> loss:0.04659018516540527
step 181/275, epoch 176/301 --> loss:0.042552334070205686
step 191/275, epoch 176/301 --> loss:0.052096742391586306
step 201/275, epoch 176/301 --> loss:0.05049980878829956
step 211/275, epoch 176/301 --> loss:0.05459713935852051
step 221/275, epoch 176/301 --> loss:0.05598070621490479
step 231/275, epoch 176/301 --> loss:0.04495224356651306
step 241/275, epoch 176/301 --> loss:0.04962320923805237
step 251/275, epoch 176/301 --> loss:0.046432048082351685
step 261/275, epoch 176/301 --> loss:0.046709191799163816
step 271/275, epoch 176/301 --> loss:0.04511048793792725
 59%|█████▉    | 177/301 [16:53:13<11:18:08, 328.13s/it]step 11/275, epoch 177/301 --> loss:0.04048025608062744
step 21/275, epoch 177/301 --> loss:0.04406233429908753
step 31/275, epoch 177/301 --> loss:0.036953723430633544
step 41/275, epoch 177/301 --> loss:0.04061075448989868
step 51/275, epoch 177/301 --> loss:0.0459600031375885
step 61/275, epoch 177/301 --> loss:0.044858497381210324
step 71/275, epoch 177/301 --> loss:0.04952432513237
step 81/275, epoch 177/301 --> loss:0.0399515688419342
step 91/275, epoch 177/301 --> loss:0.04333379864692688
step 101/275, epoch 177/301 --> loss:0.04320862889289856
step 111/275, epoch 177/301 --> loss:0.03934551477432251
step 121/275, epoch 177/301 --> loss:0.040388953685760495
step 131/275, epoch 177/301 --> loss:0.03829653859138489
step 141/275, epoch 177/301 --> loss:0.04879204630851745
step 151/275, epoch 177/301 --> loss:0.049410170316696166
step 161/275, epoch 177/301 --> loss:0.03797026872634888
step 171/275, epoch 177/301 --> loss:0.05149751901626587
step 181/275, epoch 177/301 --> loss:0.03628128170967102
step 191/275, epoch 177/301 --> loss:0.049386829137802124
step 201/275, epoch 177/301 --> loss:0.041102266311645506
step 211/275, epoch 177/301 --> loss:0.03751515746116638
step 221/275, epoch 177/301 --> loss:0.03817044496536255
step 231/275, epoch 177/301 --> loss:0.039016932249069214
step 241/275, epoch 177/301 --> loss:0.04142666459083557
step 251/275, epoch 177/301 --> loss:0.04637302160263061
step 261/275, epoch 177/301 --> loss:0.039962267875671385
step 271/275, epoch 177/301 --> loss:0.0358122706413269
 59%|█████▉    | 178/301 [16:58:34<11:08:03, 325.88s/it]step 11/275, epoch 178/301 --> loss:0.03802322149276734
step 21/275, epoch 178/301 --> loss:0.04506056308746338
step 31/275, epoch 178/301 --> loss:0.03416804671287536
step 41/275, epoch 178/301 --> loss:0.042775577306747435
step 51/275, epoch 178/301 --> loss:0.047867614030838015
step 61/275, epoch 178/301 --> loss:0.04279969930648804
step 71/275, epoch 178/301 --> loss:0.0381964921951294
step 81/275, epoch 178/301 --> loss:0.04896925091743469
step 91/275, epoch 178/301 --> loss:0.041606009006500244
step 101/275, epoch 178/301 --> loss:0.04041033983230591
step 111/275, epoch 178/301 --> loss:0.030891627073287964
step 121/275, epoch 178/301 --> loss:0.040282464027404784
step 131/275, epoch 178/301 --> loss:0.05196647644042969
step 141/275, epoch 178/301 --> loss:0.04026440978050232
step 151/275, epoch 178/301 --> loss:0.04028739333152771
step 161/275, epoch 178/301 --> loss:0.040699994564056395
step 171/275, epoch 178/301 --> loss:0.03810432553291321
step 181/275, epoch 178/301 --> loss:0.044085574150085446
step 191/275, epoch 178/301 --> loss:0.05003790855407715
step 201/275, epoch 178/301 --> loss:0.033915752172470094
step 211/275, epoch 178/301 --> loss:0.044360899925231935
step 221/275, epoch 178/301 --> loss:0.042623627185821536
step 231/275, epoch 178/301 --> loss:0.04528482556343079
step 241/275, epoch 178/301 --> loss:0.04218881130218506
step 251/275, epoch 178/301 --> loss:0.03381531834602356
step 261/275, epoch 178/301 --> loss:0.04915812611579895
step 271/275, epoch 178/301 --> loss:0.040240544080734256
 59%|█████▉    | 179/301 [17:03:53<10:58:24, 323.81s/it]step 11/275, epoch 179/301 --> loss:0.039415568113327026
step 21/275, epoch 179/301 --> loss:0.04375958442687988
step 31/275, epoch 179/301 --> loss:0.04481176137924194
step 41/275, epoch 179/301 --> loss:0.04828773140907287
step 51/275, epoch 179/301 --> loss:0.03811347484588623
step 61/275, epoch 179/301 --> loss:0.03998672366142273
step 71/275, epoch 179/301 --> loss:0.048404091596603395
step 81/275, epoch 179/301 --> loss:0.03282915949821472
step 91/275, epoch 179/301 --> loss:0.038419699668884276
step 101/275, epoch 179/301 --> loss:0.04292060136795044
step 111/275, epoch 179/301 --> loss:0.037096691131591794
step 121/275, epoch 179/301 --> loss:0.03875724673271179
step 131/275, epoch 179/301 --> loss:0.04560213088989258
step 141/275, epoch 179/301 --> loss:0.047320425510406494
step 151/275, epoch 179/301 --> loss:0.04919021725654602
step 161/275, epoch 179/301 --> loss:0.03812375068664551
step 171/275, epoch 179/301 --> loss:0.03802695870399475
step 181/275, epoch 179/301 --> loss:0.045858103036880496
step 191/275, epoch 179/301 --> loss:0.0479766845703125
step 201/275, epoch 179/301 --> loss:0.04000333547592163
step 211/275, epoch 179/301 --> loss:0.04050740599632263
step 221/275, epoch 179/301 --> loss:0.04295904040336609
step 231/275, epoch 179/301 --> loss:0.03682070374488831
step 241/275, epoch 179/301 --> loss:0.03914390206336975
step 251/275, epoch 179/301 --> loss:0.037812405824661256
step 261/275, epoch 179/301 --> loss:0.04415925741195679
step 271/275, epoch 179/301 --> loss:0.03821632266044617
 60%|█████▉    | 180/301 [17:09:10<10:48:51, 321.75s/it]step 11/275, epoch 180/301 --> loss:0.0477137565612793
step 21/275, epoch 180/301 --> loss:0.04721523523330688
step 31/275, epoch 180/301 --> loss:0.04048927426338196
step 41/275, epoch 180/301 --> loss:0.04997071623802185
step 51/275, epoch 180/301 --> loss:0.04185750484466553
step 61/275, epoch 180/301 --> loss:0.0414451539516449
step 71/275, epoch 180/301 --> loss:0.03805899024009705
step 81/275, epoch 180/301 --> loss:0.04186456799507141
step 91/275, epoch 180/301 --> loss:0.04333696961402893
step 101/275, epoch 180/301 --> loss:0.05106581449508667
step 111/275, epoch 180/301 --> loss:0.043925303220748904
step 121/275, epoch 180/301 --> loss:0.044935351610183714
step 131/275, epoch 180/301 --> loss:0.039470672607421875
step 141/275, epoch 180/301 --> loss:0.032362735271453856
step 151/275, epoch 180/301 --> loss:0.046540236473083495
step 161/275, epoch 180/301 --> loss:0.033369457721710204
step 171/275, epoch 180/301 --> loss:0.03874873518943787
step 181/275, epoch 180/301 --> loss:0.0428965151309967
step 191/275, epoch 180/301 --> loss:0.04100862741470337
step 201/275, epoch 180/301 --> loss:0.03842065334320068
step 211/275, epoch 180/301 --> loss:0.04613652229309082
step 221/275, epoch 180/301 --> loss:0.04954070448875427
step 231/275, epoch 180/301 --> loss:0.037330061197280884
step 241/275, epoch 180/301 --> loss:0.03980581164360046
step 251/275, epoch 180/301 --> loss:0.04869142770767212
step 261/275, epoch 180/301 --> loss:0.04107697010040283
step 271/275, epoch 180/301 --> loss:0.04325076937675476
step 11/275, epoch 181/301 --> loss:0.048307770490646364
step 21/275, epoch 181/301 --> loss:0.041194218397140506
step 31/275, epoch 181/301 --> loss:0.04815108776092529
step 41/275, epoch 181/301 --> loss:0.04328451156616211
step 51/275, epoch 181/301 --> loss:0.041670370101928714
step 61/275, epoch 181/301 --> loss:0.042230868339538576
step 71/275, epoch 181/301 --> loss:0.03862119913101196
step 81/275, epoch 181/301 --> loss:0.04043130278587341
step 91/275, epoch 181/301 --> loss:0.04636039137840271
step 101/275, epoch 181/301 --> loss:0.04483455419540405
step 111/275, epoch 181/301 --> loss:0.04427114129066467
step 121/275, epoch 181/301 --> loss:0.04865679144859314
step 131/275, epoch 181/301 --> loss:0.0361231803894043
step 141/275, epoch 181/301 --> loss:0.03902927041053772
step 151/275, epoch 181/301 --> loss:0.049249780178070066
step 161/275, epoch 181/301 --> loss:0.043938732147216795
step 171/275, epoch 181/301 --> loss:0.045672672986984256
step 181/275, epoch 181/301 --> loss:0.038003623485565186
step 191/275, epoch 181/301 --> loss:0.04698683619499207
step 201/275, epoch 181/301 --> loss:0.04198553562164307
step 211/275, epoch 181/301 --> loss:0.03982539772987366
step 221/275, epoch 181/301 --> loss:0.03620545864105225
step 231/275, epoch 181/301 --> loss:0.04000861048698425
step 241/275, epoch 181/301 --> loss:0.03744736909866333
step 251/275, epoch 181/301 --> loss:0.041149741411209105
step 261/275, epoch 181/301 --> loss:0.04396981596946716
step 271/275, epoch 181/301 --> loss:0.045948338508605954
########## train dataset ##########
PLout index:  2
acc -->  [96.67162557009851]
F1 -->  {'F1': [0.9596038448815654], 'precision': [0.9627953363871982], 'recall': [0.9564433758222481]}
########## eval dataset ##########
 60%|██████    | 181/301 [17:18:22<13:01:41, 390.84s/it]PLout index:  2
acc -->  [93.22115204752525]
F1 -->  {'F1': [0.9193544371859089], 'precision': [0.923909102187248], 'recall': [0.9148543607347233]}
 60%|██████    | 182/301 [17:23:40<12:11:47, 368.97s/it]step 11/275, epoch 182/301 --> loss:0.04330276250839234
step 21/275, epoch 182/301 --> loss:0.0382546067237854
step 31/275, epoch 182/301 --> loss:0.042949944734573364
step 41/275, epoch 182/301 --> loss:0.03910626769065857
step 51/275, epoch 182/301 --> loss:0.04408568739891052
step 61/275, epoch 182/301 --> loss:0.0450307309627533
step 71/275, epoch 182/301 --> loss:0.037510383129119876
step 81/275, epoch 182/301 --> loss:0.03802586793899536
step 91/275, epoch 182/301 --> loss:0.040998584032058714
step 101/275, epoch 182/301 --> loss:0.036554038524627686
step 111/275, epoch 182/301 --> loss:0.035029590129852295
step 121/275, epoch 182/301 --> loss:0.045788919925689696
step 131/275, epoch 182/301 --> loss:0.03528032302856445
step 141/275, epoch 182/301 --> loss:0.035436367988586424
step 151/275, epoch 182/301 --> loss:0.03942188620567322
step 161/275, epoch 182/301 --> loss:0.046198558807373044
step 171/275, epoch 182/301 --> loss:0.04449845552444458
step 181/275, epoch 182/301 --> loss:0.040542048215866086
step 191/275, epoch 182/301 --> loss:0.04268246293067932
step 201/275, epoch 182/301 --> loss:0.04333520531654358
step 211/275, epoch 182/301 --> loss:0.04109458327293396
step 221/275, epoch 182/301 --> loss:0.04038802981376648
step 231/275, epoch 182/301 --> loss:0.0386691153049469
step 241/275, epoch 182/301 --> loss:0.03508511781692505
step 251/275, epoch 182/301 --> loss:0.046147984266281125
step 261/275, epoch 182/301 --> loss:0.047114056348800656
step 271/275, epoch 182/301 --> loss:0.04087470173835754
 61%|██████    | 183/301 [17:29:00<11:36:48, 354.31s/it]step 11/275, epoch 183/301 --> loss:0.04599835276603699
step 21/275, epoch 183/301 --> loss:0.051333123445510866
step 31/275, epoch 183/301 --> loss:0.04196838140487671
step 41/275, epoch 183/301 --> loss:0.03619025349617004
step 51/275, epoch 183/301 --> loss:0.04587385654449463
step 61/275, epoch 183/301 --> loss:0.04579782485961914
step 71/275, epoch 183/301 --> loss:0.03164324164390564
step 81/275, epoch 183/301 --> loss:0.03371196985244751
step 91/275, epoch 183/301 --> loss:0.032503378391265866
step 101/275, epoch 183/301 --> loss:0.047012776136398315
step 111/275, epoch 183/301 --> loss:0.04160469174385071
step 121/275, epoch 183/301 --> loss:0.042809474468231204
step 131/275, epoch 183/301 --> loss:0.03705788254737854
step 141/275, epoch 183/301 --> loss:0.04187169075012207
step 151/275, epoch 183/301 --> loss:0.04254280924797058
step 161/275, epoch 183/301 --> loss:0.038233053684234616
step 171/275, epoch 183/301 --> loss:0.03779414892196655
step 181/275, epoch 183/301 --> loss:0.04127843976020813
step 191/275, epoch 183/301 --> loss:0.04237852096557617
step 201/275, epoch 183/301 --> loss:0.04886059165000915
step 211/275, epoch 183/301 --> loss:0.03641024827957153
step 221/275, epoch 183/301 --> loss:0.03909531235694885
step 231/275, epoch 183/301 --> loss:0.032864177227020265
step 241/275, epoch 183/301 --> loss:0.046570831537246705
step 251/275, epoch 183/301 --> loss:0.037546753883361816
step 261/275, epoch 183/301 --> loss:0.04651855230331421
step 271/275, epoch 183/301 --> loss:0.047342443466186525
 61%|██████    | 184/301 [17:34:21<11:11:12, 344.21s/it]step 11/275, epoch 184/301 --> loss:0.05025656223297119
step 21/275, epoch 184/301 --> loss:0.045540106296539304
step 31/275, epoch 184/301 --> loss:0.04237767457962036
step 41/275, epoch 184/301 --> loss:0.04804232716560364
step 51/275, epoch 184/301 --> loss:0.044931864738464354
step 61/275, epoch 184/301 --> loss:0.04062660932540894
step 71/275, epoch 184/301 --> loss:0.048992866277694704
step 81/275, epoch 184/301 --> loss:0.041071575880050656
step 91/275, epoch 184/301 --> loss:0.04606303572654724
step 101/275, epoch 184/301 --> loss:0.04435282349586487
step 111/275, epoch 184/301 --> loss:0.04014108180999756
step 121/275, epoch 184/301 --> loss:0.039908528327941895
step 131/275, epoch 184/301 --> loss:0.04238488078117371
step 141/275, epoch 184/301 --> loss:0.04077598452568054
step 151/275, epoch 184/301 --> loss:0.044802296161651614
step 161/275, epoch 184/301 --> loss:0.03886362910270691
step 171/275, epoch 184/301 --> loss:0.03483237624168396
step 181/275, epoch 184/301 --> loss:0.051118433475494385
step 191/275, epoch 184/301 --> loss:0.04447697997093201
step 201/275, epoch 184/301 --> loss:0.04560174345970154
step 211/275, epoch 184/301 --> loss:0.03911605477333069
step 221/275, epoch 184/301 --> loss:0.03989100456237793
step 231/275, epoch 184/301 --> loss:0.04569575786590576
step 241/275, epoch 184/301 --> loss:0.04776407480239868
step 251/275, epoch 184/301 --> loss:0.036312651634216306
step 261/275, epoch 184/301 --> loss:0.034475678205490114
step 271/275, epoch 184/301 --> loss:0.045803165435791014
 61%|██████▏   | 185/301 [17:39:40<10:51:00, 336.73s/it]step 11/275, epoch 185/301 --> loss:0.03998851776123047
step 21/275, epoch 185/301 --> loss:0.03695443272590637
step 31/275, epoch 185/301 --> loss:0.03797084093093872
step 41/275, epoch 185/301 --> loss:0.04925336241722107
step 51/275, epoch 185/301 --> loss:0.04611283540725708
step 61/275, epoch 185/301 --> loss:0.04393150806427002
step 71/275, epoch 185/301 --> loss:0.03413635492324829
step 81/275, epoch 185/301 --> loss:0.03694608807563782
step 91/275, epoch 185/301 --> loss:0.032718819379806516
step 101/275, epoch 185/301 --> loss:0.03727787733078003
step 111/275, epoch 185/301 --> loss:0.03424776792526245
step 121/275, epoch 185/301 --> loss:0.04846983551979065
step 131/275, epoch 185/301 --> loss:0.040710455179214476
step 141/275, epoch 185/301 --> loss:0.047277170419692996
step 151/275, epoch 185/301 --> loss:0.041454237699508664
step 161/275, epoch 185/301 --> loss:0.045863741636276247
step 171/275, epoch 185/301 --> loss:0.035775798559188846
step 181/275, epoch 185/301 --> loss:0.038241136074066165
step 191/275, epoch 185/301 --> loss:0.04013553261756897
step 201/275, epoch 185/301 --> loss:0.044068753719329834
step 211/275, epoch 185/301 --> loss:0.04329176545143128
step 221/275, epoch 185/301 --> loss:0.037773150205612185
step 231/275, epoch 185/301 --> loss:0.04841238260269165
step 241/275, epoch 185/301 --> loss:0.053600215911865236
step 251/275, epoch 185/301 --> loss:0.04065151214599609
step 261/275, epoch 185/301 --> loss:0.04621020555496216
step 271/275, epoch 185/301 --> loss:0.04321272969245911
 62%|██████▏   | 186/301 [17:44:59<10:35:11, 331.40s/it]step 11/275, epoch 186/301 --> loss:0.043059080839157104
step 21/275, epoch 186/301 --> loss:0.03918488025665283
step 31/275, epoch 186/301 --> loss:0.04549806118011475
step 41/275, epoch 186/301 --> loss:0.04425355792045593
step 51/275, epoch 186/301 --> loss:0.044531244039535525
step 61/275, epoch 186/301 --> loss:0.04503058195114136
step 71/275, epoch 186/301 --> loss:0.04917210340499878
step 81/275, epoch 186/301 --> loss:0.03680882453918457
step 91/275, epoch 186/301 --> loss:0.045096945762634275
step 101/275, epoch 186/301 --> loss:0.04209814667701721
step 111/275, epoch 186/301 --> loss:0.03714590072631836
step 121/275, epoch 186/301 --> loss:0.04121043086051941
step 131/275, epoch 186/301 --> loss:0.037559902667999266
step 141/275, epoch 186/301 --> loss:0.04460301995277405
step 151/275, epoch 186/301 --> loss:0.03340826630592346
step 161/275, epoch 186/301 --> loss:0.04311135411262512
step 171/275, epoch 186/301 --> loss:0.03914163708686828
step 181/275, epoch 186/301 --> loss:0.042973381280899045
step 191/275, epoch 186/301 --> loss:0.03910772800445557
step 201/275, epoch 186/301 --> loss:0.03729748725891113
step 211/275, epoch 186/301 --> loss:0.03929159641265869
step 221/275, epoch 186/301 --> loss:0.04674767851829529
step 231/275, epoch 186/301 --> loss:0.057984739542007446
step 241/275, epoch 186/301 --> loss:0.04052545428276062
step 251/275, epoch 186/301 --> loss:0.05012139678001404
step 261/275, epoch 186/301 --> loss:0.04361652135848999
step 271/275, epoch 186/301 --> loss:0.05051188468933106
 62%|██████▏   | 187/301 [17:50:16<10:21:23, 327.05s/it]step 11/275, epoch 187/301 --> loss:0.04575377702713013
step 21/275, epoch 187/301 --> loss:0.04249165058135986
step 31/275, epoch 187/301 --> loss:0.03801760673522949
step 41/275, epoch 187/301 --> loss:0.038294035196304324
step 51/275, epoch 187/301 --> loss:0.03444729447364807
step 61/275, epoch 187/301 --> loss:0.03705301880836487
step 71/275, epoch 187/301 --> loss:0.03574673533439636
step 81/275, epoch 187/301 --> loss:0.04227798581123352
step 91/275, epoch 187/301 --> loss:0.03872097134590149
step 101/275, epoch 187/301 --> loss:0.04186468124389649
step 111/275, epoch 187/301 --> loss:0.04201837778091431
step 121/275, epoch 187/301 --> loss:0.04030656814575195
step 131/275, epoch 187/301 --> loss:0.05326089262962341
step 141/275, epoch 187/301 --> loss:0.04112417101860046
step 151/275, epoch 187/301 --> loss:0.047643625736236574
step 161/275, epoch 187/301 --> loss:0.03849498629570007
step 171/275, epoch 187/301 --> loss:0.036349207162857056
step 181/275, epoch 187/301 --> loss:0.04461246132850647
step 191/275, epoch 187/301 --> loss:0.03675419688224792
step 201/275, epoch 187/301 --> loss:0.03870828747749329
step 211/275, epoch 187/301 --> loss:0.0357381284236908
step 221/275, epoch 187/301 --> loss:0.048046422004699704
step 231/275, epoch 187/301 --> loss:0.04624309539794922
step 241/275, epoch 187/301 --> loss:0.03727602958679199
step 251/275, epoch 187/301 --> loss:0.03862790465354919
step 261/275, epoch 187/301 --> loss:0.042409497499465945
step 271/275, epoch 187/301 --> loss:0.03024274706840515
 62%|██████▏   | 188/301 [17:55:32<10:09:30, 323.64s/it]step 11/275, epoch 188/301 --> loss:0.0367084801197052
step 21/275, epoch 188/301 --> loss:0.03434301614761352
step 31/275, epoch 188/301 --> loss:0.036168789863586424
step 41/275, epoch 188/301 --> loss:0.03038700819015503
step 51/275, epoch 188/301 --> loss:0.037863969802856445
step 61/275, epoch 188/301 --> loss:0.028882956504821776
step 71/275, epoch 188/301 --> loss:0.03621785640716553
step 81/275, epoch 188/301 --> loss:0.036342179775238036
step 91/275, epoch 188/301 --> loss:0.045772552490234375
step 101/275, epoch 188/301 --> loss:0.04670514464378357
step 111/275, epoch 188/301 --> loss:0.04368743896484375
step 121/275, epoch 188/301 --> loss:0.037599867582321166
step 131/275, epoch 188/301 --> loss:0.04185393452644348
step 141/275, epoch 188/301 --> loss:0.03908032178878784
step 151/275, epoch 188/301 --> loss:0.043348771333694455
step 161/275, epoch 188/301 --> loss:0.044194978475570676
step 171/275, epoch 188/301 --> loss:0.03800899386405945
step 181/275, epoch 188/301 --> loss:0.04530032873153687
step 191/275, epoch 188/301 --> loss:0.04743451476097107
step 201/275, epoch 188/301 --> loss:0.035833466053009036
step 211/275, epoch 188/301 --> loss:0.035093915462493894
step 221/275, epoch 188/301 --> loss:0.0432449996471405
step 231/275, epoch 188/301 --> loss:0.0387457013130188
step 241/275, epoch 188/301 --> loss:0.041836613416671754
step 251/275, epoch 188/301 --> loss:0.042191427946090695
step 261/275, epoch 188/301 --> loss:0.04443407654762268
step 271/275, epoch 188/301 --> loss:0.04160926342010498
 63%|██████▎   | 189/301 [18:00:48<9:59:48, 321.33s/it] step 11/275, epoch 189/301 --> loss:0.03560618162155151
step 21/275, epoch 189/301 --> loss:0.04342675805091858
step 31/275, epoch 189/301 --> loss:0.03776891231536865
step 41/275, epoch 189/301 --> loss:0.0345409095287323
step 51/275, epoch 189/301 --> loss:0.044896882772445676
step 61/275, epoch 189/301 --> loss:0.04480062127113342
step 71/275, epoch 189/301 --> loss:0.033432388305664064
step 81/275, epoch 189/301 --> loss:0.041168206930160524
step 91/275, epoch 189/301 --> loss:0.03921751976013184
step 101/275, epoch 189/301 --> loss:0.038247084617614745
step 111/275, epoch 189/301 --> loss:0.03485475778579712
step 121/275, epoch 189/301 --> loss:0.03466449379920959
step 131/275, epoch 189/301 --> loss:0.03949121832847595
step 141/275, epoch 189/301 --> loss:0.040827155113220215
step 151/275, epoch 189/301 --> loss:0.039623034000396726
step 161/275, epoch 189/301 --> loss:0.043636614084243776
step 171/275, epoch 189/301 --> loss:0.0399856686592102
step 181/275, epoch 189/301 --> loss:0.036113566160202025
step 191/275, epoch 189/301 --> loss:0.0352818489074707
step 201/275, epoch 189/301 --> loss:0.04149118661880493
step 211/275, epoch 189/301 --> loss:0.0445038914680481
step 221/275, epoch 189/301 --> loss:0.048504066467285153
step 231/275, epoch 189/301 --> loss:0.034556764364242556
step 241/275, epoch 189/301 --> loss:0.047887712717056274
step 251/275, epoch 189/301 --> loss:0.04460950493812561
step 261/275, epoch 189/301 --> loss:0.03586652874946594
step 271/275, epoch 189/301 --> loss:0.03747074604034424
 63%|██████▎   | 190/301 [18:06:05<9:52:09, 320.08s/it]step 11/275, epoch 190/301 --> loss:0.04114875793457031
step 21/275, epoch 190/301 --> loss:0.037008196115493774
step 31/275, epoch 190/301 --> loss:0.04033544659614563
step 41/275, epoch 190/301 --> loss:0.03938716053962708
step 51/275, epoch 190/301 --> loss:0.033369588851928714
step 61/275, epoch 190/301 --> loss:0.03651626706123352
step 71/275, epoch 190/301 --> loss:0.036705344915390015
step 81/275, epoch 190/301 --> loss:0.04142572283744812
step 91/275, epoch 190/301 --> loss:0.04023025631904602
step 101/275, epoch 190/301 --> loss:0.03427854776382446
step 111/275, epoch 190/301 --> loss:0.04237096905708313
step 121/275, epoch 190/301 --> loss:0.03444353938102722
step 131/275, epoch 190/301 --> loss:0.04814193248748779
step 141/275, epoch 190/301 --> loss:0.03935267925262451
step 151/275, epoch 190/301 --> loss:0.039123809337615965
step 161/275, epoch 190/301 --> loss:0.043718546628952026
step 171/275, epoch 190/301 --> loss:0.032207679748535153
step 181/275, epoch 190/301 --> loss:0.03188483715057373
step 191/275, epoch 190/301 --> loss:0.036238884925842284
step 201/275, epoch 190/301 --> loss:0.029305368661880493
step 211/275, epoch 190/301 --> loss:0.03664441704750061
step 221/275, epoch 190/301 --> loss:0.034692853689193726
step 231/275, epoch 190/301 --> loss:0.03643442988395691
step 241/275, epoch 190/301 --> loss:0.04085873365402222
step 251/275, epoch 190/301 --> loss:0.029759919643402098
step 261/275, epoch 190/301 --> loss:0.0371552050113678
step 271/275, epoch 190/301 --> loss:0.03990405797958374
step 11/275, epoch 191/301 --> loss:0.03021780252456665
step 21/275, epoch 191/301 --> loss:0.03648849129676819
step 31/275, epoch 191/301 --> loss:0.04909459352493286
step 41/275, epoch 191/301 --> loss:0.03908116817474365
step 51/275, epoch 191/301 --> loss:0.03794078230857849
step 61/275, epoch 191/301 --> loss:0.033796459436416626
step 71/275, epoch 191/301 --> loss:0.04296313524246216
step 81/275, epoch 191/301 --> loss:0.028277140855789185
step 91/275, epoch 191/301 --> loss:0.03510388731956482
step 101/275, epoch 191/301 --> loss:0.03654143810272217
step 111/275, epoch 191/301 --> loss:0.0427877128124237
step 121/275, epoch 191/301 --> loss:0.04269217848777771
step 131/275, epoch 191/301 --> loss:0.049093878269195555
step 141/275, epoch 191/301 --> loss:0.04148999452590942
step 151/275, epoch 191/301 --> loss:0.036692196130752565
step 161/275, epoch 191/301 --> loss:0.034616464376449586
step 171/275, epoch 191/301 --> loss:0.034532290697097776
step 181/275, epoch 191/301 --> loss:0.04279699921607971
step 191/275, epoch 191/301 --> loss:0.040000039339065555
step 201/275, epoch 191/301 --> loss:0.045396971702575686
step 211/275, epoch 191/301 --> loss:0.03280143737792969
step 221/275, epoch 191/301 --> loss:0.04384270906448364
step 231/275, epoch 191/301 --> loss:0.0422764003276825
step 241/275, epoch 191/301 --> loss:0.0408897340297699
step 251/275, epoch 191/301 --> loss:0.032100903987884524
step 261/275, epoch 191/301 --> loss:0.04136025309562683
step 271/275, epoch 191/301 --> loss:0.03434067964553833
########## train dataset ##########
PLout index:  2
acc -->  [97.18224694000288]
F1 -->  {'F1': [0.9659312458559088], 'precision': [0.9654261210759382], 'recall': [0.9664469099593934]}
########## eval dataset ##########
 63%|██████▎   | 191/301 [18:15:21<11:56:29, 390.81s/it]PLout index:  2
acc -->  [93.44995838107458]
F1 -->  {'F1': [0.9225672152887544], 'precision': [0.9212759269439037], 'recall': [0.9238721566043233]}
save model!
 64%|██████▍   | 192/301 [18:20:40<11:10:59, 369.36s/it]step 11/275, epoch 192/301 --> loss:0.03899330496788025
step 21/275, epoch 192/301 --> loss:0.036209499835968016
step 31/275, epoch 192/301 --> loss:0.02829543948173523
step 41/275, epoch 192/301 --> loss:0.03793153166770935
step 51/275, epoch 192/301 --> loss:0.03902134299278259
step 61/275, epoch 192/301 --> loss:0.0369221031665802
step 71/275, epoch 192/301 --> loss:0.0393731415271759
step 81/275, epoch 192/301 --> loss:0.03740890622138977
step 91/275, epoch 192/301 --> loss:0.042544209957122804
step 101/275, epoch 192/301 --> loss:0.03629065752029419
step 111/275, epoch 192/301 --> loss:0.04631460905075073
step 121/275, epoch 192/301 --> loss:0.037815988063812256
step 131/275, epoch 192/301 --> loss:0.04149677157402039
step 141/275, epoch 192/301 --> loss:0.03649998307228088
step 151/275, epoch 192/301 --> loss:0.04215620756149292
step 161/275, epoch 192/301 --> loss:0.04332466721534729
step 171/275, epoch 192/301 --> loss:0.03633232712745667
step 181/275, epoch 192/301 --> loss:0.042864125967025754
step 191/275, epoch 192/301 --> loss:0.048987078666687014
step 201/275, epoch 192/301 --> loss:0.04463922381401062
step 211/275, epoch 192/301 --> loss:0.042941725254058837
step 221/275, epoch 192/301 --> loss:0.04207512140274048
step 231/275, epoch 192/301 --> loss:0.04361302852630615
step 241/275, epoch 192/301 --> loss:0.0425753653049469
step 251/275, epoch 192/301 --> loss:0.03650751709938049
step 261/275, epoch 192/301 --> loss:0.03923028111457825
step 271/275, epoch 192/301 --> loss:0.033556568622589114
 64%|██████▍   | 193/301 [18:26:00<10:38:17, 354.60s/it]step 11/275, epoch 193/301 --> loss:0.04198154807090759
step 21/275, epoch 193/301 --> loss:0.03628239035606384
step 31/275, epoch 193/301 --> loss:0.033378887176513675
step 41/275, epoch 193/301 --> loss:0.033286643028259275
step 51/275, epoch 193/301 --> loss:0.04489264488220215
step 61/275, epoch 193/301 --> loss:0.04511340856552124
step 71/275, epoch 193/301 --> loss:0.03619532585144043
step 81/275, epoch 193/301 --> loss:0.03379243612289429
step 91/275, epoch 193/301 --> loss:0.0405751645565033
step 101/275, epoch 193/301 --> loss:0.04882397055625916
step 111/275, epoch 193/301 --> loss:0.04843547344207764
step 121/275, epoch 193/301 --> loss:0.031826096773147586
step 131/275, epoch 193/301 --> loss:0.03822281360626221
step 141/275, epoch 193/301 --> loss:0.03638685345649719
step 151/275, epoch 193/301 --> loss:0.038246291875839236
step 161/275, epoch 193/301 --> loss:0.04384846687316894
step 171/275, epoch 193/301 --> loss:0.036959731578826906
step 181/275, epoch 193/301 --> loss:0.03149918913841247
step 191/275, epoch 193/301 --> loss:0.04069312810897827
step 201/275, epoch 193/301 --> loss:0.04210998415946961
step 211/275, epoch 193/301 --> loss:0.041015511751174925
step 221/275, epoch 193/301 --> loss:0.04694241881370544
step 231/275, epoch 193/301 --> loss:0.04344034194946289
step 241/275, epoch 193/301 --> loss:0.04457187056541443
step 251/275, epoch 193/301 --> loss:0.04049788117408752
step 261/275, epoch 193/301 --> loss:0.037286579608917236
step 271/275, epoch 193/301 --> loss:0.034973806142807005
 64%|██████▍   | 194/301 [18:31:21<10:14:16, 344.46s/it]step 11/275, epoch 194/301 --> loss:0.03143573999404907
step 21/275, epoch 194/301 --> loss:0.031231045722961426
step 31/275, epoch 194/301 --> loss:0.03811014890670776
step 41/275, epoch 194/301 --> loss:0.045947599411010745
step 51/275, epoch 194/301 --> loss:0.0349215030670166
step 61/275, epoch 194/301 --> loss:0.03495474457740784
step 71/275, epoch 194/301 --> loss:0.03907652497291565
step 81/275, epoch 194/301 --> loss:0.0360624372959137
step 91/275, epoch 194/301 --> loss:0.03716825842857361
step 101/275, epoch 194/301 --> loss:0.03956679105758667
step 111/275, epoch 194/301 --> loss:0.0492571771144867
step 121/275, epoch 194/301 --> loss:0.04344509840011597
step 131/275, epoch 194/301 --> loss:0.03505332469940185
step 141/275, epoch 194/301 --> loss:0.03989910483360291
step 151/275, epoch 194/301 --> loss:0.03756170868873596
step 161/275, epoch 194/301 --> loss:0.038606077432632446
step 171/275, epoch 194/301 --> loss:0.03421644568443298
step 181/275, epoch 194/301 --> loss:0.03498167395591736
step 191/275, epoch 194/301 --> loss:0.03956634402275085
step 201/275, epoch 194/301 --> loss:0.033869427442550656
step 211/275, epoch 194/301 --> loss:0.04449630379676819
step 221/275, epoch 194/301 --> loss:0.03684455156326294
step 231/275, epoch 194/301 --> loss:0.04379485845565796
step 241/275, epoch 194/301 --> loss:0.03623310923576355
step 251/275, epoch 194/301 --> loss:0.04130663275718689
step 261/275, epoch 194/301 --> loss:0.043741679191589354
step 271/275, epoch 194/301 --> loss:0.032550156116485596
 65%|██████▍   | 195/301 [18:36:41<9:55:52, 337.29s/it] step 11/275, epoch 195/301 --> loss:0.04855448603630066
step 21/275, epoch 195/301 --> loss:0.05453859567642212
step 31/275, epoch 195/301 --> loss:0.0440024733543396
step 41/275, epoch 195/301 --> loss:0.053470653295516965
step 51/275, epoch 195/301 --> loss:0.03925684690475464
step 61/275, epoch 195/301 --> loss:0.038015127182006836
step 71/275, epoch 195/301 --> loss:0.04855473637580872
step 81/275, epoch 195/301 --> loss:0.04881255626678467
step 91/275, epoch 195/301 --> loss:0.03403413891792297
step 101/275, epoch 195/301 --> loss:0.03625011444091797
step 111/275, epoch 195/301 --> loss:0.05160297751426697
step 121/275, epoch 195/301 --> loss:0.036039888858795166
step 131/275, epoch 195/301 --> loss:0.03308146595954895
step 141/275, epoch 195/301 --> loss:0.036838638782501223
step 151/275, epoch 195/301 --> loss:0.033170127868652345
step 161/275, epoch 195/301 --> loss:0.05144725441932678
step 171/275, epoch 195/301 --> loss:0.04456124901771545
step 181/275, epoch 195/301 --> loss:0.047498655319213864
step 191/275, epoch 195/301 --> loss:0.039814919233322144
step 201/275, epoch 195/301 --> loss:0.036153435707092285
step 211/275, epoch 195/301 --> loss:0.04848037958145142
step 221/275, epoch 195/301 --> loss:0.03899165987968445
step 231/275, epoch 195/301 --> loss:0.047441065311431885
step 241/275, epoch 195/301 --> loss:0.0434175968170166
step 251/275, epoch 195/301 --> loss:0.038746345043182376
step 261/275, epoch 195/301 --> loss:0.04177218675613403
step 271/275, epoch 195/301 --> loss:0.04824197292327881
 65%|██████▌   | 196/301 [18:42:00<9:40:25, 331.67s/it]step 11/275, epoch 196/301 --> loss:0.051525849103927615
step 21/275, epoch 196/301 --> loss:0.03960630893707275
step 31/275, epoch 196/301 --> loss:0.041683894395828244
step 41/275, epoch 196/301 --> loss:0.04578571915626526
step 51/275, epoch 196/301 --> loss:0.04221871495246887
step 61/275, epoch 196/301 --> loss:0.034704601764678954
step 71/275, epoch 196/301 --> loss:0.04603789448738098
step 81/275, epoch 196/301 --> loss:0.044547027349472045
step 91/275, epoch 196/301 --> loss:0.036645418405532836
step 101/275, epoch 196/301 --> loss:0.043882977962493894
step 111/275, epoch 196/301 --> loss:0.042914348840713504
step 121/275, epoch 196/301 --> loss:0.04488663673400879
step 131/275, epoch 196/301 --> loss:0.03818860650062561
step 141/275, epoch 196/301 --> loss:0.04086044430732727
step 151/275, epoch 196/301 --> loss:0.03696506023406983
step 161/275, epoch 196/301 --> loss:0.04102334976196289
step 171/275, epoch 196/301 --> loss:0.03514813780784607
step 181/275, epoch 196/301 --> loss:0.03545804619789124
step 191/275, epoch 196/301 --> loss:0.038833397626876834
step 201/275, epoch 196/301 --> loss:0.04421795010566711
step 211/275, epoch 196/301 --> loss:0.04741876721382141
step 221/275, epoch 196/301 --> loss:0.036578261852264406
step 231/275, epoch 196/301 --> loss:0.04007108211517334
step 241/275, epoch 196/301 --> loss:0.034795749187469485
step 251/275, epoch 196/301 --> loss:0.04703027009963989
step 261/275, epoch 196/301 --> loss:0.03629948496818543
step 271/275, epoch 196/301 --> loss:0.034342730045318605
 65%|██████▌   | 197/301 [18:47:16<9:26:44, 326.97s/it]step 11/275, epoch 197/301 --> loss:0.03867228627204895
step 21/275, epoch 197/301 --> loss:0.03685463070869446
step 31/275, epoch 197/301 --> loss:0.0365735650062561
step 41/275, epoch 197/301 --> loss:0.03710554838180542
step 51/275, epoch 197/301 --> loss:0.03535711169242859
step 61/275, epoch 197/301 --> loss:0.03681849837303162
step 71/275, epoch 197/301 --> loss:0.03869691491127014
step 81/275, epoch 197/301 --> loss:0.033274614810943605
step 91/275, epoch 197/301 --> loss:0.04143739342689514
step 101/275, epoch 197/301 --> loss:0.04377035498619079
step 111/275, epoch 197/301 --> loss:0.03897966742515564
step 121/275, epoch 197/301 --> loss:0.031143826246261597
step 131/275, epoch 197/301 --> loss:0.03034137487411499
step 141/275, epoch 197/301 --> loss:0.04049866795539856
step 151/275, epoch 197/301 --> loss:0.04190310835838318
step 161/275, epoch 197/301 --> loss:0.038620364665985105
step 171/275, epoch 197/301 --> loss:0.036410284042358396
step 181/275, epoch 197/301 --> loss:0.03881986737251282
step 191/275, epoch 197/301 --> loss:0.03128846883773804
step 201/275, epoch 197/301 --> loss:0.03672320246696472
step 211/275, epoch 197/301 --> loss:0.0494194746017456
step 221/275, epoch 197/301 --> loss:0.03704195022583008
step 231/275, epoch 197/301 --> loss:0.03673105239868164
step 241/275, epoch 197/301 --> loss:0.032274043560028075
step 251/275, epoch 197/301 --> loss:0.03646389842033386
step 261/275, epoch 197/301 --> loss:0.04326314330101013
step 271/275, epoch 197/301 --> loss:0.0408339262008667
 66%|██████▌   | 198/301 [18:52:32<9:15:30, 323.60s/it]step 11/275, epoch 198/301 --> loss:0.03484176993370056
step 21/275, epoch 198/301 --> loss:0.03542039394378662
step 31/275, epoch 198/301 --> loss:0.03253889083862305
step 41/275, epoch 198/301 --> loss:0.038771200180053714
step 51/275, epoch 198/301 --> loss:0.04003506302833557
step 61/275, epoch 198/301 --> loss:0.04205547571182251
step 71/275, epoch 198/301 --> loss:0.0351101279258728
step 81/275, epoch 198/301 --> loss:0.041328781843185426
step 91/275, epoch 198/301 --> loss:0.03723546266555786
step 101/275, epoch 198/301 --> loss:0.03819405436515808
step 111/275, epoch 198/301 --> loss:0.04338155388832092
step 121/275, epoch 198/301 --> loss:0.0398883581161499
step 131/275, epoch 198/301 --> loss:0.041488397121429446
step 141/275, epoch 198/301 --> loss:0.03400022983551025
step 151/275, epoch 198/301 --> loss:0.03751835823059082
step 161/275, epoch 198/301 --> loss:0.03099933862686157
step 171/275, epoch 198/301 --> loss:0.04570406675338745
step 181/275, epoch 198/301 --> loss:0.03588737845420838
step 191/275, epoch 198/301 --> loss:0.03930842876434326
step 201/275, epoch 198/301 --> loss:0.034702193737030027
step 211/275, epoch 198/301 --> loss:0.03710013031959534
step 221/275, epoch 198/301 --> loss:0.036311328411102295
step 231/275, epoch 198/301 --> loss:0.03534772992134094
step 241/275, epoch 198/301 --> loss:0.03363432288169861
step 251/275, epoch 198/301 --> loss:0.035873234272003174
step 261/275, epoch 198/301 --> loss:0.037094336748123166
step 271/275, epoch 198/301 --> loss:0.037146008014678954
 66%|██████▌   | 199/301 [18:57:48<9:06:29, 321.46s/it]step 11/275, epoch 199/301 --> loss:0.03445357084274292
step 21/275, epoch 199/301 --> loss:0.05291415452957153
step 31/275, epoch 199/301 --> loss:0.037235337495803836
step 41/275, epoch 199/301 --> loss:0.04365883469581604
step 51/275, epoch 199/301 --> loss:0.038594961166381836
step 61/275, epoch 199/301 --> loss:0.04013053178787231
step 71/275, epoch 199/301 --> loss:0.0423412561416626
step 81/275, epoch 199/301 --> loss:0.03686648011207581
step 91/275, epoch 199/301 --> loss:0.0446983277797699
step 101/275, epoch 199/301 --> loss:0.03986281156539917
step 111/275, epoch 199/301 --> loss:0.03598904609680176
step 121/275, epoch 199/301 --> loss:0.03796393871307373
step 131/275, epoch 199/301 --> loss:0.03145197629928589
step 141/275, epoch 199/301 --> loss:0.034311318397521974
step 151/275, epoch 199/301 --> loss:0.04321012496948242
step 161/275, epoch 199/301 --> loss:0.04189838171005249
step 171/275, epoch 199/301 --> loss:0.05094607472419739
step 181/275, epoch 199/301 --> loss:0.038500469923019406
step 191/275, epoch 199/301 --> loss:0.043281334638595584
step 201/275, epoch 199/301 --> loss:0.04243471622467041
step 211/275, epoch 199/301 --> loss:0.03182356953620911
step 221/275, epoch 199/301 --> loss:0.03756021857261658
step 231/275, epoch 199/301 --> loss:0.039027941226959226
step 241/275, epoch 199/301 --> loss:0.03603048324584961
step 251/275, epoch 199/301 --> loss:0.0425150454044342
step 261/275, epoch 199/301 --> loss:0.04259368181228638
step 271/275, epoch 199/301 --> loss:0.0376360297203064
 66%|██████▋   | 200/301 [19:03:06<8:59:27, 320.47s/it]step 11/275, epoch 200/301 --> loss:0.039114391803741454
step 21/275, epoch 200/301 --> loss:0.04404581785202026
step 31/275, epoch 200/301 --> loss:0.03957086801528931
step 41/275, epoch 200/301 --> loss:0.04017242193222046
step 51/275, epoch 200/301 --> loss:0.039483296871185306
step 61/275, epoch 200/301 --> loss:0.03990638256072998
step 71/275, epoch 200/301 --> loss:0.04079931974411011
step 81/275, epoch 200/301 --> loss:0.03400332927703857
step 91/275, epoch 200/301 --> loss:0.038359814882278444
step 101/275, epoch 200/301 --> loss:0.03946384191513062
step 111/275, epoch 200/301 --> loss:0.036824315786361694
step 121/275, epoch 200/301 --> loss:0.04645099639892578
step 131/275, epoch 200/301 --> loss:0.04023428559303284
step 141/275, epoch 200/301 --> loss:0.04059751033782959
step 151/275, epoch 200/301 --> loss:0.03997235894203186
step 161/275, epoch 200/301 --> loss:0.03783378005027771
step 171/275, epoch 200/301 --> loss:0.0395632803440094
step 181/275, epoch 200/301 --> loss:0.046153795719146726
step 191/275, epoch 200/301 --> loss:0.04112089872360229
step 201/275, epoch 200/301 --> loss:0.04171098470687866
step 211/275, epoch 200/301 --> loss:0.03543099164962769
step 221/275, epoch 200/301 --> loss:0.036078423261642456
step 231/275, epoch 200/301 --> loss:0.038110661506652835
step 241/275, epoch 200/301 --> loss:0.04066264629364014
step 251/275, epoch 200/301 --> loss:0.04251086711883545
step 261/275, epoch 200/301 --> loss:0.03766602277755737
step 271/275, epoch 200/301 --> loss:0.03624563813209534
step 11/275, epoch 201/301 --> loss:0.03869282603263855
step 21/275, epoch 201/301 --> loss:0.04218143820762634
step 31/275, epoch 201/301 --> loss:0.04422106146812439
step 41/275, epoch 201/301 --> loss:0.039921528100967406
step 51/275, epoch 201/301 --> loss:0.04230866432189941
step 61/275, epoch 201/301 --> loss:0.03918030858039856
step 71/275, epoch 201/301 --> loss:0.043362957239151
step 81/275, epoch 201/301 --> loss:0.04075174927711487
step 91/275, epoch 201/301 --> loss:0.045133382081985474
step 101/275, epoch 201/301 --> loss:0.04303296208381653
step 111/275, epoch 201/301 --> loss:0.03323588967323303
step 121/275, epoch 201/301 --> loss:0.036736345291137694
step 131/275, epoch 201/301 --> loss:0.038296091556549075
step 141/275, epoch 201/301 --> loss:0.03877774477005005
step 151/275, epoch 201/301 --> loss:0.03614557385444641
step 161/275, epoch 201/301 --> loss:0.03299647569656372
step 171/275, epoch 201/301 --> loss:0.033293575048446655
step 181/275, epoch 201/301 --> loss:0.041114038228988646
step 191/275, epoch 201/301 --> loss:0.05513868927955627
step 201/275, epoch 201/301 --> loss:0.03821685314178467
step 211/275, epoch 201/301 --> loss:0.040782076120376584
step 221/275, epoch 201/301 --> loss:0.0444369912147522
step 231/275, epoch 201/301 --> loss:0.03522641062736511
step 241/275, epoch 201/301 --> loss:0.03630152940750122
step 251/275, epoch 201/301 --> loss:0.02831876277923584
step 261/275, epoch 201/301 --> loss:0.038477152585983276
step 271/275, epoch 201/301 --> loss:0.04014790654182434
########## train dataset ##########
PLout index:  2
acc -->  [96.49701909026676]
F1 -->  {'F1': [0.9578177447645411], 'precision': [0.9534886871347673], 'recall': [0.9621963827345533]}
########## eval dataset ##########
 67%|██████▋   | 201/301 [19:12:23<10:52:04, 391.24s/it]PLout index:  2
acc -->  [92.89394905346121]
F1 -->  {'F1': [0.9163234259454338], 'precision': [0.9114834159189038], 'recall': [0.9212252183971259]}
 67%|██████▋   | 202/301 [19:17:42<10:09:57, 369.67s/it]step 11/275, epoch 202/301 --> loss:0.04181904792785644
step 21/275, epoch 202/301 --> loss:0.05544328093528748
step 31/275, epoch 202/301 --> loss:0.03631536960601807
step 41/275, epoch 202/301 --> loss:0.03184958100318909
step 51/275, epoch 202/301 --> loss:0.03673863410949707
step 61/275, epoch 202/301 --> loss:0.036935561895370485
step 71/275, epoch 202/301 --> loss:0.034202396869659424
step 81/275, epoch 202/301 --> loss:0.04042162299156189
step 91/275, epoch 202/301 --> loss:0.04065983891487122
step 101/275, epoch 202/301 --> loss:0.041149312257766725
step 111/275, epoch 202/301 --> loss:0.043991243839263915
step 121/275, epoch 202/301 --> loss:0.041641372442245486
step 131/275, epoch 202/301 --> loss:0.04067960977554321
step 141/275, epoch 202/301 --> loss:0.03967882394790649
step 151/275, epoch 202/301 --> loss:0.03318131566047668
step 161/275, epoch 202/301 --> loss:0.03352358341217041
step 171/275, epoch 202/301 --> loss:0.03557990193367004
step 181/275, epoch 202/301 --> loss:0.03733922839164734
step 191/275, epoch 202/301 --> loss:0.040403878688812254
step 201/275, epoch 202/301 --> loss:0.037405377626419066
step 211/275, epoch 202/301 --> loss:0.03805794715881348
step 221/275, epoch 202/301 --> loss:0.04649457335472107
step 231/275, epoch 202/301 --> loss:0.04233589768409729
step 241/275, epoch 202/301 --> loss:0.033421111106872556
step 251/275, epoch 202/301 --> loss:0.031040728092193604
step 261/275, epoch 202/301 --> loss:0.04584344029426575
step 271/275, epoch 202/301 --> loss:0.04290275573730469
 67%|██████▋   | 203/301 [19:23:01<9:39:07, 354.56s/it] step 11/275, epoch 203/301 --> loss:0.04203817844390869
step 21/275, epoch 203/301 --> loss:0.046673929691314696
step 31/275, epoch 203/301 --> loss:0.03355668187141418
step 41/275, epoch 203/301 --> loss:0.04889406561851502
step 51/275, epoch 203/301 --> loss:0.041931760311126706
step 61/275, epoch 203/301 --> loss:0.03722879886627197
step 71/275, epoch 203/301 --> loss:0.03464975357055664
step 81/275, epoch 203/301 --> loss:0.03669174909591675
step 91/275, epoch 203/301 --> loss:0.03141096234321594
step 101/275, epoch 203/301 --> loss:0.031303679943084715
step 111/275, epoch 203/301 --> loss:0.036975753307342527
step 121/275, epoch 203/301 --> loss:0.035208004713058474
step 131/275, epoch 203/301 --> loss:0.03523339033126831
step 141/275, epoch 203/301 --> loss:0.03498506546020508
step 151/275, epoch 203/301 --> loss:0.04138883948326111
step 161/275, epoch 203/301 --> loss:0.03987874984741211
step 171/275, epoch 203/301 --> loss:0.03917272090911865
step 181/275, epoch 203/301 --> loss:0.03259645104408264
step 191/275, epoch 203/301 --> loss:0.036109638214111325
step 201/275, epoch 203/301 --> loss:0.04044645428657532
step 211/275, epoch 203/301 --> loss:0.0346718430519104
step 221/275, epoch 203/301 --> loss:0.03721410632133484
step 231/275, epoch 203/301 --> loss:0.03545824885368347
step 241/275, epoch 203/301 --> loss:0.04071717262268067
step 251/275, epoch 203/301 --> loss:0.03465940356254578
step 261/275, epoch 203/301 --> loss:0.038070154190063474
step 271/275, epoch 203/301 --> loss:0.03452034592628479
 68%|██████▊   | 204/301 [19:28:21<9:16:17, 344.09s/it]step 11/275, epoch 204/301 --> loss:0.04779313206672668
step 21/275, epoch 204/301 --> loss:0.047715109586715695
step 31/275, epoch 204/301 --> loss:0.034878474473953244
step 41/275, epoch 204/301 --> loss:0.03802338242530823
step 51/275, epoch 204/301 --> loss:0.036756080389022824
step 61/275, epoch 204/301 --> loss:0.03511267304420471
step 71/275, epoch 204/301 --> loss:0.04045053124427796
step 81/275, epoch 204/301 --> loss:0.04361993074417114
step 91/275, epoch 204/301 --> loss:0.0472206175327301
step 101/275, epoch 204/301 --> loss:0.042330878973007205
step 111/275, epoch 204/301 --> loss:0.03380587100982666
step 121/275, epoch 204/301 --> loss:0.03232796192169189
step 131/275, epoch 204/301 --> loss:0.040771639347076415
step 141/275, epoch 204/301 --> loss:0.035205841064453125
step 151/275, epoch 204/301 --> loss:0.03370187282562256
step 161/275, epoch 204/301 --> loss:0.04286739230155945
step 171/275, epoch 204/301 --> loss:0.03900461792945862
step 181/275, epoch 204/301 --> loss:0.034773868322372434
step 191/275, epoch 204/301 --> loss:0.04199396371841431
step 201/275, epoch 204/301 --> loss:0.038191020488739014
step 211/275, epoch 204/301 --> loss:0.04063981771469116
step 221/275, epoch 204/301 --> loss:0.037495511770248416
step 231/275, epoch 204/301 --> loss:0.03541396856307984
step 241/275, epoch 204/301 --> loss:0.037694907188415526
step 251/275, epoch 204/301 --> loss:0.03344035744667053
step 261/275, epoch 204/301 --> loss:0.0331247627735138
step 271/275, epoch 204/301 --> loss:0.028751230239868163
 68%|██████▊   | 205/301 [19:33:41<8:58:58, 336.86s/it]step 11/275, epoch 205/301 --> loss:0.03512800335884094
step 21/275, epoch 205/301 --> loss:0.03037211298942566
step 31/275, epoch 205/301 --> loss:0.03723100423812866
step 41/275, epoch 205/301 --> loss:0.03640703558921814
step 51/275, epoch 205/301 --> loss:0.04262073636054993
step 61/275, epoch 205/301 --> loss:0.032525825500488284
step 71/275, epoch 205/301 --> loss:0.03230202794075012
step 81/275, epoch 205/301 --> loss:0.03339650630950928
step 91/275, epoch 205/301 --> loss:0.035507142543792725
step 101/275, epoch 205/301 --> loss:0.03323986530303955
step 111/275, epoch 205/301 --> loss:0.0418715238571167
step 121/275, epoch 205/301 --> loss:0.027294766902923585
step 131/275, epoch 205/301 --> loss:0.05103398561477661
step 141/275, epoch 205/301 --> loss:0.04153985381126404
step 151/275, epoch 205/301 --> loss:0.04741007685661316
step 161/275, epoch 205/301 --> loss:0.03726634383201599
step 171/275, epoch 205/301 --> loss:0.04314305186271668
step 181/275, epoch 205/301 --> loss:0.03639405369758606
step 191/275, epoch 205/301 --> loss:0.04022133946418762
step 201/275, epoch 205/301 --> loss:0.036089980602264406
step 211/275, epoch 205/301 --> loss:0.03950604200363159
step 221/275, epoch 205/301 --> loss:0.03623365163803101
step 231/275, epoch 205/301 --> loss:0.03403775691986084
step 241/275, epoch 205/301 --> loss:0.038547170162200925
step 251/275, epoch 205/301 --> loss:0.03458423018455505
step 261/275, epoch 205/301 --> loss:0.0402277410030365
step 271/275, epoch 205/301 --> loss:0.03767115473747253
 68%|██████▊   | 206/301 [19:39:01<8:45:19, 331.78s/it]step 11/275, epoch 206/301 --> loss:0.04301682710647583
step 21/275, epoch 206/301 --> loss:0.03471779823303223
step 31/275, epoch 206/301 --> loss:0.03801300525665283
step 41/275, epoch 206/301 --> loss:0.040922689437866214
step 51/275, epoch 206/301 --> loss:0.03568238615989685
step 61/275, epoch 206/301 --> loss:0.03498395085334778
step 71/275, epoch 206/301 --> loss:0.03871510028839111
step 81/275, epoch 206/301 --> loss:0.03883515596389771
step 91/275, epoch 206/301 --> loss:0.0426760733127594
step 101/275, epoch 206/301 --> loss:0.049401456117630006
step 111/275, epoch 206/301 --> loss:0.04786894917488098
step 121/275, epoch 206/301 --> loss:0.04753631353378296
step 131/275, epoch 206/301 --> loss:0.043398100137710574
step 141/275, epoch 206/301 --> loss:0.04092623591423035
step 151/275, epoch 206/301 --> loss:0.04032296538352966
step 161/275, epoch 206/301 --> loss:0.0412580132484436
step 171/275, epoch 206/301 --> loss:0.03495497107505798
step 181/275, epoch 206/301 --> loss:0.03846384882926941
step 191/275, epoch 206/301 --> loss:0.03623130917549133
step 201/275, epoch 206/301 --> loss:0.03393264412879944
step 211/275, epoch 206/301 --> loss:0.034604811668396
step 221/275, epoch 206/301 --> loss:0.03465020060539246
step 231/275, epoch 206/301 --> loss:0.046582764387130736
step 241/275, epoch 206/301 --> loss:0.04213069081306457
step 251/275, epoch 206/301 --> loss:0.040000426769256595
step 261/275, epoch 206/301 --> loss:0.03882684111595154
step 271/275, epoch 206/301 --> loss:0.03855069875717163
 69%|██████▉   | 207/301 [19:44:21<8:34:19, 328.30s/it]step 11/275, epoch 207/301 --> loss:0.042254638671875
step 21/275, epoch 207/301 --> loss:0.037199157476425174
step 31/275, epoch 207/301 --> loss:0.039742910861968996
step 41/275, epoch 207/301 --> loss:0.03423477411270141
step 51/275, epoch 207/301 --> loss:0.03688921332359314
step 61/275, epoch 207/301 --> loss:0.034215062856674194
step 71/275, epoch 207/301 --> loss:0.0393584132194519
step 81/275, epoch 207/301 --> loss:0.03371180891990662
step 91/275, epoch 207/301 --> loss:0.03231953382492066
step 101/275, epoch 207/301 --> loss:0.04301931858062744
step 111/275, epoch 207/301 --> loss:0.03478526473045349
step 121/275, epoch 207/301 --> loss:0.038639414310455325
step 131/275, epoch 207/301 --> loss:0.041329222917556765
step 141/275, epoch 207/301 --> loss:0.034955036640167234
step 151/275, epoch 207/301 --> loss:0.028378260135650635
step 161/275, epoch 207/301 --> loss:0.03781755566596985
step 171/275, epoch 207/301 --> loss:0.03681456446647644
step 181/275, epoch 207/301 --> loss:0.03685149550437927
step 191/275, epoch 207/301 --> loss:0.033683913946151736
step 201/275, epoch 207/301 --> loss:0.04863065481185913
step 211/275, epoch 207/301 --> loss:0.04611470103263855
step 221/275, epoch 207/301 --> loss:0.033144235610961914
step 231/275, epoch 207/301 --> loss:0.03789636492729187
step 241/275, epoch 207/301 --> loss:0.0403017520904541
step 251/275, epoch 207/301 --> loss:0.03721569180488586
step 261/275, epoch 207/301 --> loss:0.04382261037826538
step 271/275, epoch 207/301 --> loss:0.03230109214782715
 69%|██████▉   | 208/301 [19:49:40<8:24:20, 325.39s/it]step 11/275, epoch 208/301 --> loss:0.0377726674079895
step 21/275, epoch 208/301 --> loss:0.038621711730957034
step 31/275, epoch 208/301 --> loss:0.03560594320297241
step 41/275, epoch 208/301 --> loss:0.03577035665512085
step 51/275, epoch 208/301 --> loss:0.04219440221786499
step 61/275, epoch 208/301 --> loss:0.04874478578567505
step 71/275, epoch 208/301 --> loss:0.0471665620803833
step 81/275, epoch 208/301 --> loss:0.04026140570640564
step 91/275, epoch 208/301 --> loss:0.0370183527469635
step 101/275, epoch 208/301 --> loss:0.03279120922088623
step 111/275, epoch 208/301 --> loss:0.04012973308563232
step 121/275, epoch 208/301 --> loss:0.040833449363708495
step 131/275, epoch 208/301 --> loss:0.03876917958259583
step 141/275, epoch 208/301 --> loss:0.035709339380264285
step 151/275, epoch 208/301 --> loss:0.03759893774986267
step 161/275, epoch 208/301 --> loss:0.0426383912563324
step 171/275, epoch 208/301 --> loss:0.03866080641746521
step 181/275, epoch 208/301 --> loss:0.04845594167709351
step 191/275, epoch 208/301 --> loss:0.039243435859680174
step 201/275, epoch 208/301 --> loss:0.042067742347717284
step 211/275, epoch 208/301 --> loss:0.04367492794990539
step 221/275, epoch 208/301 --> loss:0.031678348779678345
step 231/275, epoch 208/301 --> loss:0.04032663106918335
step 241/275, epoch 208/301 --> loss:0.03459469079971313
step 251/275, epoch 208/301 --> loss:0.03144220113754272
step 261/275, epoch 208/301 --> loss:0.03262161016464234
step 271/275, epoch 208/301 --> loss:0.03528055548667908
 69%|██████▉   | 209/301 [19:54:56<8:14:39, 322.61s/it]step 11/275, epoch 209/301 --> loss:0.033099550008773806
step 21/275, epoch 209/301 --> loss:0.03545088171958923
step 31/275, epoch 209/301 --> loss:0.034538263082504274
step 41/275, epoch 209/301 --> loss:0.029857701063156127
step 51/275, epoch 209/301 --> loss:0.03722301721572876
step 61/275, epoch 209/301 --> loss:0.0298187255859375
step 71/275, epoch 209/301 --> loss:0.03492571115493774
step 81/275, epoch 209/301 --> loss:0.04211800694465637
step 91/275, epoch 209/301 --> loss:0.04176541566848755
step 101/275, epoch 209/301 --> loss:0.039754855632781985
step 111/275, epoch 209/301 --> loss:0.04627915620803833
step 121/275, epoch 209/301 --> loss:0.040120136737823484
step 131/275, epoch 209/301 --> loss:0.03544941544532776
step 141/275, epoch 209/301 --> loss:0.03646245002746582
step 151/275, epoch 209/301 --> loss:0.03701870441436768
step 161/275, epoch 209/301 --> loss:0.038067865371704104
step 171/275, epoch 209/301 --> loss:0.03436077237129211
step 181/275, epoch 209/301 --> loss:0.03355390429496765
step 191/275, epoch 209/301 --> loss:0.03277077674865723
step 201/275, epoch 209/301 --> loss:0.03299664855003357
step 211/275, epoch 209/301 --> loss:0.03344125151634216
step 221/275, epoch 209/301 --> loss:0.0370657742023468
step 231/275, epoch 209/301 --> loss:0.04622244834899902
step 241/275, epoch 209/301 --> loss:0.03862888216972351
step 251/275, epoch 209/301 --> loss:0.03782185912132263
step 261/275, epoch 209/301 --> loss:0.039997398853302
step 271/275, epoch 209/301 --> loss:0.03560658693313599
 70%|██████▉   | 210/301 [20:00:14<8:07:15, 321.27s/it]step 11/275, epoch 210/301 --> loss:0.03767402172088623
step 21/275, epoch 210/301 --> loss:0.04490804672241211
step 31/275, epoch 210/301 --> loss:0.030838006734848024
step 41/275, epoch 210/301 --> loss:0.04733313918113709
step 51/275, epoch 210/301 --> loss:0.034771430492401126
step 61/275, epoch 210/301 --> loss:0.04055744409561157
step 71/275, epoch 210/301 --> loss:0.03877878189086914
step 81/275, epoch 210/301 --> loss:0.03688896298408508
step 91/275, epoch 210/301 --> loss:0.032379013299942014
step 101/275, epoch 210/301 --> loss:0.03156549334526062
step 111/275, epoch 210/301 --> loss:0.03496943116188049
step 121/275, epoch 210/301 --> loss:0.02716064453125
step 131/275, epoch 210/301 --> loss:0.035823863744735715
step 141/275, epoch 210/301 --> loss:0.030052322149276733
step 151/275, epoch 210/301 --> loss:0.03321223855018616
step 161/275, epoch 210/301 --> loss:0.029828989505767824
step 171/275, epoch 210/301 --> loss:0.03924689888954162
step 181/275, epoch 210/301 --> loss:0.03234880566596985
step 191/275, epoch 210/301 --> loss:0.030227893590927125
step 201/275, epoch 210/301 --> loss:0.030627280473709106
step 211/275, epoch 210/301 --> loss:0.037585437297821045
step 221/275, epoch 210/301 --> loss:0.03925923109054565
step 231/275, epoch 210/301 --> loss:0.035765069723129275
step 241/275, epoch 210/301 --> loss:0.03457383513450622
step 251/275, epoch 210/301 --> loss:0.04204229116439819
step 261/275, epoch 210/301 --> loss:0.03734527230262756
step 271/275, epoch 210/301 --> loss:0.038869422674179074
step 11/275, epoch 211/301 --> loss:0.03403152227401733
step 21/275, epoch 211/301 --> loss:0.03663150668144226
step 31/275, epoch 211/301 --> loss:0.03484618067741394
step 41/275, epoch 211/301 --> loss:0.03484761714935303
step 51/275, epoch 211/301 --> loss:0.044969063997268674
step 61/275, epoch 211/301 --> loss:0.03829184174537659
step 71/275, epoch 211/301 --> loss:0.040505635738372806
step 81/275, epoch 211/301 --> loss:0.04170103073120117
step 91/275, epoch 211/301 --> loss:0.04201996922492981
step 101/275, epoch 211/301 --> loss:0.032419657707214354
step 111/275, epoch 211/301 --> loss:0.03447663187980652
step 121/275, epoch 211/301 --> loss:0.031916916370391846
step 131/275, epoch 211/301 --> loss:0.03016672730445862
step 141/275, epoch 211/301 --> loss:0.04082695841789245
step 151/275, epoch 211/301 --> loss:0.03090413808822632
step 161/275, epoch 211/301 --> loss:0.039878731966018675
step 171/275, epoch 211/301 --> loss:0.03770869970321655
step 181/275, epoch 211/301 --> loss:0.03345017433166504
step 191/275, epoch 211/301 --> loss:0.033793747425079346
step 201/275, epoch 211/301 --> loss:0.035127300024032596
step 211/275, epoch 211/301 --> loss:0.040019935369491576
step 221/275, epoch 211/301 --> loss:0.03181967735290527
step 231/275, epoch 211/301 --> loss:0.04186549186706543
step 241/275, epoch 211/301 --> loss:0.036381834745407106
step 251/275, epoch 211/301 --> loss:0.034770858287811277
step 261/275, epoch 211/301 --> loss:0.04696140885353088
step 271/275, epoch 211/301 --> loss:0.0321125328540802
########## train dataset ##########
PLout index:  2
acc -->  [96.62740744367322]
F1 -->  {'F1': [0.959666865803164], 'precision': [0.948864603553574], 'recall': [0.9707281453881458]}
########## eval dataset ##########
 70%|███████   | 211/301 [20:09:32<9:48:29, 392.33s/it]PLout index:  2
acc -->  [92.73418924782817]
F1 -->  {'F1': [0.9154394549615147], 'precision': [0.9002226227250886], 'recall': [0.9311899089733555]}
 70%|███████   | 212/301 [20:14:53<9:10:01, 370.81s/it]step 11/275, epoch 212/301 --> loss:0.04728806018829346
step 21/275, epoch 212/301 --> loss:0.04335172176361084
step 31/275, epoch 212/301 --> loss:0.04517861008644104
step 41/275, epoch 212/301 --> loss:0.0431918203830719
step 51/275, epoch 212/301 --> loss:0.04086401462554932
step 61/275, epoch 212/301 --> loss:0.03553741574287415
step 71/275, epoch 212/301 --> loss:0.04101477265357971
step 81/275, epoch 212/301 --> loss:0.036753928661346434
step 91/275, epoch 212/301 --> loss:0.03596408367156982
step 101/275, epoch 212/301 --> loss:0.03603433966636658
step 111/275, epoch 212/301 --> loss:0.03330389857292175
step 121/275, epoch 212/301 --> loss:0.03664093017578125
step 131/275, epoch 212/301 --> loss:0.04086981415748596
step 141/275, epoch 212/301 --> loss:0.038309246301651
step 151/275, epoch 212/301 --> loss:0.03405596017837524
step 161/275, epoch 212/301 --> loss:0.03815818428993225
step 171/275, epoch 212/301 --> loss:0.03523875474929809
step 181/275, epoch 212/301 --> loss:0.03448856472969055
step 191/275, epoch 212/301 --> loss:0.03503490090370178
step 201/275, epoch 212/301 --> loss:0.03698602318763733
step 211/275, epoch 212/301 --> loss:0.03153086900711059
step 221/275, epoch 212/301 --> loss:0.037300330400466916
step 231/275, epoch 212/301 --> loss:0.037071233987808226
step 241/275, epoch 212/301 --> loss:0.04070903062820434
step 251/275, epoch 212/301 --> loss:0.03524693846702576
step 261/275, epoch 212/301 --> loss:0.035367447137832644
step 271/275, epoch 212/301 --> loss:0.04469859004020691
 71%|███████   | 213/301 [20:20:12<8:41:07, 355.31s/it]step 11/275, epoch 213/301 --> loss:0.03404220938682556
step 21/275, epoch 213/301 --> loss:0.03332154750823975
step 31/275, epoch 213/301 --> loss:0.032179737091064455
step 41/275, epoch 213/301 --> loss:0.03500680923461914
step 51/275, epoch 213/301 --> loss:0.03537528514862061
step 61/275, epoch 213/301 --> loss:0.030698156356811522
step 71/275, epoch 213/301 --> loss:0.03722316026687622
step 81/275, epoch 213/301 --> loss:0.035733258724212645
step 91/275, epoch 213/301 --> loss:0.033055686950683595
step 101/275, epoch 213/301 --> loss:0.041366207599639895
step 111/275, epoch 213/301 --> loss:0.030858057737350463
step 121/275, epoch 213/301 --> loss:0.03462930321693421
step 131/275, epoch 213/301 --> loss:0.03835030198097229
step 141/275, epoch 213/301 --> loss:0.03216952681541443
step 151/275, epoch 213/301 --> loss:0.0347201406955719
step 161/275, epoch 213/301 --> loss:0.027200078964233397
step 171/275, epoch 213/301 --> loss:0.039847451448440555
step 181/275, epoch 213/301 --> loss:0.039396119117736814
step 191/275, epoch 213/301 --> loss:0.043360406160354616
step 201/275, epoch 213/301 --> loss:0.03388078212738037
step 211/275, epoch 213/301 --> loss:0.04125073552131653
step 221/275, epoch 213/301 --> loss:0.036852318048477176
step 231/275, epoch 213/301 --> loss:0.03624218702316284
step 241/275, epoch 213/301 --> loss:0.031541687250137326
step 251/275, epoch 213/301 --> loss:0.03435055017471313
step 261/275, epoch 213/301 --> loss:0.0292397141456604
step 271/275, epoch 213/301 --> loss:0.03326361179351807
 71%|███████   | 214/301 [20:25:28<8:18:13, 343.60s/it]step 11/275, epoch 214/301 --> loss:0.028578323125839234
step 21/275, epoch 214/301 --> loss:0.04225670099258423
step 31/275, epoch 214/301 --> loss:0.03611091375350952
step 41/275, epoch 214/301 --> loss:0.03714125156402588
step 51/275, epoch 214/301 --> loss:0.036765259504318235
step 61/275, epoch 214/301 --> loss:0.03429546356201172
step 71/275, epoch 214/301 --> loss:0.02727823853492737
step 81/275, epoch 214/301 --> loss:0.030438327789306642
step 91/275, epoch 214/301 --> loss:0.0327955961227417
step 101/275, epoch 214/301 --> loss:0.03863179683685303
step 111/275, epoch 214/301 --> loss:0.036446613073348996
step 121/275, epoch 214/301 --> loss:0.03638371825218201
step 131/275, epoch 214/301 --> loss:0.044914865493774415
step 141/275, epoch 214/301 --> loss:0.03619831204414368
step 151/275, epoch 214/301 --> loss:0.04090850353240967
step 161/275, epoch 214/301 --> loss:0.041775500774383544
step 171/275, epoch 214/301 --> loss:0.028414279222488403
step 181/275, epoch 214/301 --> loss:0.036826276779174806
step 191/275, epoch 214/301 --> loss:0.034092003107070924
step 201/275, epoch 214/301 --> loss:0.03587769865989685
step 211/275, epoch 214/301 --> loss:0.03193694949150085
step 221/275, epoch 214/301 --> loss:0.0317438542842865
step 231/275, epoch 214/301 --> loss:0.043859124183654785
step 241/275, epoch 214/301 --> loss:0.03708250522613525
step 251/275, epoch 214/301 --> loss:0.03619778752326965
step 261/275, epoch 214/301 --> loss:0.0354722797870636
step 271/275, epoch 214/301 --> loss:0.0400700569152832
 71%|███████▏  | 215/301 [20:30:44<8:00:29, 335.23s/it]step 11/275, epoch 215/301 --> loss:0.0481478214263916
step 21/275, epoch 215/301 --> loss:0.03949383497238159
step 31/275, epoch 215/301 --> loss:0.040020203590393065
step 41/275, epoch 215/301 --> loss:0.03526617288589477
step 51/275, epoch 215/301 --> loss:0.02952592968940735
step 61/275, epoch 215/301 --> loss:0.028679811954498292
step 71/275, epoch 215/301 --> loss:0.035364949703216554
step 81/275, epoch 215/301 --> loss:0.03392496109008789
step 91/275, epoch 215/301 --> loss:0.03601818680763245
step 101/275, epoch 215/301 --> loss:0.03174648880958557
step 111/275, epoch 215/301 --> loss:0.038125079870223996
step 121/275, epoch 215/301 --> loss:0.03415350317955017
step 131/275, epoch 215/301 --> loss:0.03280762434005737
step 141/275, epoch 215/301 --> loss:0.036084729433059695
step 151/275, epoch 215/301 --> loss:0.034344989061355594
step 161/275, epoch 215/301 --> loss:0.03796077966690063
step 171/275, epoch 215/301 --> loss:0.035484147071838376
step 181/275, epoch 215/301 --> loss:0.031372356414794925
step 191/275, epoch 215/301 --> loss:0.041553032398223874
step 201/275, epoch 215/301 --> loss:0.03275505900382995
step 211/275, epoch 215/301 --> loss:0.033475661277771
step 221/275, epoch 215/301 --> loss:0.03405618667602539
step 231/275, epoch 215/301 --> loss:0.039108937978744505
step 241/275, epoch 215/301 --> loss:0.04085404872894287
step 251/275, epoch 215/301 --> loss:0.03141158223152161
step 261/275, epoch 215/301 --> loss:0.0331899344921112
step 271/275, epoch 215/301 --> loss:0.03140777349472046
 72%|███████▏  | 216/301 [20:36:00<7:46:41, 329.43s/it]step 11/275, epoch 216/301 --> loss:0.04159584641456604
step 21/275, epoch 216/301 --> loss:0.04429013729095459
step 31/275, epoch 216/301 --> loss:0.035303181409835814
step 41/275, epoch 216/301 --> loss:0.037215524911880495
step 51/275, epoch 216/301 --> loss:0.03921722173690796
step 61/275, epoch 216/301 --> loss:0.034846270084381105
step 71/275, epoch 216/301 --> loss:0.03352701663970947
step 81/275, epoch 216/301 --> loss:0.03514454960823059
step 91/275, epoch 216/301 --> loss:0.035813266038894655
step 101/275, epoch 216/301 --> loss:0.04135395884513855
step 111/275, epoch 216/301 --> loss:0.03192998170852661
step 121/275, epoch 216/301 --> loss:0.04037004113197327
step 131/275, epoch 216/301 --> loss:0.03718424439430237
step 141/275, epoch 216/301 --> loss:0.04255763292312622
step 151/275, epoch 216/301 --> loss:0.03764599561691284
step 161/275, epoch 216/301 --> loss:0.03913601636886597
step 171/275, epoch 216/301 --> loss:0.03255588412284851
step 181/275, epoch 216/301 --> loss:0.030605316162109375
step 191/275, epoch 216/301 --> loss:0.030640560388565063
step 201/275, epoch 216/301 --> loss:0.026420557498931886
step 211/275, epoch 216/301 --> loss:0.03904378414154053
step 221/275, epoch 216/301 --> loss:0.03210940957069397
step 231/275, epoch 216/301 --> loss:0.03376311659812927
step 241/275, epoch 216/301 --> loss:0.03766693472862244
step 251/275, epoch 216/301 --> loss:0.03616442084312439
step 261/275, epoch 216/301 --> loss:0.0378709077835083
step 271/275, epoch 216/301 --> loss:0.03333777189254761
