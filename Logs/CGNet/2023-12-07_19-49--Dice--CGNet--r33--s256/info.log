##########Config##########
{'device': 'cuda:0', 'class_nums': 2, 'data_path': 'Datasets/WHU-BCD', 'image_size': 256, 'num_parallel_workers': 4, 'batch_size': 64, 'input_dim': 6, 'seed': 33, 'pretrained': False, 'resume': '', 'eval_epochs': 10, 'start_eval_epochs': 0, 'eval_traindata': True, 'epoch_size': 501, 'loss_monitor_step': 50, 'metrics_List': ['acc', 'F1'], 'save_metrics_List': ['F1'], 'save_model_path': 'Models/CGNet', 'log_path': 'Logs/CGNet', 'lr_init': 0.0005, 'lr_max': 0.0005, 'lr_end': 5e-05, 'warmup_epochs': 0}

##########Network##########
Backbone(
  (initial_layer): CGBlock(
    (conv1): Conv2d(6, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (context_module): CGBlock(
    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (multi_scale_module): CGBlock(
    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (final_layer): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))
  (softmax): Softmax(dim=1)
)

##########Training##########
step 51/84, epoch 1/501 --> loss:0.8796952283382415

##########train dataset##########
acc--> [85.07251889686641]
F1--> {'F1': [0.3435639020063835], 'precision': [0.21132169396838626], 'recall': [0.9181387630833893]}
##########eval dataset##########
acc--> [85.1867315337357]
F1--> {'F1': [0.34053687142404293], 'precision': [0.2089967263522206], 'recall': [0.9188954059424549]}
save model!
step 51/84, epoch 2/501 --> loss:0.8440546524524689
step 51/84, epoch 3/501 --> loss:0.8433491086959839
step 51/84, epoch 4/501 --> loss:0.8434528660774231
step 51/84, epoch 5/501 --> loss:0.840632631778717
step 51/84, epoch 6/501 --> loss:0.8359504401683807
step 51/84, epoch 7/501 --> loss:0.8379735374450683
step 51/84, epoch 8/501 --> loss:0.8404895377159118
step 51/84, epoch 9/501 --> loss:0.8408083510398865
step 51/84, epoch 10/501 --> loss:0.8303193211555481
step 51/84, epoch 11/501 --> loss:0.830875928401947

##########train dataset##########
acc--> [97.19691467857011]
F1--> {'F1': [0.7065679795167666], 'precision': [0.6369910298227838], 'recall': [0.7932205885511626]}
##########eval dataset##########
acc--> [97.28948838441053]
F1--> {'F1': [0.7090888223146754], 'precision': [0.6408099048731427], 'recall': [0.7936657432303224]}
save model!
step 51/84, epoch 12/501 --> loss:0.8382118654251098
step 51/84, epoch 13/501 --> loss:0.8368257260322571
step 51/84, epoch 14/501 --> loss:0.8346287512779236
step 51/84, epoch 15/501 --> loss:0.8328600907325745
step 51/84, epoch 16/501 --> loss:0.8402082979679107
step 51/84, epoch 17/501 --> loss:0.8405554795265198
step 51/84, epoch 18/501 --> loss:0.8351450979709625
step 51/84, epoch 19/501 --> loss:0.8333129799365997
step 51/84, epoch 20/501 --> loss:0.8387322628498077
step 51/84, epoch 21/501 --> loss:0.8384255111217499

##########train dataset##########
acc--> [95.08373630953939]
F1--> {'F1': [0.6102380892211321], 'precision': [0.460427926607418], 'recall': [0.9045740234726106]}
##########eval dataset##########
acc--> [95.21070398578692]
F1--> {'F1': [0.6102194326459662], 'precision': [0.4614161237955833], 'recall': [0.9007026392053904]}
step 51/84, epoch 22/501 --> loss:0.8377429378032685
step 51/84, epoch 23/501 --> loss:0.8335327434539795
step 51/84, epoch 24/501 --> loss:0.8408358836174011
step 51/84, epoch 25/501 --> loss:0.8287038147449494
step 51/84, epoch 26/501 --> loss:0.8427046477794647
step 51/84, epoch 27/501 --> loss:0.8269642353057861
step 51/84, epoch 28/501 --> loss:0.8363537979125977
step 51/84, epoch 29/501 --> loss:0.8336087703704834
step 51/84, epoch 30/501 --> loss:0.8370367515087128
step 51/84, epoch 31/501 --> loss:0.836340411901474

##########train dataset##########
acc--> [97.3475324289575]
F1--> {'F1': [0.7205728758436718], 'precision': [0.6529437378593281], 'recall': [0.8038425024468276]}
##########eval dataset##########
acc--> [97.40126268548056]
F1--> {'F1': [0.7204197401022836], 'precision': [0.6523059589893275], 'recall': [0.8044292810423654]}
save model!
step 51/84, epoch 32/501 --> loss:0.8312817549705506
step 51/84, epoch 33/501 --> loss:0.8383405494689942
step 51/84, epoch 34/501 --> loss:0.8258412826061249
step 51/84, epoch 35/501 --> loss:0.8397649002075195
step 51/84, epoch 36/501 --> loss:0.8329662168025971
step 51/84, epoch 37/501 --> loss:0.8388598155975342
step 51/84, epoch 38/501 --> loss:0.8382536959648133
step 51/84, epoch 39/501 --> loss:0.8354312324523926
step 51/84, epoch 40/501 --> loss:0.8297619128227234
step 51/84, epoch 41/501 --> loss:0.8349520075321197

##########train dataset##########
acc--> [94.51074646705268]
F1--> {'F1': [0.5844310217477551], 'precision': [0.43106486424064056], 'recall': [0.9072189291817001]}
##########eval dataset##########
acc--> [94.7864662630914]
F1--> {'F1': [0.5904442664817642], 'precision': [0.4386508306015072], 'recall': [0.9029042901629664]}
step 51/84, epoch 42/501 --> loss:0.835944801568985
step 51/84, epoch 43/501 --> loss:0.825635496377945
step 51/84, epoch 44/501 --> loss:0.8378127944469452
step 51/84, epoch 45/501 --> loss:0.8325391411781311
step 51/84, epoch 46/501 --> loss:0.8330371415615082
step 51/84, epoch 47/501 --> loss:0.8388693249225616
step 51/84, epoch 48/501 --> loss:0.8402812302112579
step 51/84, epoch 49/501 --> loss:0.8396981954574585
step 51/84, epoch 50/501 --> loss:0.8331410312652587
step 51/84, epoch 51/501 --> loss:0.8352030110359192

##########train dataset##########
acc--> [87.92614931464614]
F1--> {'F1': [0.3995326582333924], 'precision': [0.25338322861856005], 'recall': [0.9440947830711081]}
##########eval dataset##########
acc--> [88.22195698895203]
F1--> {'F1': [0.39762496079940707], 'precision': [0.2525828604711038], 'recall': [0.9339456603213973]}
step 51/84, epoch 52/501 --> loss:0.8303676247596741
step 51/84, epoch 53/501 --> loss:0.8320844197273254
step 51/84, epoch 54/501 --> loss:0.8314329791069031
step 51/84, epoch 55/501 --> loss:0.8367811787128449
step 51/84, epoch 56/501 --> loss:0.837979097366333
step 51/84, epoch 57/501 --> loss:0.8368104279041291
step 51/84, epoch 58/501 --> loss:0.8359113037586212
step 51/84, epoch 59/501 --> loss:0.8389329195022583
step 51/84, epoch 60/501 --> loss:0.8323638749122619
step 51/84, epoch 61/501 --> loss:0.8374146437644958

##########train dataset##########
acc--> [96.84160487858051]
F1--> {'F1': [0.7034920436983193], 'precision': [0.585683179522071], 'recall': [0.8806435367959913]}
##########eval dataset##########
acc--> [96.90732647218499]
F1--> {'F1': [0.7014891093301746], 'precision': [0.5862860084347883], 'recall': [0.8730528282356675]}
step 51/84, epoch 62/501 --> loss:0.8290816426277161
step 51/84, epoch 63/501 --> loss:0.8283272314071656
step 51/84, epoch 64/501 --> loss:0.8333356559276581
step 51/84, epoch 65/501 --> loss:0.8315262079238892
step 51/84, epoch 66/501 --> loss:0.8309833252429962
step 51/84, epoch 67/501 --> loss:0.8287852334976197
step 51/84, epoch 68/501 --> loss:0.8346515583992005
step 51/84, epoch 69/501 --> loss:0.8404735898971558
step 51/84, epoch 70/501 --> loss:0.8293008208274841
step 51/84, epoch 71/501 --> loss:0.8297426104545593

##########train dataset##########
acc--> [93.18278526875157]
F1--> {'F1': [0.5328037049926493], 'precision': [0.376053632217859], 'recall': [0.91365638144457]}
##########eval dataset##########
acc--> [93.22676571021871]
F1--> {'F1': [0.526127279840175], 'precision': [0.37114402149289283], 'recall': [0.9033751217757162]}
step 51/84, epoch 72/501 --> loss:0.8411701619625092
step 51/84, epoch 73/501 --> loss:0.8320686531066894
step 51/84, epoch 74/501 --> loss:0.8240703046321869
step 51/84, epoch 75/501 --> loss:0.8279408752918244
step 51/84, epoch 76/501 --> loss:0.8390553307533264
step 51/84, epoch 77/501 --> loss:0.8372217214107514
step 51/84, epoch 78/501 --> loss:0.8399142444133758
step 51/84, epoch 79/501 --> loss:0.8300955176353455
step 51/84, epoch 80/501 --> loss:0.8263185930252075
step 51/84, epoch 81/501 --> loss:0.8326166081428528

##########train dataset##########
acc--> [96.2552208287169]
F1--> {'F1': [0.677374365946483], 'precision': [0.5346760650309631], 'recall': [0.9239877039915472]}
##########eval dataset##########
acc--> [96.30981138267107]
F1--> {'F1': [0.6727182549597037], 'precision': [0.533186575226839], 'recall': [0.9111815291589078]}
step 51/84, epoch 82/501 --> loss:0.8376064765453338
step 51/84, epoch 83/501 --> loss:0.8307400679588318
step 51/84, epoch 84/501 --> loss:0.8264474689960479
step 51/84, epoch 85/501 --> loss:0.8342576670646668
step 51/84, epoch 86/501 --> loss:0.8419871306419373
step 51/84, epoch 87/501 --> loss:0.8364953792095184
step 51/84, epoch 88/501 --> loss:0.8303634715080261
step 51/84, epoch 89/501 --> loss:0.8286826539039612
step 51/84, epoch 90/501 --> loss:0.8326344203948974
step 51/84, epoch 91/501 --> loss:0.8309110844135285

##########train dataset##########
acc--> [95.77684520467993]
F1--> {'F1': [0.6511971571785811], 'precision': [0.5020085971211589], 'recall': [0.9265717616741298]}
##########eval dataset##########
acc--> [95.85591647463714]
F1--> {'F1': [0.647388784924843], 'precision': [0.5012005365651839], 'recall': [0.9139911237962981]}
step 51/84, epoch 92/501 --> loss:0.8266433966159821
step 51/84, epoch 93/501 --> loss:0.83621941447258
step 51/84, epoch 94/501 --> loss:0.8385287308692932
step 51/84, epoch 95/501 --> loss:0.835833728313446
step 51/84, epoch 96/501 --> loss:0.8327548480033875
step 51/84, epoch 97/501 --> loss:0.8235748136043548
step 51/84, epoch 98/501 --> loss:0.829901067018509
step 51/84, epoch 99/501 --> loss:0.8298461508750915
step 51/84, epoch 100/501 --> loss:0.8274772727489471
step 51/84, epoch 101/501 --> loss:0.8308271944522858

##########train dataset##########
acc--> [96.30229679618019]
F1--> {'F1': [0.6778901264007342], 'precision': [0.5385461039785999], 'recall': [0.9145289623152946]}
##########eval dataset##########
acc--> [96.28712411314153]
F1--> {'F1': [0.6685574687710909], 'precision': [0.5319198481235214], 'recall': [0.8996753410748469]}
step 51/84, epoch 102/501 --> loss:0.836882836818695
step 51/84, epoch 103/501 --> loss:0.8297314739227295
step 51/84, epoch 104/501 --> loss:0.8336523652076722
step 51/84, epoch 105/501 --> loss:0.8380611753463745
step 51/84, epoch 106/501 --> loss:0.837402446269989
step 51/84, epoch 107/501 --> loss:0.82602663397789
step 51/84, epoch 108/501 --> loss:0.833465791940689
step 51/84, epoch 109/501 --> loss:0.8288886415958404
step 51/84, epoch 110/501 --> loss:0.8267641735076904
step 51/84, epoch 111/501 --> loss:0.8302782452106476

##########train dataset##########
acc--> [96.78336001532857]
F1--> {'F1': [0.7100416146775854], 'precision': [0.5758935609548869], 'recall': [0.9256811617193126]}
##########eval dataset##########
acc--> [96.78591563840739]
F1--> {'F1': [0.700213412746614], 'precision': [0.5722830795251794], 'recall': [0.9018224679355785]}
step 51/84, epoch 112/501 --> loss:0.8302901148796081
step 51/84, epoch 113/501 --> loss:0.8263842451572418
step 51/84, epoch 114/501 --> loss:0.8351785087585449
step 51/84, epoch 115/501 --> loss:0.8255340015888214
step 51/84, epoch 116/501 --> loss:0.84281618475914
step 51/84, epoch 117/501 --> loss:0.8319621753692626
step 51/84, epoch 118/501 --> loss:0.8241333591938019
step 51/84, epoch 119/501 --> loss:0.8276310050487519
step 51/84, epoch 120/501 --> loss:0.8298502337932586
step 51/84, epoch 121/501 --> loss:0.8296904647350312

##########train dataset##########
acc--> [94.92702820258768]
F1--> {'F1': [0.6118151214351496], 'precision': [0.45358065451694407], 'recall': [0.9396214782097235]}
##########eval dataset##########
acc--> [94.91733207268135]
F1--> {'F1': [0.5997697736596236], 'precision': [0.44609706991018067], 'recall': [0.9149768873942454]}
step 51/84, epoch 122/501 --> loss:0.8369804847240448
step 51/84, epoch 123/501 --> loss:0.8304181575775147
step 51/84, epoch 124/501 --> loss:0.8305770349502564
step 51/84, epoch 125/501 --> loss:0.8295011174678802
step 51/84, epoch 126/501 --> loss:0.8322995293140412
step 51/84, epoch 127/501 --> loss:0.831743848323822
step 51/84, epoch 128/501 --> loss:0.833444619178772
step 51/84, epoch 129/501 --> loss:0.8341291284561158
step 51/84, epoch 130/501 --> loss:0.8304427516460419
step 51/84, epoch 131/501 --> loss:0.8299308788776397

##########train dataset##########
acc--> [96.82362187788993]
F1--> {'F1': [0.7026390962003645], 'precision': [0.5838853609206556], 'recall': [0.8820464704104571]}
##########eval dataset##########
acc--> [96.82158756338893]
F1--> {'F1': [0.6928862954990384], 'precision': [0.5795111931255045], 'recall': [0.8614271682335213]}
step 51/84, epoch 132/501 --> loss:0.8257457184791565
step 51/84, epoch 133/501 --> loss:0.825285691022873
step 51/84, epoch 134/501 --> loss:0.8287539744377136
step 51/84, epoch 135/501 --> loss:0.836580331325531
step 51/84, epoch 136/501 --> loss:0.8281093215942383
step 51/84, epoch 137/501 --> loss:0.8310606038570404
step 51/84, epoch 138/501 --> loss:0.8288357293605805
step 51/84, epoch 139/501 --> loss:0.8251099038124085
step 51/84, epoch 140/501 --> loss:0.8317821073532105
step 51/84, epoch 141/501 --> loss:0.8319181430339814

##########train dataset##########
acc--> [93.1169050035711]
F1--> {'F1': [0.5424609802549665], 'precision': [0.3781929313133215], 'recall': [0.9590297798975876]}
##########eval dataset##########
acc--> [93.24016087115075]
F1--> {'F1': [0.5361704669656173], 'precision': [0.3752601699473273], 'recall': [0.9386932658716219]}
step 51/84, epoch 142/501 --> loss:0.8289344334602355
step 51/84, epoch 143/501 --> loss:0.8314962327480316
step 51/84, epoch 144/501 --> loss:0.8215177714824676
step 51/84, epoch 145/501 --> loss:0.8352638781070709
step 51/84, epoch 146/501 --> loss:0.8277947950363159
step 51/84, epoch 147/501 --> loss:0.8298546957969666
step 51/84, epoch 148/501 --> loss:0.8327416121959687
step 51/84, epoch 149/501 --> loss:0.8373257410526276
step 51/84, epoch 150/501 --> loss:0.8305019283294678
step 51/84, epoch 151/501 --> loss:0.8397267317771911

##########train dataset##########
acc--> [86.12312457066888]
F1--> {'F1': [0.3708002417351029], 'precision': [0.22971738853102122], 'recall': [0.9610584732719422]}
##########eval dataset##########
acc--> [86.3191586258264]
F1--> {'F1': [0.36464399451096907], 'precision': [0.22601217547916932], 'recall': [0.9432054556154718]}
step 51/84, epoch 152/501 --> loss:0.8231769800186157
step 51/84, epoch 153/501 --> loss:0.8324273014068604
step 51/84, epoch 154/501 --> loss:0.8285336494445801
step 51/84, epoch 155/501 --> loss:0.8275107860565185
step 51/84, epoch 156/501 --> loss:0.83562579870224
step 51/84, epoch 157/501 --> loss:0.8291635322570801
step 51/84, epoch 158/501 --> loss:0.8332119631767273
step 51/84, epoch 159/501 --> loss:0.8269226610660553
step 51/84, epoch 160/501 --> loss:0.8314809775352479
step 51/84, epoch 161/501 --> loss:0.8304144155979156

##########train dataset##########
acc--> [93.44870528344944]
F1--> {'F1': [0.5519432184771975], 'precision': [0.38923547645992873], 'recall': [0.9484110260651777]}
##########eval dataset##########
acc--> [93.42196940957928]
F1--> {'F1': [0.5405173230535487], 'precision': [0.3810456392799994], 'recall': [0.9295640076799924]}
step 51/84, epoch 162/501 --> loss:0.8313914597034454
step 51/84, epoch 163/501 --> loss:0.8287460899353027
step 51/84, epoch 164/501 --> loss:0.8319979000091553
step 51/84, epoch 165/501 --> loss:0.830435231924057
step 51/84, epoch 166/501 --> loss:0.8313418996334075
step 51/84, epoch 167/501 --> loss:0.826548057794571
step 51/84, epoch 168/501 --> loss:0.8305964720249176
step 51/84, epoch 169/501 --> loss:0.8240729570388794
step 51/84, epoch 170/501 --> loss:0.8349347329139709
step 51/84, epoch 171/501 --> loss:0.8302086889743805

##########train dataset##########
acc--> [94.78444005381624]
F1--> {'F1': [0.6081894541962107], 'precision': [0.44695424301986225], 'recall': [0.951420482050201]}
##########eval dataset##########
acc--> [94.77573104417222]
F1--> {'F1': [0.5956020867341741], 'precision': [0.43936136112829804], 'recall': [0.9243074036492268]}
step 51/84, epoch 172/501 --> loss:0.8282810199260712
step 51/84, epoch 173/501 --> loss:0.8291303837299346
step 51/84, epoch 174/501 --> loss:0.8293442642688751
step 51/84, epoch 175/501 --> loss:0.833608535528183
step 51/84, epoch 176/501 --> loss:0.8384695518016815
step 51/84, epoch 177/501 --> loss:0.8255696415901184
step 51/84, epoch 178/501 --> loss:0.827856639623642
step 51/84, epoch 179/501 --> loss:0.8248044192790985
step 51/84, epoch 180/501 --> loss:0.8319649863243103
step 51/84, epoch 181/501 --> loss:0.8323145115375519

##########train dataset##########
acc--> [97.30904389285655]
F1--> {'F1': [0.744820809413033], 'precision': [0.6242872102950008], 'recall': [0.9230495686171274]}
##########eval dataset##########
acc--> [97.16276968140174]
F1--> {'F1': [0.7237919514648061], 'precision': [0.6084361449367132], 'recall': [0.8931372604032488]}
save model!
step 51/84, epoch 182/501 --> loss:0.8316737234592437
step 51/84, epoch 183/501 --> loss:0.825661244392395
step 51/84, epoch 184/501 --> loss:0.8275731539726258
step 51/84, epoch 185/501 --> loss:0.8314687919616699
step 51/84, epoch 186/501 --> loss:0.8271083414554596
step 51/84, epoch 187/501 --> loss:0.8316102874279022
step 51/84, epoch 188/501 --> loss:0.827795250415802
step 51/84, epoch 189/501 --> loss:0.8341907191276551
step 51/84, epoch 190/501 --> loss:0.8357104885578156
step 51/84, epoch 191/501 --> loss:0.827789763212204

##########train dataset##########
acc--> [97.63350828247019]
F1--> {'F1': [0.7592298285776191], 'precision': [0.6693662744495688], 'recall': [0.8769767876539173]}
##########eval dataset##########
acc--> [97.48609380980047]
F1--> {'F1': [0.7380929587937662], 'precision': [0.6516096142317827], 'recall': [0.8510590904885904]}
save model!
step 51/84, epoch 192/501 --> loss:0.8360505712032318
step 51/84, epoch 193/501 --> loss:0.8304646074771881
step 51/84, epoch 194/501 --> loss:0.8307621669769287
step 51/84, epoch 195/501 --> loss:0.8257384884357453
step 51/84, epoch 196/501 --> loss:0.8334432756900787
step 51/84, epoch 197/501 --> loss:0.8356545567512512
step 51/84, epoch 198/501 --> loss:0.8330607771873474
step 51/84, epoch 199/501 --> loss:0.8315203750133514
step 51/84, epoch 200/501 --> loss:0.8337260484695435
step 51/84, epoch 201/501 --> loss:0.8350232779979706

##########train dataset##########
acc--> [97.08832696800684]
F1--> {'F1': [0.729963759439184], 'precision': [0.6028665480478207], 'recall': [0.924981913679897]}
##########eval dataset##########
acc--> [96.89321709846656]
F1--> {'F1': [0.7056281624599557], 'precision': [0.5825686966825959], 'recall': [0.8946151841577116]}
step 51/84, epoch 202/501 --> loss:0.8316803359985352
step 51/84, epoch 203/501 --> loss:0.8351620769500733
step 51/84, epoch 204/501 --> loss:0.8346225786209106
step 51/84, epoch 205/501 --> loss:0.8334346878528595
step 51/84, epoch 206/501 --> loss:0.8217248702049256
step 51/84, epoch 207/501 --> loss:0.8313621068000794
step 51/84, epoch 208/501 --> loss:0.8250391006469726
step 51/84, epoch 209/501 --> loss:0.8353798091411591
step 51/84, epoch 210/501 --> loss:0.8334586584568023
step 51/84, epoch 211/501 --> loss:0.8330923473834991

##########train dataset##########
acc--> [96.35869109500685]
F1--> {'F1': [0.6860861419599523], 'precision': [0.5417548148372214], 'recall': [0.9352676506335353]}
##########eval dataset##########
acc--> [96.2217162391685]
F1--> {'F1': [0.6647952612556268], 'precision': [0.5270081783895825], 'recall': [0.9001546720321049]}
step 51/84, epoch 212/501 --> loss:0.8296356117725372
step 51/84, epoch 213/501 --> loss:0.8230066251754761
step 51/84, epoch 214/501 --> loss:0.8237311339378357
step 51/84, epoch 215/501 --> loss:0.8295137202739715
step 51/84, epoch 216/501 --> loss:0.8329804980754852
step 51/84, epoch 217/501 --> loss:0.8311922121047973
step 51/84, epoch 218/501 --> loss:0.8268180406093597
step 51/84, epoch 219/501 --> loss:0.830758810043335
step 51/84, epoch 220/501 --> loss:0.8220789384841919
step 51/84, epoch 221/501 --> loss:0.8292642843723297

##########train dataset##########
acc--> [94.93816019579312]
F1--> {'F1': [0.6147982761702651], 'precision': [0.4545847466257538], 'recall': [0.9494272889609245]}
##########eval dataset##########
acc--> [94.81297023235231]
F1--> {'F1': [0.5955291525878962], 'precision': [0.44085007891944367], 'recall': [0.9174410558416277]}
step 51/84, epoch 222/501 --> loss:0.830732194185257
step 51/84, epoch 223/501 --> loss:0.8329769825935364
step 51/84, epoch 224/501 --> loss:0.8176092708110809
step 51/84, epoch 225/501 --> loss:0.8260468459129333
step 51/84, epoch 226/501 --> loss:0.8287830495834351
step 51/84, epoch 227/501 --> loss:0.832873501777649
step 51/84, epoch 228/501 --> loss:0.8321971035003662
step 51/84, epoch 229/501 --> loss:0.8313241255283356
step 51/84, epoch 230/501 --> loss:0.8313530397415161
step 51/84, epoch 231/501 --> loss:0.8311959648132324

##########train dataset##########
acc--> [96.51739279965216]
F1--> {'F1': [0.6886884453950894], 'precision': [0.55568776996848], 'recall': [0.9054041115778629]}
##########eval dataset##########
acc--> [96.30755193380945]
F1--> {'F1': [0.6636798253162118], 'precision': [0.5344633657916474], 'recall': [0.8753162197146701]}
step 51/84, epoch 232/501 --> loss:0.8272713613510132
step 51/84, epoch 233/501 --> loss:0.823965494632721
step 51/84, epoch 234/501 --> loss:0.8269098401069641
step 51/84, epoch 235/501 --> loss:0.8382134509086608
step 51/84, epoch 236/501 --> loss:0.8266827821731567
step 51/84, epoch 237/501 --> loss:0.8343036389350891
step 51/84, epoch 238/501 --> loss:0.8236691081523895
step 51/84, epoch 239/501 --> loss:0.8296040213108062
step 51/84, epoch 240/501 --> loss:0.8296769213676453
step 51/84, epoch 241/501 --> loss:0.8214134514331818

##########train dataset##########
acc--> [94.49945799545172]
F1--> {'F1': [0.5971351643586333], 'precision': [0.4337249337099034], 'recall': [0.9581364905272343]}
##########eval dataset##########
acc--> [94.31979228608976]
F1--> {'F1': [0.576327466512791], 'precision': [0.41790611894856217], 'recall': [0.928210687523318]}
step 51/84, epoch 242/501 --> loss:0.822092365026474
step 51/84, epoch 243/501 --> loss:0.831908848285675
step 51/84, epoch 244/501 --> loss:0.8278439855575561
step 51/84, epoch 245/501 --> loss:0.8255143857002258
step 51/84, epoch 246/501 --> loss:0.8293132865428925
step 51/84, epoch 247/501 --> loss:0.8272883224487305
step 51/84, epoch 248/501 --> loss:0.822500194311142
step 51/84, epoch 249/501 --> loss:0.8276986587047577
step 51/84, epoch 250/501 --> loss:0.8259805154800415
step 51/84, epoch 251/501 --> loss:0.8292929708957673

##########train dataset##########
acc--> [95.58852045196957]
F1--> {'F1': [0.643371017764709], 'precision': [0.49034072863550615], 'recall': [0.9352732984061614]}
##########eval dataset##########
acc--> [95.45331138950621]
F1--> {'F1': [0.6244785941741443], 'precision': [0.47581148262726647], 'recall': [0.9082850166965482]}
step 51/84, epoch 252/501 --> loss:0.8264135372638702
step 51/84, epoch 253/501 --> loss:0.828890517950058
step 51/84, epoch 254/501 --> loss:0.833286691904068
step 51/84, epoch 255/501 --> loss:0.8281459665298462
step 51/84, epoch 256/501 --> loss:0.8278150701522827
step 51/84, epoch 257/501 --> loss:0.8334803366661072
step 51/84, epoch 258/501 --> loss:0.8255035746097564
step 51/84, epoch 259/501 --> loss:0.8331559348106384
step 51/84, epoch 260/501 --> loss:0.8321963894367218
step 51/84, epoch 261/501 --> loss:0.8260778796672821

##########train dataset##########
acc--> [97.75876623438758]
F1--> {'F1': [0.7756891710754068], 'precision': [0.6754760617011629], 'recall': [0.9108308142468353]}
##########eval dataset##########
acc--> [97.55563477309435]
F1--> {'F1': [0.7485701746607579], 'precision': [0.6544985557071095], 'recall': [0.8742363218671709]}
save model!
step 51/84, epoch 262/501 --> loss:0.8237795293331146
step 51/84, epoch 263/501 --> loss:0.8260133647918702
step 51/84, epoch 264/501 --> loss:0.8273223018646241
step 51/84, epoch 265/501 --> loss:0.8345349597930908
step 51/84, epoch 266/501 --> loss:0.830507972240448
step 51/84, epoch 267/501 --> loss:0.8305020356178283
step 51/84, epoch 268/501 --> loss:0.8328584587574005
step 51/84, epoch 269/501 --> loss:0.8309019577503204
step 51/84, epoch 270/501 --> loss:0.8308765077590943
step 51/84, epoch 271/501 --> loss:0.8324347496032715

##########train dataset##########
acc--> [96.87313398797895]
F1--> {'F1': [0.7191735711611404], 'precision': [0.5819648188886648], 'recall': [0.9410572226937313]}
##########eval dataset##########
acc--> [96.70844758067315]
F1--> {'F1': [0.6952772791470428], 'precision': [0.5655724042636187], 'recall': [0.9021929110641386]}
step 51/84, epoch 272/501 --> loss:0.8366707849502564
step 51/84, epoch 273/501 --> loss:0.8254325723648072
step 51/84, epoch 274/501 --> loss:0.8265530025959015
step 51/84, epoch 275/501 --> loss:0.8374749279022217
step 51/84, epoch 276/501 --> loss:0.8334202790260314
step 51/84, epoch 277/501 --> loss:0.8299671363830566
step 51/84, epoch 278/501 --> loss:0.8228582608699798
step 51/84, epoch 279/501 --> loss:0.824999715089798
step 51/84, epoch 280/501 --> loss:0.8287394630908966
step 51/84, epoch 281/501 --> loss:0.8270723354816437

##########train dataset##########
acc--> [95.13561647841843]
F1--> {'F1': [0.624804888314678], 'precision': [0.4650026404945262], 'recall': [0.9519718122351248]}
##########eval dataset##########
acc--> [95.06116518302008]
F1--> {'F1': [0.6076722086326225], 'precision': [0.4539228813306671], 'recall': [0.9189430343446983]}
step 51/84, epoch 282/501 --> loss:0.8288177955150604
step 51/84, epoch 283/501 --> loss:0.8304250860214233
step 51/84, epoch 284/501 --> loss:0.8242833983898162
step 51/84, epoch 285/501 --> loss:0.827016373872757
step 51/84, epoch 286/501 --> loss:0.8267859387397766
step 51/84, epoch 287/501 --> loss:0.8280051982402802
step 51/84, epoch 288/501 --> loss:0.8332482850551606
step 51/84, epoch 289/501 --> loss:0.8280774307250977
step 51/84, epoch 290/501 --> loss:0.8277931213378906
step 51/84, epoch 291/501 --> loss:0.8332707834243774

##########train dataset##########
acc--> [96.48565057068396]
F1--> {'F1': [0.6961231009950736], 'precision': [0.5506361164040994], 'recall': [0.9461145341388046]}
##########eval dataset##########
acc--> [96.32037705948954]
F1--> {'F1': [0.6728820162306239], 'precision': [0.5340568854162568], 'recall': [0.9092488102907671]}
step 51/84, epoch 292/501 --> loss:0.8262348079681396
step 51/84, epoch 293/501 --> loss:0.823960086107254
step 51/84, epoch 294/501 --> loss:0.8315883958339692
step 51/84, epoch 295/501 --> loss:0.833197250366211
step 51/84, epoch 296/501 --> loss:0.8345792853832245
step 51/84, epoch 297/501 --> loss:0.8357716822624206
step 51/84, epoch 298/501 --> loss:0.831042823791504
step 51/84, epoch 299/501 --> loss:0.8369209229946136
step 51/84, epoch 300/501 --> loss:0.8219023656845093
step 51/84, epoch 301/501 --> loss:0.8212966096401214

##########train dataset##########
acc--> [94.048917503626]
F1--> {'F1': [0.5696244426314719], 'precision': [0.41139843581875984], 'recall': [0.9256470061420027]}
##########eval dataset##########
acc--> [93.93475616801544]
F1--> {'F1': [0.5496045601612317], 'precision': [0.3977389923947264], 'recall': [0.8890942986222418]}
step 51/84, epoch 302/501 --> loss:0.8292893052101136
step 51/84, epoch 303/501 --> loss:0.8223990440368653
step 51/84, epoch 304/501 --> loss:0.8238688576221466
step 51/84, epoch 305/501 --> loss:0.8288784146308898
step 51/84, epoch 306/501 --> loss:0.8285259938240052
step 51/84, epoch 307/501 --> loss:0.822201303243637
step 51/84, epoch 308/501 --> loss:0.8324182295799255
step 51/84, epoch 309/501 --> loss:0.8231710624694825
step 51/84, epoch 310/501 --> loss:0.8247622275352477
step 51/84, epoch 311/501 --> loss:0.8337293827533722

##########train dataset##########
acc--> [97.52637436204594]
F1--> {'F1': [0.7387861947105185], 'precision': [0.670757772203317], 'recall': [0.8221832406375917]}
##########eval dataset##########
acc--> [97.33470005625477]
F1--> {'F1': [0.7128235496319426], 'precision': [0.6462235402139104], 'recall': [0.7947408301281]}
step 51/84, epoch 312/501 --> loss:0.8280316650867462
step 51/84, epoch 313/501 --> loss:0.8263686919212341
step 51/84, epoch 314/501 --> loss:0.8218138587474823
step 51/84, epoch 315/501 --> loss:0.8316666626930237
step 51/84, epoch 316/501 --> loss:0.8365968644618988
step 51/84, epoch 317/501 --> loss:0.8301751136779785
step 51/84, epoch 318/501 --> loss:0.8262982082366943
step 51/84, epoch 319/501 --> loss:0.8259598994255066
step 51/84, epoch 320/501 --> loss:0.8281481766700745
step 51/84, epoch 321/501 --> loss:0.8349265193939209

##########train dataset##########
acc--> [97.76642051670751]
F1--> {'F1': [0.7790506004550715], 'precision': [0.6726118392477686], 'recall': [0.9255234274981137]}
##########eval dataset##########
acc--> [97.51026023403527]
F1--> {'F1': [0.7464304869259101], 'precision': [0.6478410227731454], 'recall': [0.880426731238891]}
step 51/84, epoch 322/501 --> loss:0.8284447002410888
step 51/84, epoch 323/501 --> loss:0.8248381400108338
step 51/84, epoch 324/501 --> loss:0.8307606101036071
step 51/84, epoch 325/501 --> loss:0.8202197635173798
step 51/84, epoch 326/501 --> loss:0.8262126839160919
step 51/84, epoch 327/501 --> loss:0.8310402262210846
step 51/84, epoch 328/501 --> loss:0.8298437440395355
step 51/84, epoch 329/501 --> loss:0.8236031770706177
step 51/84, epoch 330/501 --> loss:0.8386949646472931
step 51/84, epoch 331/501 --> loss:0.8299290692806244

##########train dataset##########
acc--> [96.47551122836053]
F1--> {'F1': [0.6950866669727991], 'precision': [0.5499840625068707], 'recall': [0.9442110330576609]}
##########eval dataset##########
acc--> [96.29837129580571]
F1--> {'F1': [0.6708120499751292], 'precision': [0.5325220518552279], 'recall': [0.9061386916607701]}
step 51/84, epoch 332/501 --> loss:0.8201994526386261
step 51/84, epoch 333/501 --> loss:0.8341862475872039
step 51/84, epoch 334/501 --> loss:0.8260375094413758
step 51/84, epoch 335/501 --> loss:0.8253952169418335
step 51/84, epoch 336/501 --> loss:0.8259520137310028
step 51/84, epoch 337/501 --> loss:0.8262296497821808
step 51/84, epoch 338/501 --> loss:0.8345513117313385
step 51/84, epoch 339/501 --> loss:0.8274090528488159
step 51/84, epoch 340/501 --> loss:0.8241580986976623
step 51/84, epoch 341/501 --> loss:0.8300427484512329

##########train dataset##########
acc--> [97.76457023834875]
F1--> {'F1': [0.7805250684828468], 'precision': [0.6702338501220209], 'recall': [0.9342780801869854]}
##########eval dataset##########
acc--> [97.48991718441769]
F1--> {'F1': [0.7453801119548544], 'precision': [0.6450329201196865], 'recall': [0.8827148189264643]}
step 51/84, epoch 342/501 --> loss:0.8205091726779937
step 51/84, epoch 343/501 --> loss:0.8357980394363403
step 51/84, epoch 344/501 --> loss:0.8297474992275238
step 51/84, epoch 345/501 --> loss:0.819972231388092
step 51/84, epoch 346/501 --> loss:0.8251265525817871
step 51/84, epoch 347/501 --> loss:0.8305047821998596
step 51/84, epoch 348/501 --> loss:0.8256608283519745
step 51/84, epoch 349/501 --> loss:0.8323371243476868
step 51/84, epoch 350/501 --> loss:0.8286208236217498
step 51/84, epoch 351/501 --> loss:0.8240567195415497

##########train dataset##########
acc--> [94.54320128776357]
F1--> {'F1': [0.5996505429601495], 'precision': [0.43589181777226926], 'recall': [0.9605181024553284]}
##########eval dataset##########
acc--> [94.36608195199945]
F1--> {'F1': [0.5771844355925454], 'precision': [0.4196946972393752], 'recall': [0.9238842004387203]}
step 51/84, epoch 352/501 --> loss:0.8349090421199798
step 51/84, epoch 353/501 --> loss:0.8333654248714447
step 51/84, epoch 354/501 --> loss:0.8192051362991333
step 51/84, epoch 355/501 --> loss:0.8291101801395416
step 51/84, epoch 356/501 --> loss:0.8350722980499268
step 51/84, epoch 357/501 --> loss:0.8342765235900879
step 51/84, epoch 358/501 --> loss:0.8251640892028809
step 51/84, epoch 359/501 --> loss:0.8250369608402253
step 51/84, epoch 360/501 --> loss:0.8303140687942505
step 51/84, epoch 361/501 --> loss:0.8270201504230499

##########train dataset##########
acc--> [97.88307244293767]
F1--> {'F1': [0.7856101015832363], 'precision': [0.6902029774295481], 'recall': [0.9116376389076994]}
##########eval dataset##########
acc--> [97.61156230668878]
F1--> {'F1': [0.7505260420869587], 'precision': [0.6638899126103044], 'recall': [0.863180438677048]}
save model!
step 51/84, epoch 362/501 --> loss:0.8287771320343018
step 51/84, epoch 363/501 --> loss:0.8238390171527863
step 51/84, epoch 364/501 --> loss:0.8278314125537872
step 51/84, epoch 365/501 --> loss:0.8278854811191558
step 51/84, epoch 366/501 --> loss:0.8237436842918396
step 51/84, epoch 367/501 --> loss:0.8219687521457673
step 51/84, epoch 368/501 --> loss:0.8247580397129058
step 51/84, epoch 369/501 --> loss:0.8322273623943329
step 51/84, epoch 370/501 --> loss:0.8328198540210724
step 51/84, epoch 371/501 --> loss:0.835304251909256

##########train dataset##########
acc--> [97.51204729169316]
F1--> {'F1': [0.7552937486659855], 'precision': [0.6494054560786028], 'recall': [0.9024543606177436]}
##########eval dataset##########
acc--> [97.28818077427171]
F1--> {'F1': [0.7268032164610014], 'precision': [0.6258206069360361], 'recall': [0.866659236420707]}
step 51/84, epoch 372/501 --> loss:0.831654782295227
step 51/84, epoch 373/501 --> loss:0.8294621884822846
step 51/84, epoch 374/501 --> loss:0.8280027461051941
step 51/84, epoch 375/501 --> loss:0.8382770824432373
step 51/84, epoch 376/501 --> loss:0.8298874461650848
step 51/84, epoch 377/501 --> loss:0.8324753475189209
step 51/84, epoch 378/501 --> loss:0.8340384483337402
step 51/84, epoch 379/501 --> loss:0.8146314299106598
step 51/84, epoch 380/501 --> loss:0.8299200809001923
step 51/84, epoch 381/501 --> loss:0.8212991070747375

##########train dataset##########
acc--> [94.521576660062]
F1--> {'F1': [0.5985935985569046], 'precision': [0.434863502773172], 'recall': [0.96009008197274]}
##########eval dataset##########
acc--> [94.29835856012363]
F1--> {'F1': [0.5737001935059272], 'precision': [0.41645455674393883], 'recall': [0.9217499027772462]}
step 51/84, epoch 382/501 --> loss:0.826648108959198
step 51/84, epoch 383/501 --> loss:0.8254015302658081
step 51/84, epoch 384/501 --> loss:0.8314739465713501
step 51/84, epoch 385/501 --> loss:0.817517272233963
step 51/84, epoch 386/501 --> loss:0.828962515592575
step 51/84, epoch 387/501 --> loss:0.8223765277862549
step 51/84, epoch 388/501 --> loss:0.8164550709724426
step 51/84, epoch 389/501 --> loss:0.8163287091255188
step 51/84, epoch 390/501 --> loss:0.8334736764431
step 51/84, epoch 391/501 --> loss:0.8332024729251861

##########train dataset##########
acc--> [90.19543333450248]
F1--> {'F1': [0.4542982370304219], 'precision': [0.2976320689961439], 'recall': [0.9592267795856153]}
##########eval dataset##########
acc--> [90.02959016947841]
F1--> {'F1': [0.4348434779466129], 'precision': [0.2845605397720912], 'recall': [0.9215508898237644]}
step 51/84, epoch 392/501 --> loss:0.8342991685867309
step 51/84, epoch 393/501 --> loss:0.8182347583770752
step 51/84, epoch 394/501 --> loss:0.8215731155872344
step 51/84, epoch 395/501 --> loss:0.8239650666713715
step 51/84, epoch 396/501 --> loss:0.8275872206687928
step 51/84, epoch 397/501 --> loss:0.823071573972702
step 51/84, epoch 398/501 --> loss:0.8239773964881897
step 51/84, epoch 399/501 --> loss:0.8322907841205597
step 51/84, epoch 400/501 --> loss:0.8292416846752166
step 51/84, epoch 401/501 --> loss:0.8270696532726288

##########train dataset##########
acc--> [97.61642381677109]
F1--> {'F1': [0.7699145530504207], 'precision': [0.6532442954833506], 'recall': [0.937335676710107]}
##########eval dataset##########
acc--> [97.31988180965864]
F1--> {'F1': [0.7340046428722653], 'precision': [0.6253187219915461], 'recall': [0.8884340759554532]}
step 51/84, epoch 402/501 --> loss:0.8254096567630768
step 51/84, epoch 403/501 --> loss:0.8348475503921509
step 51/84, epoch 404/501 --> loss:0.8299898362159729
step 51/84, epoch 405/501 --> loss:0.822635041475296
step 51/84, epoch 406/501 --> loss:0.8272519421577453
step 51/84, epoch 407/501 --> loss:0.8271250379085541
step 51/84, epoch 408/501 --> loss:0.825217205286026
step 51/84, epoch 409/501 --> loss:0.8257130706310272
step 51/84, epoch 410/501 --> loss:0.8228107738494873
step 51/84, epoch 411/501 --> loss:0.8273953986167908

##########train dataset##########
acc--> [96.98258275881741]
F1--> {'F1': [0.7271161387035089], 'precision': [0.5909366375010783], 'recall': [0.9448710156302478]}
##########eval dataset##########
acc--> [96.69865952805668]
F1--> {'F1': [0.6939956512482623], 'precision': [0.5649650058015777], 'recall': [0.8994248509593444]}
step 51/84, epoch 412/501 --> loss:0.8348024952411651
step 51/84, epoch 413/501 --> loss:0.8277347898483276
step 51/84, epoch 414/501 --> loss:0.8372199869155884
step 51/84, epoch 415/501 --> loss:0.8188495242595673
step 51/84, epoch 416/501 --> loss:0.8299168670177459
step 51/84, epoch 417/501 --> loss:0.8253780055046082
step 51/84, epoch 418/501 --> loss:0.827489641904831
step 51/84, epoch 419/501 --> loss:0.8165065586566925
step 51/84, epoch 420/501 --> loss:0.8289953577518463
step 51/84, epoch 421/501 --> loss:0.8315648424625397

##########train dataset##########
acc--> [98.01515451208577]
F1--> {'F1': [0.8007595084695003], 'precision': [0.6988450334842511], 'recall': [0.9374872925109611]}
##########eval dataset##########
acc--> [97.64759801294937]
F1--> {'F1': [0.7569812351592047], 'precision': [0.6640060136564602], 'recall': [0.8802461602593419]}
save model!
step 51/84, epoch 422/501 --> loss:0.832826269865036
step 51/84, epoch 423/501 --> loss:0.8217512464523316
step 51/84, epoch 424/501 --> loss:0.8289322423934936
step 51/84, epoch 425/501 --> loss:0.8272270309925079
step 51/84, epoch 426/501 --> loss:0.8234920692443848
step 51/84, epoch 427/501 --> loss:0.8266489577293396
step 51/84, epoch 428/501 --> loss:0.8275358390808105
step 51/84, epoch 429/501 --> loss:0.8262047910690308
step 51/84, epoch 430/501 --> loss:0.8292001879215241
step 51/84, epoch 431/501 --> loss:0.8182726013660431

##########train dataset##########
acc--> [96.52202593327901]
F1--> {'F1': [0.7012442863309819], 'precision': [0.5525738981591575], 'recall': [0.9593783953864694]}
##########eval dataset##########
acc--> [96.09451961433255]
F1--> {'F1': [0.6593082708099225], 'precision': [0.517588008149193], 'recall': [0.9079168186778582]}
step 51/84, epoch 432/501 --> loss:0.8235494422912598
step 51/84, epoch 433/501 --> loss:0.821693650484085
step 51/84, epoch 434/501 --> loss:0.8269948184490203
step 51/84, epoch 435/501 --> loss:0.8280361533164978
step 51/84, epoch 436/501 --> loss:0.8239708864688873
step 51/84, epoch 437/501 --> loss:0.8298515951633454
step 51/84, epoch 438/501 --> loss:0.8251537144184112
step 51/84, epoch 439/501 --> loss:0.8291885483264924
step 51/84, epoch 440/501 --> loss:0.827594518661499
step 51/84, epoch 441/501 --> loss:0.8249513411521912

##########train dataset##########
acc--> [97.45062451528607]
F1--> {'F1': [0.7609014715517729], 'precision': [0.6330631442757099], 'recall': [0.9534493771307208]}
##########eval dataset##########
acc--> [97.10893071959106]
F1--> {'F1': [0.720942062940844], 'precision': [0.6025528153365327], 'recall': [0.897244047450562]}
step 51/84, epoch 442/501 --> loss:0.8244526839256286
step 51/84, epoch 443/501 --> loss:0.8225899147987366
step 51/84, epoch 444/501 --> loss:0.8326323127746582
step 51/84, epoch 445/501 --> loss:0.8288452494144439
step 51/84, epoch 446/501 --> loss:0.828706510066986
step 51/84, epoch 447/501 --> loss:0.8268439912796021
step 51/84, epoch 448/501 --> loss:0.8337946856021881
step 51/84, epoch 449/501 --> loss:0.8280075478553772
step 51/84, epoch 450/501 --> loss:0.8250316905975342
step 51/84, epoch 451/501 --> loss:0.8315433430671691

##########train dataset##########
acc--> [97.56644770675969]
F1--> {'F1': [0.7675099940144222], 'precision': [0.6465629807739581], 'recall': [0.9441327038301687]}
##########eval dataset##########
acc--> [97.1537445682384]
F1--> {'F1': [0.7212169049822474], 'precision': [0.6088108073437536], 'recall': [0.8845441023755917]}
step 51/84, epoch 452/501 --> loss:0.8271780729293823
step 51/84, epoch 453/501 --> loss:0.824488787651062
step 51/84, epoch 454/501 --> loss:0.8317558908462525
step 51/84, epoch 455/501 --> loss:0.8237811303138733
step 51/84, epoch 456/501 --> loss:0.8242129933834076
step 51/84, epoch 457/501 --> loss:0.8294328963756561
step 51/84, epoch 458/501 --> loss:0.8251142430305481
step 51/84, epoch 459/501 --> loss:0.8321264219284058
step 51/84, epoch 460/501 --> loss:0.8210880267620086
step 51/84, epoch 461/501 --> loss:0.8248726189136505

##########train dataset##########
acc--> [97.47849025661674]
F1--> {'F1': [0.7501385200951776], 'precision': [0.6484628138409272], 'recall': [0.8896413798847251]}
##########eval dataset##########
acc--> [97.2337030258848]
F1--> {'F1': [0.7187782317923477], 'precision': [0.6230058965734339], 'recall': [0.8493584197620194]}
step 51/84, epoch 462/501 --> loss:0.8252297818660737
step 51/84, epoch 463/501 --> loss:0.8301812934875489
step 51/84, epoch 464/501 --> loss:0.8314873397350311
step 51/84, epoch 465/501 --> loss:0.8321584928035736
step 51/84, epoch 466/501 --> loss:0.8269768130779266
step 51/84, epoch 467/501 --> loss:0.8222659528255463
step 51/84, epoch 468/501 --> loss:0.8139841532707215
step 51/84, epoch 469/501 --> loss:0.8277667963504791
step 51/84, epoch 470/501 --> loss:0.8285912096500396
step 51/84, epoch 471/501 --> loss:0.8283263909816742

##########train dataset##########
acc--> [97.56372235086546]
F1--> {'F1': [0.7684075541619918], 'precision': [0.6451211569640621], 'recall': [0.9499628860649615]}
##########eval dataset##########
acc--> [97.20783917817728]
F1--> {'F1': [0.7277393090403926], 'precision': [0.6124299288494452], 'recall': [0.8965564023703605]}
step 51/84, epoch 472/501 --> loss:0.8293168544769287
step 51/84, epoch 473/501 --> loss:0.8282793533802032
step 51/84, epoch 474/501 --> loss:0.8281341195106506
step 51/84, epoch 475/501 --> loss:0.825692526102066
step 51/84, epoch 476/501 --> loss:0.8250570976734162
step 51/84, epoch 477/501 --> loss:0.8250297474861145
step 51/84, epoch 478/501 --> loss:0.8230675601959229
step 51/84, epoch 479/501 --> loss:0.8290751528739929
step 51/84, epoch 480/501 --> loss:0.8321275639533997
step 51/84, epoch 481/501 --> loss:0.82819584608078

##########train dataset##########
acc--> [98.19724530283042]
F1--> {'F1': [0.8153486919128833], 'precision': [0.7225571200426986], 'recall': [0.9354975956618816]}
##########eval dataset##########
acc--> [97.79642727534991]
F1--> {'F1': [0.7675358476783432], 'precision': [0.684192614232374], 'recall': [0.8740127730701092]}
save model!
step 51/84, epoch 482/501 --> loss:0.8261084938049317
step 51/84, epoch 483/501 --> loss:0.8243321979045868
step 51/84, epoch 484/501 --> loss:0.8215970563888549
step 51/84, epoch 485/501 --> loss:0.8294501602649689
step 51/84, epoch 486/501 --> loss:0.8369325006008148
step 51/84, epoch 487/501 --> loss:0.824311398267746
step 51/84, epoch 488/501 --> loss:0.8240904605388641
step 51/84, epoch 489/501 --> loss:0.8220581531524658
step 51/84, epoch 490/501 --> loss:0.824537318944931
step 51/84, epoch 491/501 --> loss:0.8273894321918488

##########train dataset##########
acc--> [98.09048527136952]
F1--> {'F1': [0.8072092276236843], 'precision': [0.7075333296876196], 'recall': [0.9395879277509093]}
##########eval dataset##########
acc--> [97.70597723211802]
F1--> {'F1': [0.7599950079207589], 'precision': [0.6731139277951865], 'recall': [0.8726410109395021]}
step 51/84, epoch 492/501 --> loss:0.8198979020118713
step 51/84, epoch 493/501 --> loss:0.8306864309310913
step 51/84, epoch 494/501 --> loss:0.833627290725708
step 51/84, epoch 495/501 --> loss:0.8215871119499206
step 51/84, epoch 496/501 --> loss:0.8222488200664521
step 51/84, epoch 497/501 --> loss:0.8214089906215668
step 51/84, epoch 498/501 --> loss:0.8251625061035156
step 51/84, epoch 499/501 --> loss:0.8345428097248078
step 51/84, epoch 500/501 --> loss:0.8386980533599854
step 51/84, epoch 501/501 --> loss:0.8326479411125183

##########train dataset##########
acc--> [97.96322599796204]
F1--> {'F1': [0.7981936190928705], 'precision': [0.6899478277261554], 'recall': [0.9467388819555367]}
##########eval dataset##########
acc--> [97.57584098755191]
F1--> {'F1': [0.7525122007108243], 'precision': [0.654284146736642], 'recall': [0.885458022457697]}
